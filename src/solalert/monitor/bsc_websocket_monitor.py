"""
BSC WebSocket ç›‘æ§å™¨
ä½¿ç”¨ WebSocket å®æ—¶ç›‘å¬é“¾ä¸Šäº‹ä»¶ï¼Œæ›¿ä»£ Alchemy Webhook
"""
import json
import time
import asyncio
import logging
import signal
import random
import re
import websocket
import requests
import traceback
import urllib3
import threading
import os
import time
from datetime import datetime, timezone, timedelta
from decimal import Decimal
from typing import Dict, Optional
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache
from collections import OrderedDict
from ..api.telegram_api import TelegramAPI
from ..api.dbotx_api import DBotXAPI
from ..notifiers.telegram import TelegramNotifier
from ..core.redis_client import get_redis
from ..core.config import TELEGRAM_CONFIG
from ..core.formatters import format_number
from .trigger_logic import TriggerLogic
from ..notifiers.alert_recorder import get_alert_recorder
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Prometheus Metrics
try:
    from prometheus_client import Counter, Gauge, Histogram, start_http_server, REGISTRY
    HAS_PROMETHEUS = True
except ImportError:
    HAS_PROMETHEUS = False
    Counter = Gauge = Histogram = None


# å¯é€‰ä¾èµ–ï¼šeth_abiï¼ˆç”¨äº Multicall2ï¼‰
try:
    from eth_abi import encode as eth_abi_encode, decode as eth_abi_decode
    HAS_ETH_ABI = True
except ImportError:
    HAS_ETH_ABI = False
    eth_abi_encode = None
    eth_abi_decode = None

# å¯é€‰ä¾èµ–ï¼štelegramï¼ˆç”¨äºæŒ‰é’®ï¼‰
try:
    from telegram import InlineKeyboardButton, InlineKeyboardMarkup
    HAS_TELEGRAM_BUTTONS = True
except ImportError:
    HAS_TELEGRAM_BUTTONS = False
    InlineKeyboardButton = None
    InlineKeyboardMarkup = None

# ä½¿ç”¨ç»Ÿä¸€çš„å±‚çº§loggerå‘½å
logger = logging.getLogger('solalert.monitor.bsc_ws')


class BSCWebSocketMonitor:
    """BSC WebSocket ç›‘æ§å™¨"""
    
    def __init__(
        self,
        ws_url: str,
        rpc_url: str,
        enable_telegram: bool = True
    ):
        """
        åˆå§‹åŒ– WebSocket ç›‘æ§å™¨
        
        Args:
            ws_url: WebSocket RPC URL
            rpc_url: HTTP RPC URL
            enable_telegram: æ˜¯å¦å¯ç”¨ Telegram æ¨é€
        """
        self.ws_url = ws_url
        self.rpc_url = rpc_url
        self.enable_telegram = enable_telegram
        
        # å¯åŠ¨æ—¶é—´
        self.start_time = time.time()
        
        # Redis
        self.redis_client = get_redis()
        
        # Alert Recorderï¼ˆç”¨äºè®°å½•åˆ°æ•°æ®åº“å’Œæ¨é€WebSocketï¼‰
        self.alert_recorder = get_alert_recorder()
        
        # å¸¸é‡
        self.USDT = "0x55d398326f99059ff775485246999027b3197955"
        self.WBNB = "0xbb4cdb9cbd36b01bd1cbaebf2de08d9173bc095c"
        self.USDC = "0x8ac76a51cc950d9822d68b83fe1ad97b32cd580d"
        # åªç›‘å¬ä¸»Proxyï¼ˆTry Buyå·²åºŸå¼ƒï¼Œ2025å¹´æ— æ´»åŠ¨ï¼‰
        self.FOURMEME_PROXY = [
            "0x5c952063c7fc8610ffdb798152d69f0b9550762b".lower()  # ä¸»Proxy
        ]
        self.TOPIC_V2_SWAP = "0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822"
        
        # Fourmeme è‡ªå®šä¹‰äº‹ä»¶ï¼ˆå¯æ•è·å†…éƒ¨è°ƒç”¨ï¼‰
        self.FOURMEME_CUSTOM_EVENTS = [
            "0x7db52723a3b2cdd6164364b3b766e65e540d7be48ffa89582956d8eaebe62942",  # äº‹ä»¶1
            "0x48063b1239b68b5d50123408787a6df1f644d9160f0e5f702fefddb9a855954d"   # äº‹ä»¶2
        ]
        
        # Multicall2 é…ç½®ï¼ˆBSCï¼‰
        # æ³¨æ„ï¼šBSC ä¸Šæœ‰å¤šä¸ª Multicall å®ç°ï¼Œä¼˜å…ˆä½¿ç”¨è·¨é“¾é€šç”¨çš„ Multicall3
        self.MULTICALL2_ADDRESS = "0xcA11bde05977b3631167028862bE2A173976CA11"  # Multicall3ï¼ˆè·¨é“¾é€šç”¨åœ°å€ï¼‰
        # tryAggregate å‡½æ•°é€‰æ‹©å™¨: tryAggregate(bool requireSuccess, tuple[] calls)
        # Multicall3 ä¹Ÿæ”¯æŒæ­¤å‡½æ•°ï¼Œå‘åå…¼å®¹ Multicall2
        self.MULTICALL2_TRY_AGGREGATE_SELECTOR = "bce38bd7"  # ä¸å¸¦0xå‰ç¼€
        
        # Telegram é…ç½®
        self.bsc_channel_id = str(TELEGRAM_CONFIG.get('bsc_channel_id'))
        self.telegram_notifier = TelegramNotifier(enabled=self.enable_telegram)
        
        # å†·å´æœŸé…ç½®
        self.cooldown_minutes = 3.0
        self.cooldown_jitter = 0.5
        
        # è¿‡æ»¤é…ç½®ï¼ˆä» Redis åŠ è½½ï¼‰
        self.min_amount_internal = 200  # é»˜è®¤å€¼
        self.min_amount_external = 400  # å¤–ç›˜é»˜è®¤400
        self.cumulative_min_amount_internal = 500
        self.cumulative_min_amount_external = 1000  # å¤–ç›˜ç´¯è®¡1000
        
        # æ—¶é—´é—´éš”å’ŒTopæŒæœ‰è€…é˜ˆå€¼ï¼ˆä» Redis åŠ è½½ï¼‰
        self.time_interval_internal = '1m'  # å†…ç›˜é»˜è®¤1åˆ†é’Ÿ
        self.time_interval_external = '5m'  # å¤–ç›˜é»˜è®¤5åˆ†é’Ÿ
        self.top_holders_threshold_internal = None  # å†…ç›˜TopæŒæœ‰è€…é˜ˆå€¼ï¼ˆNoneè¡¨ç¤ºä¸æ£€æŸ¥ï¼‰
        self.top_holders_threshold_external = None  # å¤–ç›˜TopæŒæœ‰è€…é˜ˆå€¼ï¼ˆNoneè¡¨ç¤ºä¸æ£€æŸ¥ï¼‰
        
        # é»˜è®¤ events_configï¼ˆåå¤‡é…ç½®ï¼‰
        self.internal_events_config = {
            'priceChange': {'enabled': True, 'risePercent': 30},  # é»˜è®¤ï¼šå†…ç›˜æ¶¨å¹… >= 30%
            'volume': {'enabled': True, 'threshold': 5000}        # é»˜è®¤ï¼šå†…ç›˜äº¤æ˜“é‡ >= $5000
        }
        self.external_events_config = {
            'priceChange': {'enabled': True, 'risePercent': 50},  # é»˜è®¤ï¼šå¤–ç›˜æ¶¨å¹… >= 50%
            'volume': {'enabled': True, 'threshold': 20000}       # é»˜è®¤ï¼šå¤–ç›˜äº¤æ˜“é‡ >= $20000
        }
        
        # è§¦å‘é€»è¾‘ï¼ˆé»˜è®¤å€¼ï¼‰
        self.trigger_logic_internal = 'any'  # å†…ç›˜è§¦å‘é€»è¾‘
        self.trigger_logic_external = 'any'  # å¤–ç›˜è§¦å‘é€»è¾‘
        
        # WebSocket
        self.ws = None
        self.should_stop = False
        self.reconnect_count = 0  # é‡è¿è®¡æ•°
        self.last_message_time = time.time()  # æœ€åä¸€æ¬¡æ”¶åˆ°æ¶ˆæ¯çš„æ—¶é—´
        self.message_count = 0  # æ¶ˆæ¯è®¡æ•°å™¨
        self.cache_hit_count = 0  # éfourmemeç¼“å­˜å‘½ä¸­è®¡æ•°
        
        # ç¬¬ä¸€å±‚/ç¬¬äºŒå±‚ç»Ÿè®¡ï¼ˆå†…å¤–ç›˜åˆ†åˆ«è®¡æ•°ï¼‰
        self.first_layer_pass_internal = 0  # å†…ç›˜é€šè¿‡ç¬¬ä¸€å±‚
        self.first_layer_pass_external = 0  # å¤–ç›˜é€šè¿‡ç¬¬ä¸€å±‚
        self.second_layer_check_internal = 0  # å†…ç›˜ç¬¬äºŒå±‚æ£€æŸ¥æ¬¡æ•°
        self.second_layer_check_external = 0  # å¤–ç›˜ç¬¬äºŒå±‚æ£€æŸ¥æ¬¡æ•°
        self.second_layer_pass_internal = 0  # å†…ç›˜é€šè¿‡ç¬¬äºŒå±‚
        self.second_layer_pass_external = 0  # å¤–ç›˜é€šè¿‡ç¬¬äºŒå±‚
        
        # å‘Šè­¦å‘é€ç»Ÿè®¡
        self.alert_success_count = 0  # å‘Šè­¦å‘é€æˆåŠŸæ¬¡æ•°
        self.alert_fail_count = 0  # å‘Šè­¦å‘é€å¤±è´¥æ¬¡æ•°
        
        # ========== ç›´æ¥å¤„ç†æ¶æ„ï¼ˆæ— é˜Ÿåˆ—ï¼‰==========
        # å¤„ç†æµç¨‹ï¼šWebSocket â†’ çº¿ç¨‹æ±  â†’ å¼‚æ­¥å¤„ç†ï¼ˆä½å»¶è¿Ÿï¼Œé«˜ååï¼‰
        
        # çº¿ç¨‹æ± ï¼ˆç›´æ¥å¤„ç†æ¨¡å¼ï¼šWebSocketå›è°ƒ â†’ çº¿ç¨‹æ±  â†’ å¼‚æ­¥å¤„ç†ï¼‰
        # 8æ ¸24GæœåŠ¡å™¨ï¼šæ‰©å¤§çº¿ç¨‹æ± ä»¥æ”¯æŒé«˜å¹¶å‘ç›´æ¥å¤„ç†
        self.executor = ThreadPoolExecutor(max_workers=20, thread_name_prefix="BSC-WS-Direct")
        self.thread_local = threading.local()
        
        # äº¤æ˜“å»é‡ï¼ˆä½¿ç”¨ tx_hash:logIndex ç»„åˆé”®ï¼Œæ”¯æŒå¤šæ—¥å¿—å¤„ç†ï¼‰
        self.seen_txs = OrderedDict()
        self.max_seen_txs = 100000  # å¢å¤§å®¹é‡ä»¥é€‚åº” (tx_hash, logIndex) ç»„åˆé”®
        
        # WBNB ä»·æ ¼ç¼“å­˜
        self.wbnb_price = 600.0
        self.wbnb_price_timestamp = 0
        self.price_cache_ttl = 300  # 5åˆ†é’Ÿ
        

        
        self.session = requests.Session()
        # é…ç½®è¿æ¥æ± å’Œé‡è¯•ç­–ç•¥ï¼ˆé™ä½å¹¶å‘ï¼‰
        retry_strategy = Retry(
            total=3,
            backoff_factor=0.3,
            status_forcelist=[500, 502, 503, 504]
        )
        adapter = HTTPAdapter(
            pool_connections=5,   # è¿æ¥æ± å¤§å°ï¼ˆä¸çº¿ç¨‹æ± max_workersä¸€è‡´ï¼‰
            pool_maxsize=10,      # æœ€å¤§è¿æ¥æ•°ï¼ˆé™ä½å¹¶å‘å‹åŠ›ï¼‰
            max_retries=retry_strategy
        )
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        # RPC è°ƒç”¨è®¡æ•°å’Œç»Ÿè®¡
        self.rpc_id = 0
        self.rpc_stats = {}  # {method: count} ç»Ÿè®¡å„æ–¹æ³•è°ƒç”¨æ¬¡æ•°
        self.rpc_stats_start_time = time.time()  # ç»Ÿè®¡å¼€å§‹æ—¶é—´
        
        # é€Ÿç‡é™åˆ¶ï¼ˆé˜²æ­¢429é™æµï¼‰
        self.rate_limit_lock = threading.Lock()
        self.last_rpc_time = 0
        self.min_rpc_interval = 0.001  # 1ms è±¡å¾æ€§é—´éš”ï¼ŒChainstackæ— é™åˆ¶
        self.rate_limit_429_count = 0  # 429é”™è¯¯è®¡æ•°
        self.rate_limit_backoff_until = 0  # é€€é¿æˆªæ­¢æ—¶é—´ï¼ˆç§’ï¼‰
        self.rate_limit_consecutive_429 = 0  # è¿ç»­429æ¬¡æ•°
        
        # æ–­çº¿å›è¡¥
        self.last_processed_block = 0
        self.reconnect_time = 0
        self.last_backfill_time = 0  # ä¸Šæ¬¡å›è¡¥æ—¶é—´
        self.backfill_cooldown = 300  # å›è¡¥å†·å´æœŸï¼ˆ5åˆ†é’Ÿï¼Œå¤§å¹…å‡å°‘å›è¡¥é¢‘ç‡ï¼‰
        self.backfill_count = 0  # å›è¡¥æ¬¡æ•°ç»Ÿè®¡
        
        # å›æ‰§ç¼“å­˜ï¼ˆå‡å°‘ eth_getTransactionReceipt é‡å¤è°ƒç”¨ï¼Œå¸¦å¹¶å‘ä¿æŠ¤ï¼‰
        self.receipt_cache = {}  # {tx_hash: {"receipt": {}, "tx_info": {}, "cached_at": timestamp, "status": "ready|loading|failed", "event": threading.Event()}}
        # OPTIMIZED: TTLå»¶é•¿åˆ°1å°æ—¶ï¼Œæé«˜ç¼“å­˜å‘½ä¸­ç‡ï¼ˆäº¤æ˜“å›æ‰§æ°¸ä¸å˜ï¼‰
        self.receipt_cache_ttl = 3600  # 1å°æ—¶è¿‡æœŸï¼ˆä»30åˆ†é’Ÿæå‡ï¼‰
        self.receipt_cache_failed_ttl = 300  # å¤±è´¥ç»“æœç¼“å­˜5åˆ†é’Ÿï¼ˆä»2åˆ†é’Ÿæå‡ï¼Œé¿å…NodeRealæ…¢èŠ‚ç‚¹é‡è¯•ï¼‰
        self.receipt_cache_hits = 0  # å‘½ä¸­è®¡æ•°
        self.receipt_cache_misses = 0  # æœªå‘½ä¸­è®¡æ•°
        self.receipt_cache_concurrent_waits = 0  # å¹¶å‘ç­‰å¾…è®¡æ•°
        self.receipt_cache_failed_hits = 0  # å¤±è´¥ç¼“å­˜å‘½ä¸­ï¼ˆé¿å…é‡è¯•ï¼‰
        self.receipt_cache_wait_time_total = 0.0  # ç´¯è®¡ç­‰å¾…è€—æ—¶ï¼ˆç§’ï¼‰
        self.receipt_cache_wait_timeouts = 0  # ç­‰å¾…è¶…æ—¶æ¬¡æ•°
        self.receipt_cache_lock = threading.Lock()  # å…¨å±€é”ï¼ˆä»…ç”¨äºè¯»å†™ç¼“å­˜å­—å…¸ï¼‰
        
        # eth_call ç¼“å­˜ï¼ˆå‡å°‘ä»£å¸ä¿¡æ¯é‡å¤æŸ¥è¯¢ï¼‰
        self.eth_call_cache = {}  # {(to, data): (result, cached_at)}
        self.eth_call_cache_ttl = 300  # 5åˆ†é’Ÿè¿‡æœŸï¼ˆdecimals/symbolä¸ä¼šå˜ï¼‰
        self.eth_call_cache_hits = 0  # å‘½ä¸­è®¡æ•°
        self.eth_call_cache_lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
        
        # ========== Prometheus Metrics ==========
        if HAS_PROMETHEUS:
            try:
                # Counterï¼ˆè®¡æ•°å™¨ï¼‰- åªå¢ä¸å‡
                self.metrics_messages = Counter(
                    'bsc_messages_total', 
                    'WebSocketæ¥æ”¶çš„æ€»æ¶ˆæ¯æ•°'
                )
                self.metrics_first_layer_pass = Counter(
                    'bsc_first_layer_pass_total', 
                    'ç¬¬ä¸€å±‚è¿‡æ»¤é€šè¿‡æ¬¡æ•°',
                    ['type']  # type: internal/external
                )
                self.metrics_second_layer_check = Counter(
                    'bsc_second_layer_check_total', 
                    'ç¬¬äºŒå±‚æ£€æŸ¥æ¬¡æ•°',
                    ['type']  # type: internal/external
                )
                self.metrics_second_layer_pass = Counter(
                    'bsc_second_layer_pass_total', 
                    'ç¬¬äºŒå±‚æ£€æŸ¥é€šè¿‡æ¬¡æ•°',
                    ['type']  # type: internal/external
                )
                self.metrics_alerts = Counter(
                    'bsc_alerts_total', 
                    'å‘Šè­¦å‘é€æ¬¡æ•°',
                    ['status']  # status: success/failure
                )
                self.metrics_cache_hits = Counter(
                    'bsc_cache_hits_total', 
                    'ç¼“å­˜å‘½ä¸­æ¬¡æ•°',
                    ['cache_type']  # cache_type: receipt/eth_call/non_fourmeme
                )
                self.metrics_fallback = Counter(
                    'bsc_time_window_fallback_total',
                    'æ—¶é—´çª—å£é€€è®©æ¬¡æ•°',
                    ['original', 'fallback']  # 1m->5m, 5m->1h
                )
                
                # Gaugeï¼ˆä»ªè¡¨ï¼‰- å¯å¢å¯å‡
                self.metrics_connections = Gauge(
                    'bsc_websocket_connections', 
                    'WebSocketè¿æ¥æ•°'
                )
                self.metrics_cache_size = Gauge(
                    'bsc_cache_size', 
                    'ç¼“å­˜å¤§å°',
                    ['cache_type']  # cache_type: seen_txs/receipt/eth_call
                )
                
                # Histogramï¼ˆç›´æ–¹å›¾ï¼‰- å»¶è¿Ÿåˆ†å¸ƒ
                self.metrics_processing_time = Histogram(
                    'bsc_processing_seconds',
                    'äº‹ä»¶å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰',
                    buckets=(0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0)
                )
                
                logger.info("âœ… Prometheus Metrics å·²å¯ç”¨")
            except Exception as e:
                logger.error(f"âŒ Prometheus Metrics åˆå§‹åŒ–å¤±è´¥: {e}")
                HAS_PROMETHEUS = False
        else:
            logger.warning("âš ï¸ Prometheus Metrics æœªå®‰è£…")
        
    async def load_config_from_redis(self):
        """ä» Redis åŠ è½½é…ç½®"""
        try:
            # åŠ è½½å†…ç›˜é…ç½®
            internal_data = await asyncio.to_thread(
                self.redis_client.client.get, 'global_monitor:config:bsc:internal'
            )
            if internal_data:
                if isinstance(internal_data, bytes):
                    internal_data = internal_data.decode('utf-8')
                
                # æ¸…ç† Java ç±»å‹æ ‡è®°

                internal_data = re.sub(r'"@type"\s*:\s*"[^"]*"\s*,?\s*', '', internal_data)
                internal_data = re.sub(r':\s*(\d+)L\b', r':\1', internal_data)
                internal_data = re.sub(r',\s*}', '}', internal_data)
                
                config = json.loads(internal_data)
                self.min_amount_internal = config.get('min_transaction_usd', 200)
                self.cumulative_min_amount_internal = config.get('cumulative_min_amount_usd', 500)
                self.time_interval_internal = config.get('timeInterval', '1m')  # å†…ç›˜æ—¶é—´é—´éš”
                self.trigger_logic_internal = config.get('triggerLogic', 'any')  # å†…ç›˜è§¦å‘é€»è¾‘
                
                logger.info(f"ğŸ“Š å†…ç›˜é…ç½®: å•ç¬”>={self.min_amount_internal}U, ç´¯è®¡>={self.cumulative_min_amount_internal}U, æ—¶é—´é—´éš”={self.time_interval_internal}")
                # topHoldersThresholdï¼šå¦‚æœé…ç½®äº†å°±å¯ç”¨æ£€æŸ¥ï¼Œå¦åˆ™ä¸ºNoneï¼ˆä¸æ£€æŸ¥ï¼‰
                threshold = config.get('topHoldersThreshold')
                self.top_holders_threshold_internal = float(threshold) if threshold is not None else None
                
                events_config_str = config.get('eventsConfig', '{}')
                if events_config_str:
                    try:
                        if isinstance(events_config_str, str):
                            loaded_config = json.loads(events_config_str)
                        else:
                            loaded_config = events_config_str
                        
                        # åªåœ¨æœ‰æœ‰æ•ˆé…ç½®æ—¶æ‰è¦†ç›–é»˜è®¤å€¼
                        if loaded_config and isinstance(loaded_config, dict):
                            self.internal_events_config = loaded_config
                            
                            # ç¡®ä¿ enabled å­—æ®µ
                            if 'priceChange' in self.internal_events_config:
                                self.internal_events_config['priceChange']['enabled'] = True
                            if 'volume' in self.internal_events_config:
                                self.internal_events_config['volume']['enabled'] = True
                    except:
                        pass  # ä¿ç•™é»˜è®¤å€¼
            
            # åŠ è½½å¤–ç›˜é…ç½®
            external_data = await asyncio.to_thread(
                self.redis_client.client.get, 'global_monitor:config:bsc:external'
            )
            if external_data:
                if isinstance(external_data, bytes):
                    external_data = external_data.decode('utf-8')
                
                # æ¸…ç† Java ç±»å‹æ ‡è®°
                external_data = re.sub(r'"@type"\s*:\s*"[^"]*"\s*,?\s*', '', external_data)
                external_data = re.sub(r':\s*(\d+)L\b', r':\1', external_data)
                external_data = re.sub(r',\s*}', '}', external_data)
                
                config = json.loads(external_data)
                self.min_amount_external = config.get('min_transaction_usd', 400)
                self.cumulative_min_amount_external = config.get('cumulative_min_amount_usd', 1000)  
                self.time_interval_external = config.get('timeInterval', '5m')  # å¤–ç›˜æ—¶é—´é—´éš”
                self.trigger_logic_external = config.get('triggerLogic', 'any')  # å¤–ç›˜è§¦å‘é€»è¾‘
                
                logger.info(f"ğŸ“Š å¤–ç›˜é…ç½®: å•ç¬”>={self.min_amount_external}U, ç´¯è®¡>={self.cumulative_min_amount_external}U, æ—¶é—´é—´éš”={self.time_interval_external}")
                
                # topHoldersThresholdï¼šå¦‚æœé…ç½®äº†å°±å¯ç”¨æ£€æŸ¥ï¼Œå¦åˆ™ä¸ºNoneï¼ˆä¸æ£€æŸ¥ï¼‰
                threshold = config.get('topHoldersThreshold')
                self.top_holders_threshold_external = float(threshold) if threshold is not None else None  
                
                events_config_str = config.get('eventsConfig', '{}')
                if events_config_str:
                    try:
                        if isinstance(events_config_str, str):
                            loaded_config = json.loads(events_config_str)
                        else:
                            loaded_config = events_config_str
                        
                        # åªåœ¨æœ‰æœ‰æ•ˆé…ç½®æ—¶æ‰è¦†ç›–é»˜è®¤å€¼
                        if loaded_config and isinstance(loaded_config, dict):
                            self.external_events_config = loaded_config
                            
                            # ç¡®ä¿ enabled å­—æ®µ
                            if 'priceChange' in self.external_events_config:
                                self.external_events_config['priceChange']['enabled'] = True
                            if 'volume' in self.external_events_config:
                                self.external_events_config['volume']['enabled'] = True
                    except:
                        pass  # ä¿ç•™é»˜è®¤å€¼

        except Exception as e:
            logger.error(f"âŒ åŠ è½½ Redis é…ç½®å¤±è´¥: {e}")
        
        # è®¡ç®—å…¨å±€æœ€å°é‡‘é¢é˜ˆå€¼ï¼ˆç”¨äºæå‰è¿‡æ»¤ï¼‰
        self.global_min_amount = min(self.min_amount_internal, self.min_amount_external)
        logger.info(f"ğŸ” å…¨å±€æœ€å°è¿‡æ»¤é˜ˆå€¼: {self.global_min_amount}Uï¼ˆå–å†…å¤–ç›˜æœ€å°å€¼ï¼Œæå‰è¿‡æ»¤å°é¢äº¤æ˜“ï¼‰")
        
        # æ‰“å°æœ€ç»ˆé…ç½®ä¿¡æ¯
        logger.info(f"ğŸ“Š å†…ç›˜é…ç½®: å•ç¬”>={self.min_amount_internal}U, ç´¯è®¡>={self.cumulative_min_amount_internal}U, æ¶¨å¹…>={self.internal_events_config.get('priceChange', {}).get('risePercent')}%, äº¤æ˜“é‡>=${self.internal_events_config.get('volume', {}).get('threshold')}, è§¦å‘é€»è¾‘={self.trigger_logic_internal}")
        logger.info(f"ğŸ“Š å¤–ç›˜é…ç½®: å•ç¬”>={self.min_amount_external}U, ç´¯è®¡>={self.cumulative_min_amount_external}U, æ¶¨å¹…>={self.external_events_config.get('priceChange', {}).get('risePercent')}%, äº¤æ˜“é‡>=${self.external_events_config.get('volume', {}).get('threshold')}, è§¦å‘é€»è¾‘={self.trigger_logic_external}")
        
        # æ€§èƒ½ä¼˜åŒ–è¯´æ˜
        logger.info("âœ¨ æ€§èƒ½ä¼˜åŒ–: å·²å¯ç”¨ä¸‰å±‚ç¼“å­˜æ¶æ„ (L1: å†…å­˜LRU / L2: RedisæŒä¹…åŒ– / L3: Multicall3æ‰¹é‡æŸ¥è¯¢)")
        logger.info(f"âœ¨ Multicall3: {self.MULTICALL2_ADDRESS} (è·¨é“¾é€šç”¨åœ°å€)")
        logger.info(f"âœ¨ eth-abi çŠ¶æ€: {'âœ… å·²å®‰è£…' if HAS_ETH_ABI else 'âŒ æœªå®‰è£…ï¼ˆå°†ä½¿ç”¨æ‰‹åŠ¨ç¼–ç ï¼‰'}")
        logger.info("âœ¨ æ”¯æŒä»£å¸: USDT, USDC, WBNB (å¯æ‰©å±•)")
        logger.info("âœ¨ ä¼˜åŒ–æ•ˆæœ: ç¼“å­˜å‘½ä¸­0æ¬¡RPC / å…¨missä»…1æ¬¡Multicall3 (vs æ—§ç‰ˆ6æ¬¡eth_call)")
        
        # é¢„åŠ è½½ WBNB ä»·æ ¼ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        self.wbnb_price = await asyncio.to_thread(self.get_wbnb_price)
        logger.info(f"ğŸ’° WBNB ä»·æ ¼: ${self.wbnb_price:.2f}")
        
        # ç»Ÿè®¡éfourmemeç¼“å­˜å¤§å°å¹¶ç¡®ä¿TTL
        self.NON_FOURMEME_KEY = "bsc:non_fourmeme_tokens"
        self.NON_FOURMEME_TTL = 30 * 24 * 3600  # 30å¤©
        
        if self.redis_client:
            try:
                cache_size = self.redis_client.scard(self.NON_FOURMEME_KEY)
                # ç¡®ä¿ç¼“å­˜æœ‰è¿‡æœŸæ—¶é—´ï¼ˆé˜²æ­¢æ°¸ä¹…å­˜å‚¨ï¼‰
                ttl = self.redis_client.client.ttl(self.NON_FOURMEME_KEY)
                if ttl == -1:  # -1 è¡¨ç¤ºæ²¡æœ‰è¿‡æœŸæ—¶é—´
                    self.redis_client.client.expire(self.NON_FOURMEME_KEY, self.NON_FOURMEME_TTL)
                    logger.info(f"ğŸ“Š éfourmemeç¼“å­˜: {cache_size} ä¸ªtoken (å·²è®¾ç½®30å¤©è¿‡æœŸ)")
                else:
                    logger.info(f"ğŸ“Š éfourmemeç¼“å­˜: {cache_size} ä¸ªtoken (å‰©ä½™{ttl // 86400}å¤©)")
            except Exception as e:
                logger.debug(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
    
    def get_thread_dbotx_api(self) -> DBotXAPI:
        """è·å–å½“å‰çº¿ç¨‹çš„ DBotX API å®ä¾‹"""
        if not hasattr(self.thread_local, 'dbotx_api'):
            self.thread_local.dbotx_api = DBotXAPI()
        return self.thread_local.dbotx_api
    
    def get_receipt_cached(self, tx_hash: str) -> tuple:
        """
        è·å–äº¤æ˜“å›æ‰§ï¼ˆå¸¦ç¼“å­˜ï¼Œå¹¶å‘ä¿æŠ¤ï¼Œå¤±è´¥ç¼“å­˜ï¼‰
        
        ä¼˜åŒ–ï¼š
        1. LoadingçŠ¶æ€ï¼šé˜²æ­¢å¤šä¸ªçº¿ç¨‹åŒæ—¶æ‹‰å–åŒä¸€äº¤æ˜“
        2. Eventç­‰å¾…ï¼šåç»­çº¿ç¨‹ç­‰å¾…ç¬¬ä¸€ä¸ªçº¿ç¨‹å®Œæˆ
        3. å¤±è´¥ç¼“å­˜ï¼šRPCå¤±è´¥æ—¶ç¼“å­˜5ç§’ï¼Œé¿å…é£æš´å¼é‡è¯•
        4. è¯¦ç»†ç»Ÿè®¡ï¼šhits/misses/waits/failed_hits
        
        Returns:
            (receipt, tx_info) æˆ– (None, None) å¦‚æœå¤±è´¥
        """
        now = time.time()
        event_to_wait = None
        
        # === é˜¶æ®µ1: æ£€æŸ¥ç¼“å­˜ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰ ===
        with self.receipt_cache_lock:
            if tx_hash in self.receipt_cache:
                cached_data = self.receipt_cache[tx_hash]
                status = cached_data.get("status", "ready")
                cached_at = cached_data.get("cached_at", 0)
                
                # æƒ…å†µ1: æ­£åœ¨åŠ è½½ä¸­ â†’ å…¶ä»–çº¿ç¨‹æ­£åœ¨æ‹‰å–ï¼Œç­‰å¾…å®ƒå®Œæˆ
                if status == "loading":
                    event_to_wait = cached_data.get("event")
                    self.receipt_cache_concurrent_waits += 1
                    logger.info(f"â³ å¹¶å‘ç­‰å¾…ï¼ˆå…¶ä»–çº¿ç¨‹æ­£åœ¨æ‹‰å–ï¼‰: {tx_hash[:10]}... (ç­‰å¾…#{self.receipt_cache_concurrent_waits})")
                
                # æƒ…å†µ2: æˆåŠŸç¼“å­˜ï¼Œæœªè¿‡æœŸ
                elif status == "ready" and now - cached_at < self.receipt_cache_ttl:
                    receipt = cached_data.get("receipt")
                    tx_info = cached_data.get("tx_info")
                    
                    # éªŒè¯æ•°æ®å®Œæ•´æ€§
                    if receipt and isinstance(receipt, dict) and receipt.get("logs"):
                        self.receipt_cache_hits += 1
                        if HAS_PROMETHEUS:
                            self.metrics_cache_hits.labels(cache_type='receipt').inc()
                        logger.debug(f"âœ… å›æ‰§ç¼“å­˜å‘½ä¸­: {tx_hash[:10]}... (å‘½ä¸­#{self.receipt_cache_hits})")
                        return receipt, tx_info
                    else:
                        # è„æ•°æ®ï¼Œåˆ é™¤
                        logger.debug(f"âš ï¸ è„æ•°æ®ï¼Œé‡æ–°æ‹‰å–: {tx_hash[:10]}...")
                        del self.receipt_cache[tx_hash]
                
                # æƒ…å†µ3: å¤±è´¥ç¼“å­˜ï¼Œæœªè¿‡æœŸ â†’ é¿å…çŸ­æœŸå†…é‡è¯•
                elif status == "failed" and now - cached_at < self.receipt_cache_failed_ttl:
                    self.receipt_cache_failed_hits += 1
                    logger.debug(f"ğŸš« å¤±è´¥ç¼“å­˜å‘½ä¸­ï¼ˆè·³è¿‡é‡è¯•ï¼‰: {tx_hash[:10]}... (å¤±è´¥ç¼“å­˜#{self.receipt_cache_failed_hits})")
                    return None, None
                
                # æƒ…å†µ4: è¿‡æœŸï¼Œåˆ é™¤
                else:
                    del self.receipt_cache[tx_hash]
        
        # === é˜¶æ®µ2: å¦‚æœéœ€è¦ç­‰å¾…å…¶ä»–çº¿ç¨‹ ===
        if event_to_wait:
            # OPTIMIZED: ç­‰å¾…5ç§’é€‚é…NodeRealé«˜å»¶è¿Ÿ
            wait_start = time.time()
            wait_result = event_to_wait.wait(timeout=5)
            wait_elapsed = time.time() - wait_start
            
            # ç»Ÿè®¡ç­‰å¾…è€—æ—¶
            self.receipt_cache_wait_time_total += wait_elapsed
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if not wait_result or wait_elapsed >= 5.5:  # æ¥è¿‘6ç§’è§†ä¸ºè¶…æ—¶
                self.receipt_cache_wait_timeouts += 1
                logger.warning(
                    f"âš ï¸ å¹¶å‘ç­‰å¾…è¶…æ—¶: {tx_hash[:10]}... (è€—æ—¶{wait_elapsed:.2f}s, "
                    f"è¶…æ—¶#{self.receipt_cache_wait_timeouts}æ¬¡ï¼Œå°†è‡ªè¡Œæ‹‰å–)"
                )
            else:
                logger.info(f"âœ… å¹¶å‘ç­‰å¾…å®Œæˆ: {tx_hash[:10]}... (è€—æ—¶{wait_elapsed:.2f}s)")
            
            # ç­‰å¾…å®Œæˆåï¼Œå†æ¬¡å°è¯•è¯»ç¼“å­˜
            with self.receipt_cache_lock:
                if tx_hash in self.receipt_cache:
                    cached_data = self.receipt_cache[tx_hash]
                    if cached_data.get("status") == "ready":
                        receipt = cached_data.get("receipt")
                        tx_info = cached_data.get("tx_info")
                        if receipt:
                            logger.info(f"âœ… ç­‰å¾…åè·å–ç»“æœæˆåŠŸ: {tx_hash[:10]}...")
                            return receipt, tx_info
            
            # å¦‚æœç­‰å¾…åä»æœªè·å–åˆ°ï¼Œè¯´æ˜ç¬¬ä¸€ä¸ªçº¿ç¨‹å¤±è´¥äº†ï¼Œç»§ç»­åç»­æµç¨‹
            logger.warning(f"âš ï¸ ç­‰å¾…åä»æœªè·å–åˆ°æ•°æ®ï¼Œè‡ªè¡Œæ‹‰å–: {tx_hash[:10]}...")
        
        # === é˜¶æ®µ3: ç¼“å­˜æœªå‘½ä¸­ï¼Œå ä½å¹¶æ‹‰å– ===
        loading_event = threading.Event()
        
        with self.receipt_cache_lock:
            # åŒé‡æ£€æŸ¥ï¼šå¯èƒ½åˆšæ‰ç­‰å¾…æ—¶å…¶ä»–çº¿ç¨‹å·²å†™å…¥
            if tx_hash in self.receipt_cache and self.receipt_cache[tx_hash].get("status") == "ready":
                cached_data = self.receipt_cache[tx_hash]
                receipt = cached_data.get("receipt")
                tx_info = cached_data.get("tx_info")
                if receipt:
                    return receipt, tx_info
            
            # è®¾ç½® loading çŠ¶æ€ï¼ˆå ä½ï¼‰
            self.receipt_cache[tx_hash] = {
                "status": "loading",
                "event": loading_event,
                "cached_at": now
            }
            self.receipt_cache_misses += 1
            logger.debug(f"ğŸ” å›æ‰§ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨RPC: {tx_hash[:10]}... (æœªå‘½ä¸­#{self.receipt_cache_misses})")
        
        # === é˜¶æ®µ4: é”å¤–æ‰§è¡Œ RPCï¼ˆé¿å…é˜»å¡ï¼‰ ===
        try:
            receipt = self.rpc_call("eth_getTransactionReceipt", [tx_hash])
            tx_info = self.rpc_call("eth_getTransactionByHash", [tx_hash])
            
            # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
            success = receipt and isinstance(receipt, dict) and receipt.get("logs")
            
            # å†™å…¥ç¼“å­˜
            with self.receipt_cache_lock:
                if success:
                    # æˆåŠŸï¼šç¼“å­˜ 5 åˆ†é’Ÿ
                    self.receipt_cache[tx_hash] = {
                        "status": "ready",
                        "receipt": receipt,
                        "tx_info": tx_info,
                        "cached_at": now,
                        "event": None
                    }
                else:
                    # å¤±è´¥ï¼šç¼“å­˜ 5 ç§’ï¼ˆé˜²æ­¢é£æš´å¼é‡è¯•ï¼‰
                    self.receipt_cache[tx_hash] = {
                        "status": "failed",
                        "receipt": None,
                        "tx_info": None,
                        "cached_at": now,
                        "event": None
                    }
                    logger.debug(f"âŒ RPCå¤±è´¥ï¼Œç¼“å­˜å¤±è´¥çŠ¶æ€5ç§’: {tx_hash[:10]}...")
                
                # æ¸…ç†è¿‡æœŸç¼“å­˜
                if len(self.receipt_cache) > 5000:
                    to_delete = [
                        k for k, v in self.receipt_cache.items()
                        if now - v.get("cached_at", 0) > max(self.receipt_cache_ttl, self.receipt_cache_failed_ttl)
                    ]
                    for k in to_delete:
                        del self.receipt_cache[k]
                    if to_delete:
                        logger.debug(f"ğŸ§¹ æ¸…ç†è¿‡æœŸå›æ‰§ç¼“å­˜: {len(to_delete)} æ¡")
            
            # é€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹
            loading_event.set()
            
            return receipt, tx_info
            
        except Exception as e:
            logger.debug(f"âŒ RPCå¼‚å¸¸: {tx_hash[:10]}... - {e}")
            
            # å¼‚å¸¸ä¹Ÿç¼“å­˜ä¸ºå¤±è´¥çŠ¶æ€
            with self.receipt_cache_lock:
                self.receipt_cache[tx_hash] = {
                    "status": "failed",
                    "receipt": None,
                    "tx_info": None,
                    "cached_at": now,
                    "event": None
                }
            
            loading_event.set()
            return None, None
    
    def cached_eth_call(self, to: str, data: str):
        """
        å¸¦ç¼“å­˜çš„ eth_callï¼ˆç”¨äºä»£å¸ä¿¡æ¯æŸ¥è¯¢ï¼‰
        
        ä¼˜åŒ–ï¼š
        - ç¼“å­˜ decimals/symbol ç­‰ä¸å˜çš„æ•°æ®
        - USDT/WBNBç­‰å¸¸è§ä»£å¸100%å‘½ä¸­
        - å‡å°‘30-50% eth_call
        """
        cache_key = (to.lower(), data.lower())
        now = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        with self.eth_call_cache_lock:
            if cache_key in self.eth_call_cache:
                result, cached_at = self.eth_call_cache[cache_key]
                if now - cached_at < self.eth_call_cache_ttl:
                    self.eth_call_cache_hits += 1
                    return result
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨RPC
        result = self.rpc_call("eth_call", [{"to": to, "data": data}, "latest"])
        
        # å†™å…¥ç¼“å­˜
        if result:  # åªç¼“å­˜æˆåŠŸçš„ç»“æœ
            with self.eth_call_cache_lock:
                self.eth_call_cache[cache_key] = (result, now)
                
                # æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
                if len(self.eth_call_cache) > 5000:
                    to_delete = [
                        k for k, (_, t) in self.eth_call_cache.items()
                        if now - t > self.eth_call_cache_ttl
                    ]
                    for k in to_delete:
                        del self.eth_call_cache[k]
        
        return result
    
    def rpc_call(self, method: str, params: list):
        """
        å‘é€ HTTP RPC è¯·æ±‚ï¼ˆå¸¦429å¤„ç† + æ…¢è°ƒç”¨ç›‘æ§ï¼‰
        
        ä¼˜åŒ–ï¼š
        1. æœ€å°é—´éš”ï¼šè±¡å¾æ€§1msé—´éš”ï¼ˆChainstackæ— é™åˆ¶ï¼‰
        2. 429æ£€æµ‹ï¼šæ£€æµ‹é™æµé”™è¯¯å¹¶æŒ‡æ•°é€€é¿
        3. é€€é¿æœºåˆ¶ï¼šè¿ç»­429æ—¶å»¶é•¿é€€é¿æ—¶é—´ï¼ˆæœ€é«˜16sï¼‰
        4. ç»Ÿè®¡ç›‘æ§ï¼šè®°å½•429æ¬¡æ•°å’Œæ…¢è°ƒç”¨
        """
        self.rpc_id += 1
        
        # === é˜¶æ®µ1: é€Ÿç‡é™åˆ¶ï¼ˆé˜²æ­¢429ï¼‰ ===
        with self.rate_limit_lock:
            # æ£€æŸ¥æ˜¯å¦åœ¨é€€é¿æœŸå†…
            now = time.time()
            if now < self.rate_limit_backoff_until:
                backoff_wait = self.rate_limit_backoff_until - now
                logger.warning(f"â¸ï¸  é€Ÿç‡é™åˆ¶é€€é¿ä¸­ï¼Œç­‰å¾… {backoff_wait:.2f}s...")
                time.sleep(backoff_wait)
            
            # é™åˆ¶æœ€å°è¯·æ±‚é—´éš”
            elapsed_since_last = now - self.last_rpc_time
            if elapsed_since_last < self.min_rpc_interval:
                time.sleep(self.min_rpc_interval - elapsed_since_last)
            
            self.last_rpc_time = time.time()
        
        # === é˜¶æ®µ2: å‘é€RPCè¯·æ±‚ ===
        start_time = time.time()
        self.rpc_stats[method] = self.rpc_stats.get(method, 0) + 1
        
        try:
            resp = self.session.post(
                self.rpc_url,
                json={"jsonrpc": "2.0", "id": self.rpc_id, "method": method, "params": params},
                timeout=10
            )
            
            # === é˜¶æ®µ3: æ£€æŸ¥429é™æµ ===
            if resp.status_code == 429:
                self.rate_limit_429_count += 1
                self.rate_limit_consecutive_429 += 1
                
                # æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s, 8s, æœ€é«˜16s
                backoff_time = min(2 ** self.rate_limit_consecutive_429, 16)
                self.rate_limit_backoff_until = time.time() + backoff_time
                
                logger.warning(
                    f"ğŸš« é‡åˆ°429é™æµ (ç´¯è®¡#{self.rate_limit_429_count}, è¿ç»­#{self.rate_limit_consecutive_429}æ¬¡), "
                    f"é€€é¿ {backoff_time}s, method={method}"
                )
                
                # è¿”å›Noneï¼Œè®©ä¸Šå±‚ç¼“å­˜ä¸ºfailedçŠ¶æ€
                return None
            
            # === é˜¶æ®µ4: æˆåŠŸå“åº”ï¼Œé‡ç½®è¿ç»­429è®¡æ•° ===
            if resp.status_code == 200:
                self.rate_limit_consecutive_429 = 0  # é‡ç½®è¿ç»­429è®¡æ•°
            
            result = resp.json().get("result")
            
            # === é˜¶æ®µ5: æ…¢è°ƒç”¨ç›‘æ§ ===
            latency = time.time() - start_time
            if latency > 1.0:
                logger.warning("RPCæ…¢è°ƒç”¨", extra={
                    "method": method,
                    "latency": f"{latency:.2f}s",
                    "params_count": len(params)
                })
            
            return result
            
        except Exception as e:
            latency = time.time() - start_time
            logger.debug(f"RPC é”™è¯¯: {e}", extra={
                "method": method,
                "latency": f"{latency:.2f}s"
            })
            return None
    
    def multicall2_try_aggregate(self, calls: list) -> list:
        """
        ä½¿ç”¨ Multicall2.tryAggregate æ‰¹é‡æŸ¥è¯¢
        ä¼˜å…ˆä½¿ç”¨ eth_abiï¼Œæ— åº“æ—¶ä½¿ç”¨ä¿®æ­£åçš„æ‰‹åŠ¨ç¼–ç 
        
        Args:
            calls: [(target_address, calldata), ...] è°ƒç”¨åˆ—è¡¨
        
        Returns:
            [result1, result2, ...] ç»“æœåˆ—è¡¨ï¼ˆå¤±è´¥è¿”å› Noneï¼‰
        """
        if not calls:
            return []
        
        try:
            # è·¯å¾„1: ä½¿ç”¨ eth_abiï¼ˆæ¨èï¼Œç»“æ„å‡†ç¡®ï¼‰
            if HAS_ETH_ABI:
                # tryAggregate(bool requireSuccess, (address,bytes)[] calls)
                call_tuples = []
                for target, calldata in calls:
                    target_bytes = bytes.fromhex(target[2:] if target.startswith('0x') else target)
                    calldata_bytes = bytes.fromhex(calldata[2:] if calldata.startswith('0x') else calldata)
                    call_tuples.append((target_bytes, calldata_bytes))
                
                # ç¼–ç å‚æ•°ï¼šrequireSuccess=false, calls
                encoded_args = eth_abi_encode(
                    ['bool', '(address,bytes)[]'],
                    [False, call_tuples]
                )
                
                # æ„å»ºå®Œæ•´çš„ calldata
                full_calldata = self.MULTICALL2_TRY_AGGREGATE_SELECTOR + encoded_args.hex()
                
                # è°ƒç”¨ Multicall2
                result = self.rpc_call("eth_call", [{
                    "to": self.MULTICALL2_ADDRESS,
                    "data": "0x" + full_calldata
                }, "latest"])
                
                if not result or result == "0x":
                    logger.warning(f"âš ï¸ Multicall2 è¿”å›ç©ºç»“æœ (eth_abi)ï¼Œå›é€€åˆ°é€ä¸ªè°ƒç”¨")
                    logger.debug(f"è°ƒç”¨æ•°é‡: {len(calls)}, Calldataé•¿åº¦: {len(full_calldata)}")
                    return self._fallback_individual_calls(calls)
                
                # è§£ç ç»“æœ
                try:
                    result_bytes = bytes.fromhex(result[2:] if result.startswith('0x') else result)
                    decoded = eth_abi_decode(['(bool,bytes)[]'], result_bytes)[0]
                    
                    results = []
                    for success, return_data in decoded:
                        if success and return_data:
                            results.append('0x' + return_data.hex())
                        else:
                            results.append(None)
                    
                    logger.info(f"âœ… Multicall2 æ‰¹é‡æŸ¥è¯¢æˆåŠŸ (eth_abi): {len(results)} ä¸ªè°ƒç”¨")
                    return results
                except Exception as decode_error:
                    logger.warning(f"âš ï¸ eth_abi è§£ç å¤±è´¥: {decode_error}, å›é€€åˆ°é€ä¸ªè°ƒç”¨")
                    return self._fallback_individual_calls(calls)
            
            # è·¯å¾„2: æ‰‹åŠ¨ç¼–ç ï¼ˆä¿®æ­£åï¼Œæ— ä¾èµ–ï¼‰
            sig = "bce38bd7"  # tryAggregate selector
            ignore_results = "00" * 32  # bool False (32 bytes)
            
            # Array offset: 0x20 (after bool)
            array_offset = format(0x20, '064x')  # 32 bytes padded
            
            # Array length
            array_len_hex = format(len(calls), '064x')
            
            # Array data: å¯¹äº tuple[] ç±»å‹ï¼Œéœ€è¦åµŒå¥—åç§»
            # æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª tupleï¼ŒåŒ…å« address + bytesï¼ˆåŠ¨æ€ï¼‰
            # ç»“æ„ï¼š[offset1, offset2, ...] + [tuple1_data, tuple2_data, ...]
            
            tuple_offsets = []
            tuple_contents = []
            
            # åç§»åŸºå‡†ï¼šlen(calls) * 32ï¼ˆæ¯ä¸ªåç§»å 32å­—èŠ‚ï¼‰
            base_offset = len(calls) * 32
            current_offset = base_offset
            
            for target, calldata in calls:
                target_clean = target[2:] if target.startswith('0x') else target
                calldata_clean = calldata[2:] if calldata.startswith('0x') else calldata
                
                # è®°å½•å½“å‰ tuple çš„åç§»
                tuple_offsets.append(format(current_offset, '064x'))
                
                # æ„å»º tuple å†…å®¹ï¼šaddress (32b) + bytes_offset (0x20) + bytes_len + bytes_data
                address_padded = target_clean.zfill(64)  # 32 bytes
                bytes_offset_in_tuple = format(0x20, '064x')  # bytes åœ¨ tuple å†…åç§» 32 å­—èŠ‚ï¼ˆaddress åï¼‰
                
                calldata_len = len(calldata_clean) // 2
                calldata_len_hex = format(calldata_len, '064x')
                calldata_full = calldata_clean  # åŠ¨æ€æ•°æ®ï¼Œä¸éœ€è¦ padding
                
                tuple_content = address_padded + bytes_offset_in_tuple + calldata_len_hex + calldata_full
                tuple_contents.append(tuple_content)
                
                # æ›´æ–°åç§»ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰
                current_offset += len(tuple_content) // 2
            
            # ç»„è£…æ•°ç»„æ•°æ®
            array_data = "".join(tuple_offsets) + "".join(tuple_contents)
            
            # å®Œæ•´ç¼–ç 
            encoded_args = ignore_results + array_offset + array_len_hex + array_data
            full_data = sig + encoded_args
            
            # è°ƒç”¨ RPC
            result = self.rpc_call("eth_call", [{
                "to": self.MULTICALL2_ADDRESS,
                "data": "0x" + full_data
            }, "latest"])
            
            if not result or result == "0x":
                logger.warning("âš ï¸ Multicall2 è¿”å›ç©ºç»“æœ (manual)ï¼Œå›é€€åˆ°é€ä¸ªè°ƒç”¨")
                logger.debug(f"Full data len: {len(full_data)}, first 100: {full_data[:100]}")
                return self._fallback_individual_calls(calls)
            
            # æ‰‹åŠ¨è§£æè¿”å›å€¼: (bool success, bytes returnData)[] æ•°ç»„
            result_hex = result[2:] if result.startswith('0x') else result
            
            # æ•°ç»„åç§»ï¼ˆé€šå¸¸æ˜¯0x20ï¼‰
            array_start = int(result_hex[0:64], 16) * 2
            # æ•°ç»„é•¿åº¦
            array_len = int(result_hex[array_start:array_start+64], 16)
            
            results = []
            offset = array_start + 64  # è·³è¿‡é•¿åº¦å­—æ®µ
            
            # è¯»å–æ¯ä¸ªå…ƒç´ çš„åç§»ï¼ˆç›¸å¯¹äºæ•°ç»„å¼€å§‹ä½ç½®ï¼‰
            result_offsets = []
            for i in range(array_len):
                elem_offset = int(result_hex[offset:offset+64], 16) * 2
                result_offsets.append(array_start + elem_offset)
                offset += 64
            
            # è§£ææ¯ä¸ª (bool, bytes) tuple
            for elem_offset in result_offsets:
                success = int(result_hex[elem_offset:elem_offset+64], 16)
                bytes_offset = int(result_hex[elem_offset+64:elem_offset+128], 16) * 2
                bytes_start = elem_offset + bytes_offset
                bytes_len = int(result_hex[bytes_start:bytes_start+64], 16)
                
                if success == 1 and bytes_len > 0:
                    ret_data = "0x" + result_hex[bytes_start+64:bytes_start+64+bytes_len*2]
                    results.append(ret_data)
                else:
                    results.append(None)
            
            logger.info(f"âœ… Multicall2 æ‰¹é‡æŸ¥è¯¢æˆåŠŸ (manual): {len(results)} ä¸ªè°ƒç”¨")
            return results
            
        except Exception as e:
            logger.warning(f"âš ï¸ Multicall2 è°ƒç”¨å¤±è´¥: {e}, å›é€€åˆ°é€ä¸ªè°ƒç”¨")
            logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return self._fallback_individual_calls(calls)
    
    def _fallback_individual_calls(self, calls: list) -> list:
        """å›é€€æ–¹æ¡ˆï¼šé€ä¸ªè°ƒç”¨"""
        results = []
        for target, calldata in calls:
            try:
                result = self.rpc_call("eth_call", [{
                    "to": target,
                    "data": calldata
                }, "latest"])
                results.append(result)
            except Exception as e:
                logger.debug(f"è°ƒç”¨å¤±è´¥ {target}: {e}")
                results.append(None)
        return results
    
    def _extract_pair_from_receipt(self, logs: list) -> str:
        """ä» receipt logs ä¸­æå– PancakeV2 Pair åœ°å€"""
        try:
            swap_topic = "0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822"
            for log in logs:
                topics = log.get("topics", [])
                if topics and topics[0] == swap_topic:
                    # Swap äº‹ä»¶çš„åœ°å€å°±æ˜¯ Pair åœ°å€
                    return log.get("address", "").lower()
        except Exception as e:
            logger.debug(f"æå– pair å¤±è´¥: {e}")
        return None
    
    def get_wbnb_price(self) -> float:
        """åŠ¨æ€è·å– WBNB ä»·æ ¼ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        now = time.time()
        if now - self.wbnb_price_timestamp < self.price_cache_ttl:
            return self.wbnb_price
        
        try:
            # ç¦ç”¨ SSL è­¦å‘Š
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
            
            # ä½¿ç”¨é•¿è¿æ¥ï¼ˆSessionï¼‰
            resp = self.session.get(
                'https://api.gateio.ws/api/v4/spot/tickers?currency_pair=BNB_USDT',
                timeout=5,
                verify=False  # ç¦ç”¨ SSL è¯ä¹¦éªŒè¯
            )
            data = resp.json()
            
            if data and isinstance(data, list) and len(data) > 0:
                price = float(data[0].get('last', self.wbnb_price))
                self.wbnb_price = price
                self.wbnb_price_timestamp = now
                logger.info(f"âœ… æ›´æ–° WBNB ä»·æ ¼: ${price}")
                return price
        except Exception as e:
            logger.warning(f"âš ï¸ è·å– WBNB ä»·æ ¼å¤±è´¥: {e}")
        
        return self.wbnb_price
    
    @lru_cache(maxsize=10000)
    def get_decimals(self, token: str) -> int:
        """è·å–ä»£å¸ç²¾åº¦ï¼ˆL1 å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜ + L3 é“¾ä¸ŠæŸ¥è¯¢ï¼‰"""
        # L1: LRU Cache å·²é€šè¿‡è£…é¥°å™¨å¤„ç†
        
        try:
            # L2: Redis ç¼“å­˜
            redis_key = f"token:{token}:decimals"
            cached_value = self.redis_client.client.get(redis_key)
            if cached_value:
                try:
                    value = int(cached_value)
                    return value
                except:
                    pass
            
            # L3: é“¾ä¸ŠæŸ¥è¯¢ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            data = self.cached_eth_call(token, "0x313ce567")
            
            result = int(data, 16) if data else 18
            
            # å†™å…¥ Redis (TTL=1å¤©)
            try:
                self.redis_client.client.setex(redis_key, 86400, str(result))
            except:
                pass
            
            return result
        except:
            return 18
    
    def parse_symbol_data(self, data: str) -> str:
        """è§£æ symbol() è¿”å›çš„æ•°æ®"""
        if not data or data == "0x":
            return "???"
        
        try:
            hex_data = data[2:] if data.startswith('0x') else data
            
            # åŠ¨æ€å­—ç¬¦ä¸²ï¼šoffset(32) + length(32) + data
            if len(hex_data) >= 128:
                length = int(hex_data[64:128], 16)
                data_hex = hex_data[128:128 + length * 2]
                if data_hex:
                    return bytes.fromhex(data_hex).decode('utf-8', errors='ignore').rstrip('\x00')
            
            # å›ºå®šé•¿åº¦å­—ç¬¦ä¸²ï¼ˆç›´æ¥ç¼–ç ï¼‰
            if len(hex_data) == 64:
                return bytes.fromhex(hex_data).decode('utf-8', errors='ignore').rstrip('\x00')
            
            return "???"
        except Exception as e:
            logger.debug(f"è§£æ symbol å¤±è´¥: {e}")
            return "???"
    
    @lru_cache(maxsize=10000)
    def get_token_symbol(self, token: str) -> str:
        """è·å–ä»£å¸ç¬¦å·ï¼ˆL1 å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜ + L3 é“¾ä¸ŠæŸ¥è¯¢ï¼‰"""
        # L1: LRU Cache å·²é€šè¿‡è£…é¥°å™¨å¤„ç†
        
        try:
            # L2: Redis ç¼“å­˜
            redis_key = f"token:{token}:symbol"
            cached_value = self.redis_client.client.get(redis_key)
            if cached_value:
                if isinstance(cached_value, bytes):
                    cached_value = cached_value.decode('utf-8')
                return cached_value
            
            # L3: é“¾ä¸ŠæŸ¥è¯¢ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            data = self.cached_eth_call(token, "0x95d89b41")
            
            # ä½¿ç”¨æ”¹è¿›çš„è§£æå‡½æ•°
            result = self.parse_symbol_data(data)
            
            # å†™å…¥ Redis (TTL=1å¤©)
            try:
                self.redis_client.client.setex(redis_key, 86400, result)
            except:
                pass
            
            return result
        except:
            return "???"
    
    @lru_cache(maxsize=5000)
    def get_pair_tokens(self, pair: str) -> tuple:
        """è·å–äº¤æ˜“å¯¹çš„ token0 å’Œ token1ï¼ˆL1 å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜ + L3 é“¾ä¸ŠæŸ¥è¯¢ï¼‰"""
        # L1: LRU Cache å·²é€šè¿‡è£…é¥°å™¨å¤„ç†
        
        try:
            # L2: Redis ç¼“å­˜
            redis_key = f"pair:{pair}:tokens"
            cached_value = self.redis_client.client.get(redis_key)
            if cached_value:
                if isinstance(cached_value, bytes):
                    cached_value = cached_value.decode('utf-8')
                parts = cached_value.split(',')
                if len(parts) == 2:
                    return parts[0], parts[1]
            
            # L3: é“¾ä¸ŠæŸ¥è¯¢ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            token0_data = self.cached_eth_call(pair, "0x0dfe1681")
            token1_data = self.cached_eth_call(pair, "0xd21220a7")
            
            if token0_data and token1_data:
                token0 = "0x" + token0_data[-40:]
                token1 = "0x" + token1_data[-40:]
                token0 = token0.lower()
                token1 = token1.lower()
                
                # å†™å…¥ Redis (TTL=1å¤©)
                try:
                    self.redis_client.client.setex(redis_key, 86400, f"{token0},{token1}")
                except:
                    pass
                
                return token0, token1
        except:
            pass
        return None, None
    
    def get_pair_full_info(self, pair_address: str) -> Optional[Dict]:
        """
        è·å–äº¤æ˜“å¯¹å®Œæ•´ä¿¡æ¯ï¼ˆä¼˜åŒ–ç‰ˆï¼šç¼“å­˜ â†’ Multicall2æ‰¹é‡æŸ¥è¯¢ï¼‰
        
        Returns:
            {
                'token0': '0x...',
                'token1': '0x...',
                'decimals0': 18,
                'symbol0': 'USDT',
                'decimals1': 18,
                'symbol1': 'TOKEN'
            }
        """
        try:
            # ç¬¬ä¸€æ­¥ï¼šè·å– token0 å’Œ token1ï¼ˆèµ°ç¼“å­˜ï¼‰
            token0, token1 = self.get_pair_tokens(pair_address)
            
            if not token0 or not token1:
                return None
            
            # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½æ‰¹é‡æŸ¥è¯¢ï¼ˆå…ˆæŸ¥ç¼“å­˜ï¼Œæ”¶é›† missï¼Œæ‰¹é‡è°ƒç”¨ï¼‰
            result = {
                'token0': token0,
                'token1': token1,
                'decimals0': None,
                'symbol0': None,
                'decimals1': None,
                'symbol1': None
            }
            
            # æ£€æŸ¥ L1 (LRU) ç¼“å­˜
            # æ³¨æ„ï¼š@lru_cache çš„ç¼“å­˜æ£€æŸ¥éœ€è¦å®é™…è°ƒç”¨ï¼Œä½†ä¼šèµ°å†…éƒ¨çš„ L2 (Redis) é€»è¾‘
            miss_calls = []  # [(token, calldata, field_name)]
            
            # æ£€æŸ¥ token0 decimals ç¼“å­˜ï¼ˆç›´æ¥æŸ¥ Redisï¼Œä¸è§¦å‘é“¾ä¸ŠæŸ¥è¯¢ï¼‰
            try:
                cached = self.redis_client.client.get(f"token:{token0}:decimals")
                if cached:
                    result['decimals0'] = int(cached)
                else:
                    miss_calls.append((token0, "0x313ce567", 'decimals0'))
            except:
                miss_calls.append((token0, "0x313ce567", 'decimals0'))
            
            # æ£€æŸ¥ token0 symbol ç¼“å­˜
            try:
                cached = self.redis_client.client.get(f"token:{token0}:symbol")
                if cached:
                    if isinstance(cached, bytes):
                        cached = cached.decode('utf-8')
                    result['symbol0'] = cached
                else:
                    miss_calls.append((token0, "0x95d89b41", 'symbol0'))
            except:
                miss_calls.append((token0, "0x95d89b41", 'symbol0'))
            
            # æ£€æŸ¥ token1 decimals ç¼“å­˜
            try:
                cached = self.redis_client.client.get(f"token:{token1}:decimals")
                if cached:
                    result['decimals1'] = int(cached)
                else:
                    miss_calls.append((token1, "0x313ce567", 'decimals1'))
            except:
                miss_calls.append((token1, "0x313ce567", 'decimals1'))
            
            # æ£€æŸ¥ token1 symbol ç¼“å­˜
            try:
                cached = self.redis_client.client.get(f"token:{token1}:symbol")
                if cached:
                    if isinstance(cached, bytes):
                        cached = cached.decode('utf-8')
                    result['symbol1'] = cached
                else:
                    miss_calls.append((token1, "0x95d89b41", 'symbol1'))
            except:
                miss_calls.append((token1, "0x95d89b41", 'symbol1'))
            
            # å¦‚æœæœ‰æœªå‘½ä¸­çš„ï¼Œä½¿ç”¨ Multicall2 æ‰¹é‡æŸ¥è¯¢
            if not miss_calls:
                # å…¨éƒ¨å‘½ä¸­ï¼Œç›´æ¥è¿”å›
                return result
            
            multicall_params = [(target, calldata) for target, calldata, _ in miss_calls]
            multicall_results = self.multicall2_try_aggregate(multicall_params)
            
            # è§£æç»“æœå¹¶æ›´æ–°ç¼“å­˜
            for (target, calldata, field_name), call_result in zip(miss_calls, multicall_results):
                if call_result:
                    if 'decimals' in field_name:
                        try:
                            value = int(call_result, 16) if call_result else 18
                            result[field_name] = value
                            # å†™å…¥ Redis ç¼“å­˜
                            try:
                                redis_key = f"token:{target}:decimals"
                                self.redis_client.client.setex(redis_key, 86400, str(value))
                            except:
                                pass
                        except:
                            result[field_name] = 18
                    elif 'symbol' in field_name:
                        try:
                            # ä½¿ç”¨ parse_symbol_data å¤„ç†åŠ¨æ€/å›ºå®šé•¿åº¦ç¼–ç 
                            value = self.parse_symbol_data(call_result)
                            result[field_name] = value
                            # å†™å…¥ Redis ç¼“å­˜
                            try:
                                redis_key = f"token:{target}:symbol"
                                self.redis_client.client.setex(redis_key, 86400, value)
                            except:
                                pass
                        except:
                            result[field_name] = "???"
                else:
                    # è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    if 'decimals' in field_name:
                        result[field_name] = 18
                    else:
                        result[field_name] = "???"
            
            # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æœ‰é»˜è®¤å€¼
            for key in ['decimals0', 'decimals1']:
                if result[key] is None:
                    result[key] = 18
            for key in ['symbol0', 'symbol1']:
                if result[key] is None:
                    result[key] = "???"
            
            return result
        
        except Exception as e:
            logger.error(f"âŒ è·å–äº¤æ˜“å¯¹ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def parse_swap_data(self, data: str) -> Optional[Dict]:
        """è§£æ Swap äº‹ä»¶æ•°æ®"""
        try:
            if not data or data == "0x":
                return None
            
            hex_data = data[2:] if data.startswith("0x") else data
            
            if len(hex_data) < 256:
                return None
            
            return {
                "amount0In": int(hex_data[0:64], 16),
                "amount1In": int(hex_data[64:128], 16),
                "amount0Out": int(hex_data[128:192], 16),
                "amount1Out": int(hex_data[192:256], 16)
            }
        except:
            return None
    
    def format_amount(self, amount: int, decimals: int) -> str:
        """æ ¼å¼åŒ–æ•°é‡"""
        value = Decimal(amount) / (Decimal(10) ** Decimal(decimals))
        if value >= 1000:
            return f"{value:,.2f}"
        elif value >= 1:
            return f"{value:.4f}"
        else:
            return f"{value:.8f}"
    
    def first_layer_filter(self, usd_value: float, is_internal: bool) -> bool:
        """ç¬¬ä¸€å±‚è¿‡æ»¤ï¼šé‡‘é¢"""
        threshold = self.min_amount_internal if is_internal else self.min_amount_external
        return usd_value >= threshold
    
    async def check_and_set_alert_cooldown(self, token_address: str) -> bool:
        """
        åŸå­åŒ–æ£€æŸ¥å†·å´æœŸå¹¶è®¾ç½®ï¼ˆä½¿ç”¨Luaè„šæœ¬ï¼‰
        è¿”å› True = å…è®¸æ¨é€å¹¶å·²è®¾ç½®å†·å´æœŸ
        è¿”å› False = åœ¨å†·å´æœŸå†…ï¼Œè·³è¿‡
        """
        redis_key = f"bsc:alert:last:{token_address.lower()}"
        
        try:
            now_timestamp = int(time.time())
            # ä½¿ç”¨ uniform è·å¾—æ›´ç²¾ç¡®çš„æŠ–åŠ¨ï¼ˆfloat â†’ intï¼‰
            jitter_seconds = random.uniform(0, self.cooldown_jitter * 60)
            cooldown_seconds = int(self.cooldown_minutes * 60 + jitter_seconds)
            
            # Luaè„šæœ¬ï¼šåŸå­åŒ–æ£€æŸ¥å¹¶è®¾ç½®å†·å´æœŸ
            lua_script = """
            local key = KEYS[1]
            local now = tonumber(ARGV[1])
            local cooldown = tonumber(ARGV[2])
            
            -- è·å–ä¸Šæ¬¡è®°å½•
            local last_data = redis.call('GET', key)
            
            -- é¦–æ¬¡æˆ–æ— è®°å½•
            if not last_data then
                local new_data = string.format('{"timestamp":%d,"cooldown_seconds":%d,"alert_count":1}', now, cooldown)
                redis.call('SETEX', key, 86400, new_data)
                return 1  -- å…è®¸æ¨é€
            end
            
            -- è§£æJSONï¼ˆç®€åŒ–ï¼šç›´æ¥æå–timestampï¼‰
            local last_timestamp = tonumber(string.match(last_data, '"timestamp":(%d+)'))
            
            -- æ— æ³•è§£æï¼Œè§†ä¸ºé¦–æ¬¡
            if not last_timestamp then
                local new_data = string.format('{"timestamp":%d,"cooldown_seconds":%d,"alert_count":1}', now, cooldown)
                redis.call('SETEX', key, 86400, new_data)
                return 1
            end
            
            -- æ£€æŸ¥å†·å´æœŸ
            if now - last_timestamp < cooldown then
                return 0  -- å†·å´æœŸå†…ï¼Œæ‹’ç»
            end
            
            -- é€šè¿‡å†·å´æœŸï¼Œæ›´æ–°è®°å½•
            local alert_count = tonumber(string.match(last_data, '"alert_count":(%d+)')) or 0
            local new_data = string.format('{"timestamp":%d,"cooldown_seconds":%d,"alert_count":%d}', now, cooldown, alert_count + 1)
            redis.call('SETEX', key, 86400, new_data)
            return 1  -- å…è®¸æ¨é€
            """
            
            # æ‰§è¡ŒLuaè„šæœ¬
            result = await asyncio.to_thread(
                self.redis_client.client.eval,
                lua_script,
                1,  # numkeys
                redis_key,
                now_timestamp,
                cooldown_seconds
            )
            
            if result == 1:
                return True  # å…è®¸æ¨é€
            else:
                logger.info(f"â³ å†·å´æœŸå†…ï¼Œè·³è¿‡: {token_address}")
                return False
        
        except Exception as e:
            logger.error(f"æ£€æŸ¥å†·å´æœŸå¤±è´¥: {e}")
            # å‡ºé”™æ—¶å…è®¸æ¨é€ï¼ˆé¿å…è¯¯é˜»æ­¢ï¼‰
            return True
    
    async def check_alert_cooldown_readonly(self, token_address: str) -> bool:
        """
        åªè¯»æ£€æŸ¥ä»£å¸æ˜¯å¦åœ¨å†·å´æœŸå†…ï¼ˆä¸è®¾ç½®å†·å´æœŸï¼‰
        ç”¨äºç¬¬ä¸€å±‚è¿‡æ»¤åï¼Œé¿å…æµªè´¹APIè°ƒç”¨
        """
        redis_key = f"bsc:alert:last:{token_address.lower()}"
        
        try:
            last_alert_data = await asyncio.to_thread(self.redis_client.get, redis_key)
            
            if not last_alert_data:
                return True  # æ²¡æœ‰è®°å½•ï¼Œå…è®¸ç»§ç»­
            
            # å®‰å…¨è§£æ JSON
            try:
                if isinstance(last_alert_data, dict):
                    last_alert = last_alert_data
                elif isinstance(last_alert_data, (str, bytes)):
                    if isinstance(last_alert_data, bytes):
                        last_alert_data = last_alert_data.decode('utf-8')
                    if not last_alert_data or last_alert_data == 'null':
                        return True
                    last_alert = json.loads(last_alert_data)
                else:
                    return True
            except:
                return True
            
            last_timestamp = last_alert.get('timestamp', 0)
            cooldown_seconds = last_alert.get('cooldown_seconds', int(self.cooldown_minutes * 60))
            now_timestamp = int(time.time())
            
            if now_timestamp - last_timestamp < cooldown_seconds:
                logger.info(f"â³ å†·å´æœŸå†…ï¼Œè·³è¿‡: {token_address} (å‰©ä½™ {cooldown_seconds - (now_timestamp - last_timestamp)}ç§’)")
                return False
            
            return True
        except Exception as e:
            logger.error(f"æ£€æŸ¥å†·å´æœŸå¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶å…è®¸ç»§ç»­
    
    async def check_alert_cooldown(self, token_address: str) -> bool:
        """
        æ£€æŸ¥ä»£å¸æ˜¯å¦åœ¨å†·å´æœŸå†…ï¼ˆå…¼å®¹æ—§æ¥å£ï¼Œåªè¯»ï¼‰
        """
        return await self.check_alert_cooldown_readonly(token_address)
    
    # update_alert_historyå·²åºŸå¼ƒï¼Œé€»è¾‘å·²åˆå¹¶åˆ°check_and_set_alert_cooldownä¸­
    
    def create_token_buttons(self, token_address: str):
        """åˆ›å»ºä»£å¸çš„ Telegram å†…è”æŒ‰é’®"""
        if not HAS_TELEGRAM_BUTTONS:
            return None
        
        buttons = [
            [
                InlineKeyboardButton("ğŸ“Š GMGN", url=f"https://gmgn.ai/bsc/token/{token_address}"),
                InlineKeyboardButton("ğŸ” OKX", url=f"https://www.okx.com/web3/dex-swap#inputChain=56&inputCurrency={token_address}&outputChain=56&outputCurrency=0x55d398326f99059fF775485246999027B3197955")
            ]
        ]
        return InlineKeyboardMarkup(buttons)
    
    async def send_alert(self, message: str, token_address: str) -> bool:
        """
        å‘é€ Telegram é€šçŸ¥
        
        Returns:
            bool: æ˜¯å¦å‘é€æˆåŠŸ
        """
        if not self.enable_telegram:
            logger.debug(f"â­ï¸  Telegramæœªå¯ç”¨ï¼Œè·³è¿‡å‘é€")
            return False
        
        try:
            reply_markup = self.create_token_buttons(token_address)
            
            result = await self.telegram_notifier.send(
                target=self.bsc_channel_id,
                message=message,
                parse_mode="HTML",
                reply_markup=reply_markup
            )
            
            if result:
                logger.info(f"âœ… Telegramé€šçŸ¥å·²å‘é€ - {token_address[:10]}...")
                self.alert_success_count += 1  # å‘é€æˆåŠŸè®¡æ•°
                return True
            else:
                logger.error(f"âŒ Telegramå‘é€å¤±è´¥ - {token_address[:10]}...")
                self.alert_fail_count += 1  # å‘é€å¤±è´¥è®¡æ•°
                return False
        
        except Exception as e:
            logger.error(f"âŒ å‘é€é€šçŸ¥å¼‚å¸¸: {e}")
            self.alert_fail_count += 1  # å¼‚å¸¸ä¹Ÿç®—å‘é€å¤±è´¥
            return False
    
    async def check_external_is_fourmeme(self, token_address: str) -> tuple[bool, bool, Optional[Dict]]:
        """
        æ£€æŸ¥å¤–ç›˜ä»£å¸æ˜¯å¦æ¥è‡ª fourmeme å¹³å°
        
        Returns:
            (is_fourmeme, is_confirmed, launchpad_info):
            - is_fourmeme: æ˜¯å¦æ˜¯fourmeme
            - is_confirmed: æ˜¯å¦ç¡®è®¤ç»“æœï¼ˆFalseè¡¨ç¤ºAPIå¤±è´¥ï¼Œç»“æœä¸ç¡®å®šï¼‰
            - launchpad_info: è¯¦ç»†ä¿¡æ¯ï¼ˆä»…å½“is_fourmeme=Trueæ—¶æœ‰å€¼ï¼‰
            
        ç¤ºä¾‹:
            (True, True, {...})   - ç¡®è®¤æ˜¯fourmeme
            (False, True, None)   - ç¡®è®¤ä¸æ˜¯fourmemeï¼ˆå¯ä»¥åŠ é»‘åå•ï¼‰
            (False, False, None)  - APIå¤±è´¥ï¼ŒæœªçŸ¥ï¼ˆä¸åº”åŠ é»‘åå•ï¼‰
        """
        dbotx_api = self.get_thread_dbotx_api()
        
        try:
            launchpad_info = await dbotx_api.get_token_launchpad_info('bsc', token_address)
            
            if not launchpad_info:
                # APIå¤±è´¥æˆ–æ— æ•°æ®ï¼Œç»“æœä¸ç¡®å®š
                # è¿™å¯èƒ½æ˜¯ï¼š1) APIæ•…éšœ  2) ç½‘ç»œé—®é¢˜  3) tokenå¤ªæ–°è¿˜æ²¡æ•°æ®
                # ä¸ºå®‰å…¨èµ·è§ï¼Œä¸ç¡®è®¤ç»“æœ
                return (False, False, None)
            
            launchpad = launchpad_info.get('launchpad', '').lower()
            
            if launchpad == 'fourmeme':
                # ç¡®è®¤æ˜¯fourmeme
                return (True, True, launchpad_info)
            elif launchpad:
                # æœ‰æ˜ç¡®çš„launchpadä¿¡æ¯ï¼ˆå¦‚pancake_v2ï¼‰ï¼Œç¡®è®¤ä¸æ˜¯fourmeme
                return (False, True, None)
            else:
                # launchpadä¸ºç©ºï¼Œå¯èƒ½æ˜¯æ•°æ®ä¸å®Œæ•´ï¼Œä¸ç¡®è®¤
                return (False, False, None)
        
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ Launchpad å¤±è´¥: {e}")
            # APIå¼‚å¸¸ï¼Œç»“æœä¸ç¡®å®š
            return (False, False, None)
    
    async def second_layer_filter(
        self,
        token_address: str,
        pair_address: str,
        launchpad_info: Dict,
        is_internal: bool
    ) -> Optional[Dict]:
        """ç¬¬äºŒå±‚è¿‡æ»¤ï¼šæŒ‡æ ‡æ£€æŸ¥"""
        dbotx_api = self.get_thread_dbotx_api()
        
        try:
            # 1. ä½¿ç”¨ launchpad_info ä¸­çš„ pair_addressï¼ˆå¦‚æœæœ‰ï¼‰
            api_pair_address = launchpad_info.get('pair_address')
            if api_pair_address:
                pair_address = api_pair_address
            
            # 2. è°ƒç”¨ DBotX API è·å–ä»£å¸æŒ‡æ ‡
            raw_data = await dbotx_api.get_pair_info('bsc', pair_address)
            
            if not raw_data:
                logger.debug("ç¬¬äºŒå±‚è¿‡æ»¤-æ— DBotXæ•°æ®", extra={"token": token_address[:10]})
                return None
            
            # 3. åˆ¤æ–­å†…å¤–ç›˜
            launchpad_status = launchpad_info.get('launchpad_status', 0)
            is_internal = (launchpad_status == 0)
            pool_type = "å†…ç›˜" if is_internal else "å¤–ç›˜"
            pool_emoji = "ğŸ”´" if is_internal else "ğŸŸ¢"
            
            # 4. æ ¹æ®å†…å¤–ç›˜é€‰æ‹©æ—¶é—´é—´éš”
            time_interval = self.time_interval_internal if is_internal else self.time_interval_external
            
            # 5. è§£ææ•°æ®ï¼ˆä½¿ç”¨åŠ¨æ€æ—¶é—´é—´éš”ï¼‰
            token_data = dbotx_api.parse_token_data(raw_data, time_interval)
            if not token_data:
                logger.debug(f"â­ï¸  [ç¬¬äºŒå±‚] è§£æå¤±è´¥: {token_address}...")
                return None
            
            # 6. TopæŒæœ‰è€…è¿‡æ»¤ï¼ˆå†…ç›˜å’Œå¤–ç›˜éƒ½æ£€æŸ¥ï¼‰
            # å…ˆåˆ¤æ–­ Redis é…ç½®æ˜¯å¦æœ‰ topHoldersThreshold
            top_holders_threshold = self.top_holders_threshold_internal if is_internal else self.top_holders_threshold_external
            top10_holder_check_passed = None  # ç”¨äºæ—¥å¿—æ˜¾ç¤º
            if top_holders_threshold is not None:
                # å†åˆ¤æ–­ API è¿”å›æ•°æ®æ˜¯å¦æœ‰ top10_holder_rate
                top10_holder_rate = token_data.get('top10_holder_rate')
                if top10_holder_rate is not None:
                    # API è¿”å›çš„æ˜¯å°æ•°ï¼ˆ0-1ï¼‰ï¼Œéœ€è¦è½¬æˆç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰å†æ¯”è¾ƒ
                    top10_holder_percent = top10_holder_rate * 100
                    top10_holder_check_passed = top10_holder_percent < top_holders_threshold
                    # ä¸¤ä¸ªéƒ½æœ‰ï¼Œæ‰è¿›è¡Œæ ¡éªŒ
                    if top10_holder_percent >= top_holders_threshold:
                        symbol = token_data.get('symbol', 'Unknown')
                        logger.info(f"â­ï¸  [ç¬¬äºŒå±‚] Top10æŒæœ‰è€…æ¯”ä¾‹è¿‡é«˜: {symbol} ({top10_holder_percent:.1f}% >= {top_holders_threshold:.1f}%)")
                        return None
                else:
                    top10_holder_check_passed = "N/A"  # APIæ²¡è¿”å›æ•°æ®ï¼Œè·³è¿‡æ£€æŸ¥
            else:
                top10_holder_check_passed = "æœªé…ç½®"  # Redisæœªé…ç½®ï¼Œè·³è¿‡æ£€æŸ¥
            
            # 7. è·å–æŒ‡æ ‡æ•°æ® + æ—¶é—´çª—å£é€€è®©ç­–ç•¥
            price_change = token_data.get('price_change', 0)
            volume = token_data.get('volume', 0)
            symbol = token_data.get('symbol', 'Unknown')
            fallback_info = None  # ç”¨äºè®°å½•é€€è®©ä¿¡æ¯ï¼ˆç»™TGæ’­æŠ¥ç”¨ï¼‰
            
            # æ—¶é—´çª—å£é€€è®©ï¼šå¦‚æœæ•°æ®ä¸º0ï¼Œè‡ªåŠ¨é€€è®©åˆ°æ›´é•¿æ—¶é—´çª—å£
            if price_change == 0 and volume == 0:
                original_interval = time_interval
                fallback_interval = None
                
                # å®šä¹‰é€€è®©é“¾ï¼ˆ1mâ†’5måœæ­¢ï¼Œ5mâ†’1håœæ­¢ï¼‰
                if time_interval == '1m':
                    fallback_interval = '5m'
                elif time_interval == '5m':
                    fallback_interval = '1h'
                
                # å°è¯•é€€è®©
                if fallback_interval:
                    logger.info(f"   ğŸ”„ {original_interval}æ•°æ®ä¸º0ï¼Œå°è¯•é€€è®©è‡³{fallback_interval}")
                    fallback_data = dbotx_api.parse_token_data(raw_data, fallback_interval)
                    if fallback_data:
                        fallback_price_change = fallback_data.get('price_change', 0)
                        fallback_volume = fallback_data.get('volume', 0)
                        
                        if fallback_price_change != 0 or fallback_volume != 0:
                            # é€€è®©æˆåŠŸï¼Œä½¿ç”¨é€€è®©æ•°æ®
                            price_change = fallback_price_change
                            volume = fallback_volume
                            time_interval = fallback_interval  # æ›´æ–°æ—¶é—´çª—å£
                            fallback_info = {
                                'original': original_interval,
                                'fallback': fallback_interval,
                                'reason': f'{original_interval}æ•°æ®ä¸º0'
                            }
                            # Prometheus: æ—¶é—´çª—å£é€€è®©è®¡æ•°
                            if HAS_PROMETHEUS:
                                self.metrics_fallback.labels(original=original_interval, fallback=fallback_interval).inc()
                            logger.info(f"   âœ… é€€è®©æˆåŠŸ: ä½¿ç”¨{fallback_interval}æ•°æ® (æ¶¨å¹…{price_change:+.2f}%, äº¤æ˜“é‡${volume:,.2f})")
                        else:
                            logger.info(f"   âŒ {fallback_interval}æ•°æ®ä¹Ÿä¸º0ï¼Œæ— æ³•é€€è®©")
                    else:
                        logger.warning(f"   âš ï¸ è§£æ{fallback_interval}æ•°æ®å¤±è´¥")
            
            # 8. æ„é€  stats æ•°æ®ï¼ˆç”¨äº TriggerLogicï¼‰
            stats = {
                'priceChange': price_change,
                'volume': volume,
                'holderChange': 0
            }
            
            # 9. é€‰æ‹©å¯¹åº”çš„ events_config å’Œ trigger_logic
            events_config = self.internal_events_config if is_internal else self.external_events_config
            trigger_logic = self.trigger_logic_internal if is_internal else self.trigger_logic_external
            
            # ç¬¬äºŒå±‚æ£€æŸ¥è®¡æ•°
            if is_internal:
                self.second_layer_check_internal += 1
                if HAS_PROMETHEUS:
                    self.metrics_second_layer_check.labels(type='internal').inc()
            else:
                self.second_layer_check_external += 1
                if HAS_PROMETHEUS:
                    self.metrics_second_layer_check.labels(type='external').inc()
            
            logger.info(f"ğŸ” [ç¬¬äºŒå±‚æ£€æŸ¥] {pool_emoji}{pool_type} {symbol} ({token_address})")
            logger.info(f"   â”œâ”€ {time_interval}æ¶¨å¹…: {price_change:+.2f}%")
            logger.info(f"   â”œâ”€ {time_interval}äº¤æ˜“é‡: ${volume:,.2f}")
            
            # æ˜¾ç¤º Top10 æŒæœ‰è€…æ£€æŸ¥çŠ¶æ€
            if top10_holder_check_passed == "æœªé…ç½®":
                logger.info(f"   â”œâ”€ Top10æŒæœ‰è€…: æœªé…ç½®é˜ˆå€¼ï¼ˆè·³è¿‡æ­¤é¡¹ï¼‰")
            elif top10_holder_check_passed == "N/A":
                logger.info(f"   â”œâ”€ Top10æŒæœ‰è€…: APIæœªè¿”å›ï¼ˆè·³è¿‡æ­¤é¡¹ï¼‰")
            elif top10_holder_check_passed is True:
                top10_holder_rate = token_data.get('top10_holder_rate', 0)
                logger.info(f"   â”œâ”€ Top10æŒæœ‰è€…: {top10_holder_rate * 100:.1f}% (âœ… < {top_holders_threshold:.1f}%)")
            elif top10_holder_check_passed is False:
                # è¿™ä¸ªåˆ†æ”¯ä¸ä¼šæ‰§è¡Œï¼Œå› ä¸ºå¦‚æœæœªé€šè¿‡å·²ç»returnäº†
                pass
            
            # æ˜¾ç¤ºè§¦å‘é€»è¾‘
            logic_text = "AND" if trigger_logic == "all" else "OR"
            logger.info(f"   â””â”€ é…ç½®é˜ˆå€¼: æ¶¨å¹…>={events_config.get('priceChange', {}).get('risePercent')}% {logic_text} äº¤æ˜“é‡>=${events_config.get('volume', {}).get('threshold')}")
            logger.debug(f"   é…ç½®è¯¦æƒ…: {events_config}")
            logger.debug(f"   ç»Ÿè®¡æ•°æ®: {stats}")
            
            # 10. ä½¿ç”¨ TriggerLogic è¯„ä¼°ï¼ˆä½¿ç”¨é…ç½®çš„è§¦å‘é€»è¾‘ï¼‰
            should_trigger, triggered_events = TriggerLogic.evaluate_trigger(
                stats, events_config, trigger_logic
            )
            
            logger.debug(f"   è§¦å‘ç»“æœ: should_trigger={should_trigger}, triggered_events={len(triggered_events) if triggered_events else 0}")
            
            if not should_trigger:
                logger.info(f"   âŒ æœªè¾¾åˆ°è§¦å‘æ¡ä»¶")
                return None
            
            # 11. é€šè¿‡ç­›é€‰ï¼Œè¿”å›æ•°æ®
            logger.info(f"   âœ… æ»¡è¶³æ¡ä»¶ï¼è§¦å‘ {len(triggered_events)} ä¸ªäº‹ä»¶")
            
            # ç¬¬äºŒå±‚é€šè¿‡è®¡æ•°
            if is_internal:
                self.second_layer_pass_internal += 1
                if HAS_PROMETHEUS:
                    self.metrics_second_layer_pass.labels(type='internal').inc()
            else:
                self.second_layer_pass_external += 1
                if HAS_PROMETHEUS:
                    self.metrics_second_layer_pass.labels(type='external').inc()
            
            token_data['pool_type'] = pool_type
            token_data['is_internal'] = is_internal
            token_data['pool_emoji'] = pool_emoji
            token_data['triggered_events'] = triggered_events
            token_data['fallback_info'] = fallback_info  # æ—¶é—´çª—å£é€€è®©ä¿¡æ¯
            
            return token_data
        
        except Exception as e:
            logger.error(f"âŒ ç¬¬äºŒå±‚è¿‡æ»¤å¤±è´¥: {e}")
            return None
    
    async def handle_swap_event(self, log: Dict):
        """
        å¤„ç† PancakeSwap Swap äº‹ä»¶ï¼ˆå¤–ç›˜ï¼‰
        
        ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨ DBotX API æ›¿ä»£ RPC è°ƒç”¨ï¼ˆå¸¦é™çº§ç­–ç•¥ï¼‰
        - ä¼˜å…ˆè·¯å¾„ï¼š1æ¬¡APIè°ƒç”¨è·å–æ‰€æœ‰æ•°æ®
        - é™çº§è·¯å¾„ï¼šAPIå¤±è´¥ â†’ RPCè·å–token0/token1 â†’ ç»§ç»­å¤„ç†
        """
        tx_hash = log.get("transactionHash")
        pair_address = log.get("address", "").lower()
        swap_data = self.parse_swap_data(log.get("data"))
        
        if not swap_data:
            # WebSocketæ•°æ®è§£æå¤±è´¥ï¼Œå°è¯•ä»receiptå…œåº•
            await self._handle_swap_with_receipt_fallback(tx_hash, pair_address)
            return
        
        # ğŸš€ ä¼˜å…ˆè·¯å¾„ï¼šå°è¯•ä½¿ç”¨ DBotX API è·å–äº¤æ˜“å¯¹ä¿¡æ¯ï¼ˆå¤ç”¨è¿æ¥æ± ï¼‰
        mint = None
        base_mint = None
        base_symbol = None
        token_symbol = None
        use_api_data = False  # æ ‡è®°æ˜¯å¦ä½¿ç”¨ API å®Œæ•´æ•°æ®
        pair_info_raw = None
        
        # ğŸš€ ä¼˜åŒ–ï¼šæ£€æŸ¥"æ— æ•°æ®pair"ç¼“å­˜
        no_data_key = f"no_data_pair:{pair_address}"
        skip_api = False  # æ ‡è®°æ˜¯å¦è·³è¿‡APIè°ƒç”¨
        
        if self.redis_client:
            try:
                if self.redis_client.get(no_data_key):
                    skip_api = True
                    logger.debug(f"â­ï¸  [ç¼“å­˜å‘½ä¸­] pairæ— APIæ•°æ®ï¼Œè·³è¿‡APIç›´æ¥èµ°RPC: {pair_address[:10]}...")
            except Exception as e:
                logger.debug(f"RedisæŸ¥è¯¢å¤±è´¥: {e}")
        
        # å¦‚æœç¼“å­˜æœªå‘½ä¸­ï¼Œå°è¯•API
        if not skip_api:
            dbotx_api = self.get_thread_dbotx_api()
            pair_info_raw = await dbotx_api.get_pair_info('bsc', pair_address)
            
            # ğŸ” è°ƒè¯•ï¼šæ‰“å°APIè¿”å›çš„å®Œæ•´å­—æ®µï¼ˆä»…æ‰“å°å‰3ä¸ªï¼Œé¿å…åˆ·å±ï¼‰
            if pair_info_raw is not None and hasattr(self, '_api_debug_count'):
                if self._api_debug_count < 3:
                    logger.info(f"ğŸ” [è°ƒè¯•] APIè¿”å›å­—æ®µ: {list(pair_info_raw.keys())[:20]}")
                    self._api_debug_count += 1
            elif pair_info_raw is not None and not hasattr(self, '_api_debug_count'):
                self._api_debug_count = 1
                logger.info(f"ğŸ” [è°ƒè¯•] APIè¿”å›çš„æ‰€æœ‰å­—æ®µå: {list(pair_info_raw.keys())}")
        
        # æ£€æŸ¥ API è¿”å›ï¼ˆå¯èƒ½æ˜¯ Noneã€ç©ºå­—å…¸ {}ã€æˆ–æœ‰æ•°æ®çš„å­—å…¸ï¼‰
        if pair_info_raw is not None:  # æ’é™¤ None
            mint = pair_info_raw.get('mint', '').lower()
            base_mint = pair_info_raw.get('baseMint', '').lower()
            base_symbol = pair_info_raw.get('baseSymbol', '')
            token_symbol = pair_info_raw.get('symbol', '')
            
            # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å­˜åœ¨ä¸”éç©º
            # æ³¨æ„ï¼šç©ºå­—å…¸ {} ä¼šè¿›å…¥è¿™ä¸ªåˆ†æ”¯ï¼Œä½† mint/base_mint ä¼šæ˜¯ç©ºå­—ç¬¦ä¸²
            if mint and base_mint:  # ä¸¤è€…éƒ½éç©ºæ‰ä½¿ç”¨ API æ•°æ®
                use_api_data = True
                logger.info(f"âš¡ [å¿«é€Ÿè·¯å¾„] APIæ•°æ®å®Œæ•´: {pair_address[:10]}... (mint={mint[:10]}, base={base_mint[:10]})")
            else:
                logger.info(f"ğŸ”„ [é™çº§] APIæ•°æ®ä¸å®Œæ•´ï¼ˆç©ºå­—å…¸æˆ–ç¼ºå­—æ®µï¼‰: {pair_address[:10]}... â†’ ä½¿ç”¨RPC")
                # ğŸš€ ç¼“å­˜æ— æ•°æ®pairï¼ˆ1å°æ—¶ï¼‰ï¼Œé¿å…é‡å¤RPCæŸ¥è¯¢
                if self.redis_client:
                    try:
                        self.redis_client.set(no_data_key, "1", ex=3600)
                        logger.debug(f"âœ… å·²ç¼“å­˜æ— æ•°æ®pair: {pair_address[:10]}...")
                    except Exception as e:
                        logger.debug(f"Rediså†™å…¥å¤±è´¥: {e}")
        else:
            logger.info(f"ğŸ”„ [é™çº§] APIè¿”å›None: {pair_address[:10]}... â†’ ä½¿ç”¨RPC")
            # ğŸš€ ç¼“å­˜æ— æ•°æ®pairï¼ˆ1å°æ—¶ï¼‰
            if self.redis_client:
                try:
                    self.redis_client.set(no_data_key, "1", ex=3600)
                    logger.debug(f"âœ… å·²ç¼“å­˜æ— æ•°æ®pair: {pair_address[:10]}...")
                except Exception as e:
                    logger.debug(f"Rediså†™å…¥å¤±è´¥: {e}")
        
        # ğŸ”„ é™çº§è·¯å¾„ï¼šAPI å¤±è´¥æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œä½¿ç”¨ RPC è·å– token0/token1
        pair_info_rpc = None  # RPCè·å–çš„pairä¿¡æ¯
        if not use_api_data:
            
            # ä½¿ç”¨åŸæ¥çš„ RPC æ–¹å¼
            pair_info_rpc = self.get_pair_full_info(pair_address)
            if not pair_info_rpc:
                logger.debug(f"â­ï¸  RPC ä¹Ÿå¤±è´¥ï¼Œè·³è¿‡: {pair_address[:10]}...")
            return
        
            mint = pair_info_rpc['token0'].lower()  # æ ¹æ®æµ‹è¯•ï¼Œtoken0 = mint
            base_mint = pair_info_rpc['token1'].lower()  # token1 = baseMint
            token_symbol = pair_info_rpc.get('symbol0', '???')
            base_symbol = pair_info_rpc.get('symbol1', '???')
            
            # æ ‡è®°ä¸ºé™çº§æ¨¡å¼ï¼ˆåç»­éœ€è¦è°ƒç”¨ second_layer_filterï¼‰
            # æ³¨æ„ï¼šä¿æŒ pair_info_raw = None ç”¨äºåˆ¤æ–­ï¼Œä½†åç»­ä½¿ç”¨ pair_info_rpc è·å–æ•°æ®
            pair_info_raw = None
        
        # å¿«é€Ÿè¿‡æ»¤ï¼šæ£€æŸ¥åŸºç¡€è´§å¸æ˜¯å¦æ˜¯æˆ‘ä»¬å…³æ³¨çš„ç¨³å®šå¸
        if base_mint not in (self.USDT, self.USDC, self.WBNB):
            return
        
        # è§£æäº¤æ˜“æ•°æ®
        amount0_in = swap_data["amount0In"]
        amount1_in = swap_data["amount1In"]
        amount0_out = swap_data["amount0Out"]
        amount1_out = swap_data["amount1Out"]
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯ä¹°å…¥è¡Œä¸ºï¼ˆç¨³å®šå¸è¾“å…¥ â†’ ä¸»ä»£å¸è¾“å‡ºï¼‰
        # æ ¹æ®æµ‹è¯•ç»“æœï¼šmint=token0, baseMint=token1 (100%åŒ¹é…)
        quote_token = None
        base_token = None
        quote_amount = 0
        base_amount = 0
        quote_decimals = 18  # ç¨³å®šå¸ç²¾åº¦é»˜è®¤18
        # ğŸ”§ ä¿®å¤ï¼šRPCè·¯å¾„ä¸‹ä» pair_info_rpc è·å–ç²¾åº¦ï¼ŒAPIè·¯å¾„ä» pair_info_raw è·å–
        if pair_info_raw:
            base_decimals = pair_info_raw.get('decimals', 18)  # APIè·¯å¾„
        elif pair_info_rpc:
            base_decimals = pair_info_rpc.get('decimals0', 18)  # RPCè·¯å¾„
        else:
            base_decimals = 18  # å…œåº•
        quote_symbol = base_symbol
        base_symbol = token_symbol
        
        if amount0_in > 0 and amount1_out > 0:
            # token0è¾“å…¥ â†’ token1è¾“å‡º
            # è¿™ç§æƒ…å†µé€šå¸¸ä¸æ˜¯ä¹°å…¥ï¼ˆtoken0æ˜¯ä¸»ä»£å¸ï¼Œtoken1æ˜¯ç¨³å®šå¸ï¼‰
            # ä½†æˆ‘ä»¬ä»éœ€æ£€æŸ¥
            if mint == base_mint:  # ç‰¹æ®Šæƒ…å†µï¼šç¨³å®šå¸å¯¹
                return
            logger.debug(f"â­ï¸  å¯èƒ½æ˜¯å–å‡ºï¼štoken0è¾“å…¥ â†’ token1è¾“å‡º")
            return
            
        elif amount1_in > 0 and amount0_out > 0:
            # token1è¾“å…¥ â†’ token0è¾“å‡º
            # æ ¹æ®æµ‹è¯•ï¼štoken1=baseMintï¼ˆç¨³å®šå¸ï¼‰ï¼Œtoken0=mintï¼ˆä¸»ä»£å¸ï¼‰
            # è¿™æ˜¯æ ‡å‡†çš„ä¹°å…¥è¡Œä¸º âœ“
            quote_token = base_mint  # ç¨³å®šå¸
            base_token = mint  # ä¸»ä»£å¸
            quote_amount = amount1_in
            base_amount = amount0_out
        else:
            # å…¶ä»–æƒ…å†µï¼šå¯èƒ½æ˜¯å¤æ‚äº¤æ˜“
            return
        
        if not quote_token or not base_token:
            return
        
        quote_value = Decimal(quote_amount) / (Decimal(10) ** Decimal(quote_decimals))
        if quote_token == self.WBNB:
            wbnb_price = self.get_wbnb_price()
            usd_value = float(quote_value) * wbnb_price
        else:
            usd_value = float(quote_value)
        
        # ç¬¬ä¸€å±‚è¿‡æ»¤
        if not self.first_layer_filter(usd_value, is_internal=False):
            return
        
        # ä¸œå…«åŒºæ—¶é—´
        cn_time = datetime.now(timezone(timedelta(hours=8))).strftime('%H:%M:%S')
        logger.info(f"âœ… [å¤–ç›˜] é€šè¿‡ç¬¬ä¸€å±‚: {base_symbol} (${usd_value:.2f}) [{cn_time}] - {base_token[:10]}...")
        self.first_layer_pass_external += 1  # å¤–ç›˜ç¬¬ä¸€å±‚è®¡æ•°
        
        # Prometheus: ç¬¬ä¸€å±‚é€šè¿‡è®¡æ•°
        if HAS_PROMETHEUS:
            self.metrics_first_layer_pass.labels(type='external').inc()
        
        # ğŸš€ ä¼˜åŒ–ï¼šå…ˆæ£€æŸ¥ Redis ç¼“å­˜ï¼ˆéfourmeme tokené»‘åå•ï¼‰
        if self.redis_client:
            try:
                is_cached_non_fourmeme = self.redis_client.sismember(self.NON_FOURMEME_KEY, base_token)
                if is_cached_non_fourmeme:
                    self.cache_hit_count += 1
                    logger.info(f"â­ï¸  [å¤–ç›˜] éfourmeme (ç¼“å­˜å‘½ä¸­ #{self.cache_hit_count}): {base_symbol} (${usd_value:.2f}) - {base_token[:10]}...")
                    return
            except Exception as e:
                logger.warning(f"âš ï¸  Redisç¼“å­˜æŸ¥è¯¢å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ fourmeme
        is_fourmeme = False
        is_confirmed = False  # æ˜¯å¦èƒ½ç¡®è®¤ï¼ˆAPI æœ‰æ•°æ®ï¼‰
        
        if use_api_data and pair_info_raw:
            # å¿«é€Ÿè·¯å¾„ï¼šä½¿ç”¨ API å·²è¿”å›çš„æ•°æ®
            pre_dex = pair_info_raw.get('preDex', '').lower()
            pool_type = pair_info_raw.get('poolType', '').lower()
            is_fourmeme = (pre_dex == 'fourmeme' or pool_type == 'fourmeme')
            is_confirmed = True
        else:
            # é™çº§è·¯å¾„ï¼šä½¿ç”¨åŸæœ‰çš„ API æ£€æŸ¥
            logger.debug(f"ğŸ”„ [é™çº§] è°ƒç”¨ check_external_is_fourmeme: {base_token[:10]}...")
            is_fourmeme, is_confirmed, launchpad_info = await self.check_external_is_fourmeme(base_token)
        
        if not is_fourmeme:
            if is_confirmed:
                # ç¡®è®¤ä¸æ˜¯fourmeme â†’ åŠ å…¥Redisé»‘åå•ï¼ˆ30å¤©è¿‡æœŸï¼‰
                if self.redis_client:
                    try:
                        self.redis_client.client.sadd(self.NON_FOURMEME_KEY, base_token)
                        self.redis_client.client.expire(self.NON_FOURMEME_KEY, self.NON_FOURMEME_TTL)
                        logger.debug(f"âœ… å·²åŠ å…¥é»‘åå•: {base_symbol} - {base_token[:10]}...")
                    except Exception as e:
                        logger.warning(f"âš ï¸  Redisç¼“å­˜å†™å…¥å¤±è´¥: {e}")
                    
                    # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæ˜¾ç¤ºåˆ¤å®šä¾æ®
                    if use_api_data and pair_info_raw:
                        pre_dex = pair_info_raw.get('preDex', 'N/A')
                        pool_type = pair_info_raw.get('poolType', 'N/A')
                        logger.info(f"â­ï¸  [å¤–ç›˜] éfourmemeï¼Œè·³è¿‡: {base_symbol} (${usd_value:.2f}) | preDex={pre_dex}, poolType={pool_type} | {base_token[:10]}...")
                    else:
                        logger.info(f"â­ï¸  [å¤–ç›˜] éfourmemeï¼Œè·³è¿‡: {base_symbol} (${usd_value:.2f}) | {base_token[:10]}...")
            else:
                # API å¤±è´¥ï¼Œä¸ç¡®å®š â†’ ä¸åŠ é»‘åå•
                logger.info(f"âš ï¸  [å¤–ç›˜] fourmemeæ£€æŸ¥å¤±è´¥ï¼ˆAPIæ•…éšœï¼‰ï¼Œè·³è¿‡ä½†ä¸åŠ é»‘åå•: {base_symbol} - {base_token[:10]}...")
            return
        
        # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæ˜¾ç¤ºåˆ¤å®šä¾æ®
        if use_api_data and pair_info_raw:
            pre_dex = pair_info_raw.get('preDex', 'N/A')
            pool_type = pair_info_raw.get('poolType', 'N/A')
            logger.info(f"âœ… [å¤–ç›˜] æ˜¯fourmeme: {base_symbol} (${usd_value:.2f}) | preDex={pre_dex}, poolType={pool_type} | {base_token[:10]}...")
        else:
            logger.info(f"âœ… [å¤–ç›˜] æ˜¯fourmeme: {base_symbol} (${usd_value:.2f}) | {base_token[:10]}...")
        
        # ğŸš€ ç¬¬äºŒå±‚è¿‡æ»¤ï¼šåŒºåˆ†å¿«é€Ÿè·¯å¾„å’Œé™çº§è·¯å¾„
        if use_api_data and pair_info_raw:
            # ============================================
            # å¿«é€Ÿè·¯å¾„ï¼šç›´æ¥ä½¿ç”¨ API è¿”å›çš„æ•°æ®è¿›è¡Œç¬¬äºŒå±‚åˆ¤æ–­
            # ============================================
            logger.info(f"âš¡ [å¿«é€Ÿè·¯å¾„] ä½¿ç”¨APIæ•°æ®è¿›è¡Œç¬¬äºŒå±‚æ£€æŸ¥: {base_token[:10]}...")
            
            token_price_usd = pair_info_raw.get('tokenPriceUsd', 0)
            market_cap = pair_info_raw.get('marketCap', 0)
            
            # è·å–é…ç½®çš„æ—¶é—´é—´éš”
            time_interval = self.time_interval_external  # å¤–ç›˜
            
            # æ ¹æ®æ—¶é—´é—´éš”é€‰æ‹©å¯¹åº”çš„æ¶¨è·Œå¹…å’Œäº¤æ˜“é‡ + é€€è®©ç­–ç•¥
            fallback_info = None  # é€€è®©ä¿¡æ¯
            
            if time_interval == '1m':
                price_change = pair_info_raw.get('priceChange1m', 0) * 100
                volume = pair_info_raw.get('buyAndSellVolume1m', 0)
            elif time_interval == '5m':
                price_change = pair_info_raw.get('priceChange5m', 0) * 100
                volume = pair_info_raw.get('buyAndSellVolume5m', 0)
            elif time_interval == '1h':
                price_change = pair_info_raw.get('priceChange1h', 0) * 100
                volume = pair_info_raw.get('buyAndSellVolume1h', 0)
            else:
                price_change = pair_info_raw.get('priceChange5m', 0) * 100  # é»˜è®¤5åˆ†é’Ÿ
                volume = pair_info_raw.get('buyAndSellVolume5m', 0)
            
            # æ—¶é—´çª—å£é€€è®©ï¼šå¦‚æœæ•°æ®ä¸º0ï¼Œè‡ªåŠ¨é€€è®©åˆ°æ›´é•¿æ—¶é—´çª—å£
            if price_change == 0 and volume == 0:
                original_interval = time_interval
                fallback_interval = None
                
                # å®šä¹‰é€€è®©é“¾ï¼ˆ1mâ†’5måœæ­¢ï¼Œ5mâ†’1håœæ­¢ï¼‰
                if time_interval == '1m':
                    fallback_interval = '5m'
                elif time_interval == '5m':
                    fallback_interval = '1h'
                
                # å°è¯•é€€è®©
                if fallback_interval:
                    logger.info(f"   ğŸ”„ [å¤–ç›˜å¿«é€Ÿè·¯å¾„] {original_interval}æ•°æ®ä¸º0ï¼Œå°è¯•é€€è®©è‡³{fallback_interval}")
                    
                    if fallback_interval == '5m':
                        fallback_price_change = pair_info_raw.get('priceChange5m', 0) * 100
                        fallback_volume = pair_info_raw.get('buyAndSellVolume5m', 0)
                    elif fallback_interval == '1h':
                        fallback_price_change = pair_info_raw.get('priceChange1h', 0) * 100
                        fallback_volume = pair_info_raw.get('buyAndSellVolume1h', 0)
                    else:
                        fallback_price_change = 0
                        fallback_volume = 0
                    
                    if fallback_price_change != 0 or fallback_volume != 0:
                        # é€€è®©æˆåŠŸ
                        price_change = fallback_price_change
                        volume = fallback_volume
                        time_interval = fallback_interval
                        fallback_info = {
                            'original': original_interval,
                            'fallback': fallback_interval,
                            'reason': f'{original_interval}æ•°æ®ä¸º0'
                        }
                        # Prometheus: æ—¶é—´çª—å£é€€è®©è®¡æ•°
                        if HAS_PROMETHEUS:
                            self.metrics_fallback.labels(original=original_interval, fallback=fallback_interval).inc()
                        logger.info(f"   âœ… é€€è®©æˆåŠŸ: ä½¿ç”¨{fallback_interval}æ•°æ® (æ¶¨å¹…{price_change:+.2f}%, äº¤æ˜“é‡${volume:,.2f})")
                    else:
                        logger.info(f"   âŒ {fallback_interval}æ•°æ®ä¹Ÿä¸º0ï¼Œæ— æ³•é€€è®©")
            
            # è·å–å¤–ç›˜é…ç½®ï¼ˆä» external_events_config è¯»å–ï¼‰
            external_config = self.external_events_config
            
            # Prometheus: å¤–ç›˜å¿«é€Ÿè·¯å¾„ç¬¬äºŒå±‚æ£€æŸ¥è®¡æ•°
            if HAS_PROMETHEUS:
                self.metrics_second_layer_check.labels(type='external').inc()
            
            # ç¬¬äºŒå±‚åˆ¤æ–­ï¼šæ¶¨è·Œå¹…å’Œäº¤æ˜“é‡
            min_price_change = external_config.get('priceChange', {}).get('risePercent', 50)  # é»˜è®¤50%
            min_volume = external_config.get('volume', {}).get('threshold', 20000)  # é»˜è®¤$20000
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ¡ä»¶
            triggered_events = []
            
            # æ£€æŸ¥æ¶¨è·Œå¹…
            price_change_enabled = external_config.get('priceChange', {}).get('enabled', True)
            if price_change_enabled:
                if price_change >= min_price_change:
                    triggered_events.append({'event': 'priceChange', 'value': price_change})
                    logger.info(f"   âœ… æ¶¨è·Œå¹…è¾¾æ ‡: {price_change:+.2f}% >= {min_price_change}%")
                else:
                    logger.info(f"   â­ï¸  æ¶¨è·Œå¹…ä¸è¶³: {price_change:.2f}% < {min_price_change}%")
            
            # æ£€æŸ¥äº¤æ˜“é‡
            volume_enabled = external_config.get('volume', {}).get('enabled', True)
            if volume_enabled:
                if volume >= min_volume:
                    triggered_events.append({'event': 'volume', 'value': volume})
                    logger.info(f"   âœ… äº¤æ˜“é‡è¾¾æ ‡: ${volume:.2f} >= ${min_volume}")
                else:
                    logger.info(f"   â­ï¸  äº¤æ˜“é‡ä¸è¶³: ${volume:.2f} < ${min_volume}")
            
            # æ ¹æ®è§¦å‘é€»è¾‘åˆ¤æ–­æ˜¯å¦é€šè¿‡ç¬¬äºŒå±‚
            trigger_logic = self.trigger_logic_external  # 'any' æˆ– 'all'
            
            if trigger_logic == 'all':
                # è¦æ±‚æ‰€æœ‰å¯ç”¨çš„æŒ‡æ ‡éƒ½è¾¾æ ‡
                required_events = []
                if price_change_enabled:
                    required_events.append('priceChange')
                if volume_enabled:
                    required_events.append('volume')
                
                triggered_event_names = {e['event'] for e in triggered_events}
                if not all(evt in triggered_event_names for evt in required_events):
                    logger.info(f"   â­ï¸  æœªæ»¡è¶³'all'è§¦å‘é€»è¾‘ï¼ˆéœ€è¦æ‰€æœ‰æŒ‡æ ‡ï¼‰")
                    return
            elif trigger_logic == 'any':
                # åªè¦æœ‰ä¸€ä¸ªæŒ‡æ ‡è¾¾æ ‡å³å¯
                if not triggered_events:
                    logger.info(f"   â­ï¸  æœªæ»¡è¶³'any'è§¦å‘é€»è¾‘ï¼ˆè‡³å°‘ä¸€ä¸ªæŒ‡æ ‡ï¼‰")
                    return
            
            logger.info(f"âœ… é€šè¿‡ç¬¬äºŒå±‚: è§¦å‘äº‹ä»¶={[e['event'] for e in triggered_events]}")
            
            # å¤–ç›˜å¿«é€Ÿè·¯å¾„é€šè¿‡ç¬¬äºŒå±‚è®¡æ•°
            self.second_layer_pass_external += 1
            if HAS_PROMETHEUS:
                self.metrics_second_layer_pass.labels(type='external').inc()
            
            # æ„å»º token_dataï¼ˆå…¼å®¹åŸæœ‰æ ¼å¼ï¼‰
            token_data = {
                'symbol': token_symbol,
                'price': token_price_usd,
                'price_change': price_change,
                'volume': volume,
                'market_cap': market_cap,
                'buy_tax': pair_info_raw.get('safetyInfo', {}).get('buyTax', 0) if pair_info_raw.get('safetyInfo') else 0,
                'sell_tax': pair_info_raw.get('safetyInfo', {}).get('sellTax', 0) if pair_info_raw.get('safetyInfo') else 0,
                'pool_type': pool_type or 'pancake_v2',
                'pool_emoji': 'ğŸ”¥',
                'is_internal': False,
                'triggered_events': triggered_events,
                'fallback_info': fallback_info  # æ—¶é—´çª—å£é€€è®©ä¿¡æ¯
            }
        else:
            # ============================================
            # é™çº§è·¯å¾„ï¼šå¦‚æœ no_data_pair å·²ç¼“å­˜ï¼Œé¿å…å†æ¬¡è°ƒç”¨ API
            # ============================================
            if skip_api:
                # ç¼“å­˜å‘½ä¸­ï¼špair æ— APIæ•°æ®ï¼Œè·³è¿‡ second_layer_filterï¼ˆé¿å…å†æ¬¡è°ƒç”¨APIï¼‰
                # ç›´æ¥è¿”å›ï¼Œä¸å‘é€å‘Šè­¦ï¼ˆå› ä¸ºæ— æ³•è·å–å‡†ç¡®æŒ‡æ ‡ï¼‰
                logger.info(f"â­ï¸  [å½»åº•è·³è¿‡] pairå·²ç¼“å­˜ä¸ºæ— æ•°æ®ï¼ŒRPCä¹Ÿæ— æ³•æä¾›å®Œæ•´æŒ‡æ ‡: {base_token[:10]}...")
                return
            else:
                # ç¼“å­˜æœªå‘½ä¸­ï¼šæ­£å¸¸è°ƒç”¨ second_layer_filterï¼ˆä¼šè°ƒç”¨ä¸€æ¬¡APIï¼‰
                logger.info(f"ğŸ”„ [é™çº§è·¯å¾„] è°ƒç”¨second_layer_filterè·å–æŒ‡æ ‡: {base_token[:10]}...")
                
                # æ„é€  launchpad_infoï¼ˆå…¼å®¹ second_layer_filterï¼‰
                launchpad_info = {
                    'launchpad': 'fourmeme',
                    'launchpad_status': 1,  # å¤–ç›˜
                    'pair_address': pair_address
                }
                
                # è°ƒç”¨ç»Ÿä¸€çš„ç¬¬äºŒå±‚è¿‡æ»¤
        token_data = await self.second_layer_filter(base_token, pair_address, launchpad_info, is_internal=False)
                
        if not token_data:
            logger.info(f"â­ï¸  [é™çº§è·¯å¾„] ç¬¬äºŒå±‚è¿‡æ»¤æœªé€šè¿‡: {base_token[:10]}...")
            return
        
        logger.info(f"âœ… [é™çº§è·¯å¾„] é€šè¿‡ç¬¬äºŒå±‚: è§¦å‘äº‹ä»¶={[e['event'] for e in token_data.get('triggered_events', [])]}")
        
        # ğŸ”’ å…³é”®ï¼šæ£€æŸ¥å†·å´æœŸï¼ˆåªè¯»ï¼Œä¸è®¾ç½®ï¼‰
        # é¿å…ä¸ºå·²åœ¨å†·å´æœŸçš„ä»£å¸æ„å»ºæ¶ˆæ¯
        if not await self.check_alert_cooldown_readonly(base_token):
            logger.info(f"â³ å†·å´æœŸå†…ï¼Œè·³è¿‡: {base_token}")
            return
        
        # æ„å»ºæ¶ˆæ¯
        quote_formatted = self.format_amount(quote_amount, quote_decimals)
        base_formatted = self.format_amount(base_amount, base_decimals)
        
        pool_emoji = token_data['pool_emoji']
        pool_type = token_data['pool_type']
        is_internal = token_data.get('is_internal', False)
        symbol = token_data.get('symbol', base_symbol)
        price_change = token_data.get('price_change', 0)
        volume = token_data.get('volume', 0)
        market_cap = token_data.get('market_cap', 0)  # parse_token_data å·²è§£æä¸º market_capï¼ˆä¸‹åˆ’çº¿ï¼‰
        buy_tax = token_data.get('buy_tax', 0)
        sell_tax = token_data.get('sell_tax', 0)
        price = token_data.get('price', 0)
        
        # è·å–æ—¶é—´é—´éš”ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
        time_interval = self.time_interval_internal if is_internal else self.time_interval_external
        
        volume_str = format_number(volume)
        market_cap_str = format_number(market_cap)
        
        price_str = f"${price:.5f} USDT" if price >= 0.01 else f"${price:.10f} USDT"
        
        triggered_events = token_data.get('triggered_events', [])
        fallback_info = token_data.get('fallback_info')  # è·å–é€€è®©ä¿¡æ¯
        
        alert_reasons = []
        for event in triggered_events:
            if hasattr(event, 'description'):
                alert_reasons.append(event.description)
            elif isinstance(event, dict):
                if event.get('event') == 'priceChange':
                    alert_reasons.append(f"ğŸ“ˆ {time_interval}æ¶¨å¹… {price_change:+.2f}%")
                elif event.get('event') == 'volume':
                    alert_reasons.append(f"ğŸ’¹ {time_interval}äº¤æ˜“é‡ ${volume_str}")
        
        # å¦‚æœæœ‰é€€è®©ä¿¡æ¯ï¼Œæ·»åŠ åˆ°å‘Šè­¦åŸå› 
        if fallback_info:
            original = fallback_info['original']
            fallback = fallback_info['fallback']
            reason = fallback_info['reason']
            alert_reasons.append(f"âš ï¸ {reason}ï¼Œé‡‡ç”¨{fallback}æ•°æ®")
        
        if not alert_reasons:
            alert_reasons.append(f"ğŸ’° å¤§é¢äº¤æ˜“ ${usd_value:.2f}")
        
        message = f"""<b>ğŸŸ¢ BSC ä¿¡å·</b>

ğŸ’° ä»£å¸: {symbol}
ğŸ“ åç§°: {symbol}
ğŸ”— åˆçº¦: <code>{base_token}</code>
ğŸ”— äº¤æ˜“å“ˆå¸Œ: <code>{tx_hash}</code>

ğŸ“Š <b>å®æ—¶æ•°æ®</b>
ğŸ’µ å½“å‰ä»·æ ¼: {price_str}
ğŸ’ å¸‚å€¼: ${market_cap_str}
ğŸŠ çŠ¶æ€: {pool_emoji} {pool_type}

ğŸ“‰ <b>äº¤æ˜“æ•°æ®</b>
ğŸ’° æœ¬æ¬¡ä¹°å…¥: {quote_formatted} {quote_symbol} (â‰ˆ${usd_value:.2f})
ğŸ è·å¾—ä»£å¸: {base_formatted} {symbol}

âœ¨ <b>è§¦å‘åŸå› </b>
{chr(10).join('â€¢ ' + reason for reason in alert_reasons)}

â° æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        # ç»“æ„åŒ–æ—¥å¿—è¾“å‡ºï¼ˆå¤–ç›˜ï¼‰
        logger.info("å¤–ç›˜äº¤æ˜“è§¦å‘", extra={
            "pool_type": pool_type,
            "symbol": symbol,
            "token": base_token[:10],
            "tx_hash": tx_hash[:10],
            "quote_amount": f"{quote_formatted} {quote_symbol}",
            "usd_value": f"${usd_value:.2f}",
            "base_amount": f"{base_formatted} {symbol}",
            "price_change": f"{price_change:+.2f}%",
            "volume": f"${volume:,.0f}",
            "market_cap": f"${market_cap:,.0f}",
            "buy_tax": f"{buy_tax:.1f}%",
            "sell_tax": f"{sell_tax:.1f}%"
        })
        
        # ğŸš€ å‘é€æ¨é€ï¼ŒæˆåŠŸåæ‰è®¾ç½®å†·å´æœŸ
        send_success = await self.send_alert(message, base_token)
        
        if send_success:
            # âœ… æ’­æŠ¥æˆåŠŸï¼Œè®¾ç½®å†·å´æœŸ
            self.alert_success_count += 1
            if HAS_PROMETHEUS:
                self.metrics_alerts.labels(status='success').inc()
            await self.check_and_set_alert_cooldown(base_token)
            logger.info(f"âœ… å·²è®¾ç½®å†·å´æœŸ: {base_token[:10]}... ({self.cooldown_minutes}åˆ†é’Ÿ)")
        else:
            # âŒ æ’­æŠ¥å¤±è´¥ï¼Œä¸è®¾ç½®å†·å´æœŸï¼Œå…è®¸ä¸‹æ¬¡é‡è¯•
            self.alert_fail_count += 1
            if HAS_PROMETHEUS:
                self.metrics_alerts.labels(status='failure').inc()
            logger.warning(f"âš ï¸  æ’­æŠ¥å¤±è´¥ï¼Œæœªè®¾ç½®å†·å´æœŸ: {base_token[:10]}...")
        
        # è®°å½•åˆ°æ•°æ®åº“å¹¶æ¨é€WebSocketï¼ˆæ— è®ºé€šçŸ¥æ˜¯å¦æˆåŠŸï¼‰
        await asyncio.to_thread(
            self.alert_recorder.write_bsc_alert,
            ca=base_token,
            token_name=symbol,
            token_symbol=symbol,
            single_max=usd_value,
            total_sum=usd_value,
            alert_reasons=alert_reasons,
            block_number=0,  # WebSocketä¸å…³å¿ƒåŒºå—å·
            price_usdt=price,
            pair_address=pair_address,
            market_cap=market_cap,
            price_change=price_change,
            volume_24h=volume,
            holders=0,
            logo="",
            notify_error=None if send_success else "Telegramå‘é€å¤±è´¥"
        )
    
    async def _handle_swap_with_receipt_fallback(self, tx_hash: str, pair_address: str):
        """å¤–ç›˜receiptå…œåº•ï¼šä»äº¤æ˜“å›æ‰§ä¸­æå–Swapäº‹ä»¶"""
        try:
            # è·å–äº¤æ˜“å›æ‰§ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            receipt, _ = self.get_receipt_cached(tx_hash)
            if not receipt:
                logger.debug(f"âš ï¸ è·å–receiptå¤±è´¥: {tx_hash}")
                return
            
            logs = receipt.get("logs", [])
            swap_topic = self.TOPIC_V2_SWAP
            
            # æŸ¥æ‰¾Swapäº‹ä»¶
            for log in logs:
                topics = log.get("topics", [])
                log_addr = log.get("address", "").lower()
                
                # åŒ¹é…Swapäº‹ä»¶
                if topics and topics[0].lower() == swap_topic and log_addr == pair_address:
                    logger.info(f"âœ… Receiptå…œåº•æˆåŠŸ: {tx_hash} (å¤–ç›˜)")
                    # é€’å½’è°ƒç”¨åŸå‡½æ•°å¤„ç†
                    await self.handle_swap_event(log)
                    return
            
            logger.debug(f"âš ï¸ Receiptä¸­æœªæ‰¾åˆ°Swapäº‹ä»¶: {tx_hash}")
        except Exception as e:
            logger.debug(f"âŒ Receiptå…œåº•å¤±è´¥: {e}")
    
    async def handle_proxy_event(self, log: Dict):
        """å¤„ç† Fourmeme Proxy äº‹ä»¶ï¼ˆå†…ç›˜ï¼‰"""
        tx_hash = log.get("transactionHash")
        addr = log.get("address", "").lower()
        topics = log.get("topics", [])
        
        proxy_type = "ä¸»Proxy" if addr == self.FOURMEME_PROXY[0] else "Try Buy"
        
        try:
            dbotx_api = self.get_thread_dbotx_api()
            
            # ========== å¿«é€Ÿè·¯å¾„ï¼šCustom Eventsï¼ˆTokenPurchase/Saleï¼‰==========
            if topics and topics[0] in self.FOURMEME_CUSTOM_EVENTS:
                try:
                    # TokenPurchase/Sale äº‹ä»¶æ ¼å¼ï¼š
                    # event TokenPurchase(address indexed token, address indexed buyer, uint256 cost, uint256 amount)
                    # topics[0]: event signature
                    # topics[1]: token address (indexed)
                    # topics[2]: buyer address (indexed)  
                    # data: cost (uint256) + amount (uint256)
                    
                    if len(topics) < 3:
                        logger.debug(f"âš ï¸ Custom Event topicsä¸è¶³: {len(topics)}")
                        # ç»§ç»­èµ°å…œåº•é€»è¾‘
                    else:
                        target_token = ("0x" + topics[1][-40:]).lower()
                        buyer = ("0x" + topics[2][-40:]).lower()
                        
                        # è§£ç  data
                        # TokenPurchaseäº‹ä»¶å®Œæ•´æ ¼å¼ï¼š8ä¸ªéç´¢å¼•å‚æ•°
                        # (address indexed token, address indexed buyer, 
                        #  address payToken, uint256 payAmount, uint256 getAmount, 
                        #  uint256 curvePrice, uint256 protocolFee, uint256 subjectFee, 
                        #  uint256 referralFee, uint256 supply)
                        data = log.get("data", "0x")
                        if data and len(data) >= 66:
                            try:
                                # ä½¿ç”¨eth_abiè§£ç ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                                if HAS_ETH_ABI:
                                    try:
                                        decoded = eth_abi_decode(['address', 'uint256', 'uint256', 'uint256', 'uint256', 'uint256', 'uint256', 'uint256'], bytes.fromhex(data[2:]))
                                        pay_token = decoded[0]  # æ”¯ä»˜ä»£å¸åœ°å€
                                        cost = decoded[1]  # æ”¯ä»˜é‡‘é¢
                                        amount = decoded[2]  # è·å¾—ä»£å¸æ•°é‡
                                    except:
                                        # Fallback: æ‰‹åŠ¨è§£æå‰2ä¸ªuint256
                                        cost = int(data[2:66], 16) if len(data) >= 66 else 0
                                        amount = int(data[66:130], 16) if len(data) >= 130 else 0
                                else:
                                    # Fallback: æ‰‹åŠ¨è§£æ
                                    # è·³è¿‡ç¬¬ä¸€ä¸ªaddress(32å­—èŠ‚)ï¼Œå–ç¬¬2ã€3ä¸ªuint256
                                    cost = int(data[66:130], 16) if len(data) >= 130 else 0
                                    amount = int(data[130:194], 16) if len(data) >= 194 else 0
                                
                                if cost > 0:
                                    logger.info(f"âš¡ [å†…ç›˜å¿«é€Ÿ] Custom Event: {tx_hash[:10]}...")
                                    logger.info(f"   Token: {target_token[:10]}... | Buyer: {buyer[:10]}...")
                                    logger.info(f"   Cost: {cost} (raw) | Amount: {amount} (raw)")
                                    
                                    # ç›´æ¥å¤„ç†ï¼ˆè·³è¿‡ receiptï¼ï¼‰
                                    # å‡è®¾ cost æ˜¯ USDTï¼ˆ18 decimalsï¼‰ï¼Œå¦‚æœæ˜¯ WBNB éœ€è¦è¿›ä¸€æ­¥åˆ¤æ–­
                                    quote_token = self.USDT  # é»˜è®¤ USDTï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                                    quote_amount = cost
                                    quote_symbol = "USDT"
                                    target_amount = amount
                                    
                                    # è·å– token symbol å’Œ decimals
                                    target_symbol = self.get_token_symbol(target_token)
                                    quote_decimals = self.get_decimals(quote_token)
                                    target_decimals = self.get_decimals(target_token)
                                    
                                    # è®¡ç®— USD ä»·å€¼ï¼ˆcost å°±æ˜¯æ”¯ä»˜çš„ USDTï¼‰
                                    quote_value = Decimal(quote_amount) / (Decimal(10) ** Decimal(quote_decimals))
                                    usd_value = float(quote_value)  # USDT â‰ˆ $1
                                    
                                    # ç¬¬ä¸€å±‚è¿‡æ»¤ï¼šé‡‘é¢æ£€æŸ¥
                                    if not self.first_layer_filter(usd_value, is_internal=True):
                                        logger.debug(f"â­ï¸  [å†…ç›˜å¿«é€Ÿ] é‡‘é¢ä¸è¶³: {target_symbol} (${usd_value:.2f})")
                                        return
                                    
                                    logger.info(f"âœ… [å†…ç›˜å¿«é€Ÿ] {target_symbol} ä¹°å…¥ ${usd_value:.2f}")
                                    
                                    # å†·å´æœŸæ£€æŸ¥ï¼ˆåªè¯»ï¼‰
                                    if not await self.check_alert_cooldown_readonly(target_token):
                                        logger.info(f"â³ [å†…ç›˜å¿«é€Ÿ] å†·å´æœŸå†…ï¼Œè·³è¿‡: {target_token[:10]}...")
                                        return
                                    
                                    # è·å– launchpad ä¿¡æ¯ï¼ˆè½»é‡ API è°ƒç”¨ï¼‰
                                    launchpad_info = await dbotx_api.get_token_launchpad_info('bsc', target_token)
                                    if not launchpad_info:
                                        # Fallbackï¼šæ„é€ åŸºç¡€ä¿¡æ¯
                                        launchpad_info = {
                                            'launchpad': 'fourmeme',
                                            'pair_address': None
                                        }
                                    
                                    pair_address = launchpad_info.get('pair_address')
                                    if not pair_address:
                                        logger.debug(f"âš ï¸ [å†…ç›˜å¿«é€Ÿ] æ— pairåœ°å€: {target_token[:10]}...")
                                        return
                                    
                                    # ç¬¬äºŒå±‚è¿‡æ»¤ï¼ˆè·å–å¸‚å€¼ç­‰ï¼‰
                                    token_data = await self.second_layer_filter(target_token, pair_address, launchpad_info, is_internal=True)
                                    if not token_data:
                                        logger.debug(f"â­ï¸  [å†…ç›˜å¿«é€Ÿ] æœªé€šè¿‡ç¬¬äºŒå±‚è¿‡æ»¤: {target_token[:10]}...")
                                        return
                                    
                                    # è®¾ç½®å†·å´æœŸï¼ˆåŸå­æ“ä½œï¼‰
                                    if not await self.check_and_set_alert_cooldown(target_token):
                                        logger.info(f"â³ [å†…ç›˜å¿«é€Ÿ] å†·å´æœŸå†…ï¼ˆç«æ€ï¼‰ï¼Œè·³è¿‡: {target_token[:10]}...")
                                        return
                                    
                                    # æ„å»ºå¹¶å‘é€å‘Šè­¦
                                    await self._send_internal_alert(
                                        tx_hash=tx_hash,
                                        target_token=target_token,
                                        target_symbol=target_symbol,
                                        target_amount=target_amount,
                                        target_decimals=target_decimals,
                                        quote_symbol=quote_symbol,
                                        quote_amount=quote_amount,
                                        quote_decimals=quote_decimals,
                                        usd_value=usd_value,
                                        token_data=token_data,
                                        proxy_type=proxy_type
                                    )
                                    
                                    logger.info(f"ğŸ“¤ [å†…ç›˜å¿«é€Ÿ] å‘Šè­¦å·²å‘é€: {target_symbol} ${usd_value:.2f}")
                                    return  # âš¡ å¿«é€Ÿè¿”å›ï¼Œä¸èµ° receipt é€»è¾‘
                            except Exception as e:
                                logger.debug(f"Custom Event è§£ç å¤±è´¥: {e}")
                                # ç»§ç»­èµ°å…œåº•é€»è¾‘
                except Exception as e:
                    logger.debug(f"Custom Event å¿«é€Ÿè·¯å¾„å¤±è´¥: {e}")
                    # ç»§ç»­èµ°å…œåº•é€»è¾‘
            
            # ========== å…œåº•è·¯å¾„ï¼šä» Receipt è§£æ Transfer ==========
            # è·å–äº¤æ˜“å›æ‰§ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            receipt, tx_info = self.get_receipt_cached(tx_hash)
            if not receipt:
                return
            
            logs = receipt.get("logs", [])
            
            # è§£æ Transfer äº‹ä»¶
            transfer_topic = "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"
            transfers = []
            
            for log in logs:
                topics = log.get("topics", [])
                if not topics or topics[0] != transfer_topic:
                    continue
                
                token_addr = log.get("address", "").lower()
                data = log.get("data", "0x")
                
                if len(topics) >= 3:
                    from_addr = "0x" + topics[1][-40:]
                    to_addr = "0x" + topics[2][-40:]
                    
                    try:
                        value = int(data, 16) if data and data != "0x" else 0
                    except:
                        value = 0
                    
                    transfers.append({
                        "token": token_addr,
                        "from": from_addr.lower(),
                        "to": to_addr.lower(),
                        "value": value
                    })
            
            if not transfers:
                return
            
            # æ‰¾å‡ºä¹°å…¥çš„ USDT/WBNB
            usdt_in = sum(t["value"] for t in transfers 
                         if t["token"] == self.USDT and t["to"] in self.FOURMEME_PROXY)
            wbnb_in = sum(t["value"] for t in transfers 
                         if t["token"] == self.WBNB and t["to"] in self.FOURMEME_PROXY)
            
            # è·å–äº¤æ˜“ä¿¡æ¯ï¼ˆBNB ä¹°å…¥ï¼Œå·²ä»ç¼“å­˜è·å–ï¼‰
            tx_value = 0
            if tx_info and tx_info.get("value"):
                try:
                    tx_value = int(tx_info["value"], 16)
                except:
                    pass
            
            # ç¡®å®šä»˜å‡ºçš„åŸºå‡†å¸
            quote_token = None
            quote_amount = 0
            quote_symbol = ""
            
            if usdt_in > 0:
                quote_token = self.USDT
                quote_amount = usdt_in
                quote_symbol = "USDT"
            elif wbnb_in > 0:
                quote_token = self.WBNB
                quote_amount = wbnb_in
                quote_symbol = "WBNB"
            elif tx_value > 0:
                quote_token = self.WBNB
                quote_amount = tx_value
                quote_symbol = "BNB"
            else:
                return
            
            # æ‰¾å‡ºç›®æ ‡ä»£å¸
            target_tokens = {}
            for t in transfers:
                if (t["from"] in self.FOURMEME_PROXY and 
                    t["token"] not in (self.USDT, self.WBNB)):
                    target_tokens[t["token"]] = target_tokens.get(t["token"], 0) + t["value"]
            
            if not target_tokens:
                return
            
            target_token = max(target_tokens.items(), key=lambda x: x[1])[0]
            target_amount = target_tokens[target_token]
            
            target_symbol = self.get_token_symbol(target_token)
            quote_decimals = self.get_decimals(quote_token)
            target_decimals = self.get_decimals(target_token)
            
            # è®¡ç®— USD ä»·å€¼
            quote_value = Decimal(quote_amount) / (Decimal(10) ** Decimal(quote_decimals))
            if quote_token == self.WBNB:
                wbnb_price = self.get_wbnb_price()
                usd_value = float(quote_value) * wbnb_price
            else:
                usd_value = float(quote_value)
            
            # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šå†…ç›˜ tx è¯¦æƒ…
            logger.info(f"ğŸ” å†…ç›˜tx: hash={tx_hash}, proxy={proxy_type}, input_BNB={quote_amount / 10**quote_decimals:.4f}, usd={usd_value:.2f}, token={target_token}")
            
            # ç¬¬ä¸€å±‚è¿‡æ»¤
            if not self.first_layer_filter(usd_value, is_internal=True):
                logger.debug(f"â­ï¸  å†…ç›˜é‡‘é¢ä¸è¶³: {target_symbol} (${usd_value:.2f}) - {target_token[:10]}...")
                return
            
            # ä¸œå…«åŒºæ—¶é—´
            cn_time = datetime.now(timezone(timedelta(hours=8))).strftime('%H:%M:%S')
            logger.info(f"âœ… [å†…ç›˜] é€šè¿‡ç¬¬ä¸€å±‚: {target_symbol} (${usd_value:.2f}) [{cn_time}]")
            self.first_layer_pass_internal += 1  # å†…ç›˜ç¬¬ä¸€å±‚è®¡æ•°
            
            # Prometheus: ç¬¬ä¸€å±‚é€šè¿‡è®¡æ•°
            if HAS_PROMETHEUS:
                self.metrics_first_layer_pass.labels(type='internal').inc()
            
            # è·å– launchpad ä¿¡æ¯
            launchpad_info = await dbotx_api.get_token_launchpad_info('bsc', target_token)
            if not launchpad_info:
                logger.warning(f"âš ï¸ API miss: hash={tx_hash}, token={target_token} - ä½¿ç”¨ fallback")
                # Fallbackï¼šæ„é€ åŸºç¡€ launchpad_info
                launchpad_info = {
                    'launchpad': 'fourmeme',
                    'pair_address': None  # ç¨åå°è¯•ä» receipt æå–
                }
            
            pair_address = launchpad_info.get('pair_address')
            if not pair_address:
                # å°è¯•ä» receipt çš„ logs ä¸­æå– PancakeV2 Pair åœ°å€
                pair_address = self._extract_pair_from_receipt(logs)
                if pair_address:
                    logger.info(f"âœ… ä» receipt æå–åˆ° pair: {pair_address}")
                    launchpad_info['pair_address'] = pair_address
                else:
                    logger.debug("å†…ç›˜æ— äº¤æ˜“å¯¹åœ°å€", extra={
                        "token": target_token[:10],
                        "symbol": target_symbol
                    })
                    return
            
            # ç¬¬äºŒå±‚è¿‡æ»¤
            token_data = await self.second_layer_filter(target_token, pair_address, launchpad_info, is_internal=True)
            if not token_data:
                return
            
            # æ›´æ–°symbolç¼“å­˜ï¼ˆå¦‚æœç¬¬ä¸€å±‚è·å–å¤±è´¥ï¼Œè¿™é‡Œç”¨DBotXçš„æ­£ç¡®symbolæ›´æ–°ï¼‰
            if target_symbol == "???" and token_data.get('symbol'):
                correct_symbol = token_data.get('symbol')
                try:
                    redis_key = f"token:{target_token}:symbol"
                    self.redis_client.client.setex(redis_key, 86400, correct_symbol)
                    logger.debug(f"âœ… æ›´æ–°symbolç¼“å­˜: {target_token} â†’ {correct_symbol}")
                except:
                    pass
            
            # ğŸ”’ å…³é”®ï¼šæ£€æŸ¥å†·å´æœŸï¼ˆåªè¯»ï¼Œä¸è®¾ç½®ï¼‰
            # é¿å…ä¸ºå·²åœ¨å†·å´æœŸçš„ä»£å¸æ„å»ºæ¶ˆæ¯
            if not await self.check_alert_cooldown_readonly(target_token):
                logger.info(f"â³ å†·å´æœŸå†…ï¼Œè·³è¿‡: {target_token}")
                return
            
            # æ„å»ºæ¶ˆæ¯
            quote_formatted = self.format_amount(quote_amount, quote_decimals)
            target_formatted = self.format_amount(target_amount, target_decimals)
            
            pool_emoji = token_data['pool_emoji']
            pool_type = token_data['pool_type']
            is_internal = token_data.get('is_internal', True)  # Proxyäº‹ä»¶é»˜è®¤æ˜¯å†…ç›˜
            symbol = token_data.get('symbol', target_symbol)
            price_change = token_data.get('price_change', 0)
            volume = token_data.get('volume', 0)
            market_cap = token_data.get('market_cap', 0)  # parse_token_data å·²è§£æä¸º market_capï¼ˆä¸‹åˆ’çº¿ï¼‰
            buy_tax = token_data.get('buy_tax', 0)
            sell_tax = token_data.get('sell_tax', 0)
            price = token_data.get('price', 0)
            
            # è·å–æ—¶é—´é—´éš”ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
            time_interval = self.time_interval_internal if is_internal else self.time_interval_external
            
            volume_str = format_number(volume)
            market_cap_str = format_number(market_cap)
            
            price_str = f"${price:.5f} USDT" if price >= 0.01 else f"${price:.10f} USDT"
            
            triggered_events = token_data.get('triggered_events', [])
            fallback_info = token_data.get('fallback_info')  # è·å–é€€è®©ä¿¡æ¯
            
            alert_reasons = []
            for event in triggered_events:
                if hasattr(event, 'description'):
                    alert_reasons.append(event.description)
                elif isinstance(event, dict):
                    if event.get('event') == 'priceChange':
                        alert_reasons.append(f"ğŸ“ˆ {time_interval}æ¶¨å¹… {price_change:+.2f}%")
                    elif event.get('event') == 'volume':
                        alert_reasons.append(f"ğŸ’¹ {time_interval}äº¤æ˜“é‡ ${volume_str}")
            
            # å¦‚æœæœ‰é€€è®©ä¿¡æ¯ï¼Œæ·»åŠ åˆ°å‘Šè­¦åŸå› 
            if fallback_info:
                original = fallback_info['original']
                fallback = fallback_info['fallback']
                reason = fallback_info['reason']
                alert_reasons.append(f"âš ï¸ {reason}ï¼Œé‡‡ç”¨{fallback}æ•°æ®")
            
            if not alert_reasons:
                alert_reasons.append(f"ğŸ’° å¤§é¢äº¤æ˜“ ${usd_value:.2f}")
            
            message = f"""<b>{pool_emoji} BSC ä¿¡å·</b>

ğŸ’° ä»£å¸: {symbol}
ğŸ“ åç§°: {symbol}
ğŸ”— åˆçº¦: <code>{target_token}</code>
ğŸ”— äº¤æ˜“å“ˆå¸Œ: <code>{tx_hash}</code>

ğŸ“Š <b>å®æ—¶æ•°æ®</b>
ğŸ’µ å½“å‰ä»·æ ¼: {price_str}
ğŸ’ å¸‚å€¼: ${market_cap_str}
ğŸŠ çŠ¶æ€: {pool_emoji} {pool_type}

ğŸ“‰ <b>äº¤æ˜“æ•°æ®</b>
ğŸ’° æœ¬æ¬¡ä¹°å…¥: {quote_formatted} {quote_symbol} (â‰ˆ${usd_value:.2f})
ğŸ è·å¾—ä»£å¸: {target_formatted} {symbol}

âœ¨ <b>è§¦å‘åŸå› </b>
{chr(10).join('â€¢ ' + reason for reason in alert_reasons)}

â° æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            # ç»“æ„åŒ–æ—¥å¿—è¾“å‡ºï¼ˆå†…ç›˜ï¼‰
            logger.info("å†…ç›˜äº¤æ˜“è§¦å‘", extra={
                "pool_type": pool_type,
                "proxy_type": proxy_type,
                "symbol": symbol,
                "token": target_token[:10],
                "tx_hash": tx_hash[:10],
                "quote_amount": f"{quote_formatted} {quote_symbol}",
                "usd_value": f"${usd_value:.2f}",
                "target_amount": f"{target_formatted} {symbol}",
                "price_change": f"{price_change:+.2f}%",
                "volume": f"${volume:,.0f}",
                "market_cap": f"${market_cap:,.0f}",
                "buy_tax": f"{buy_tax:.1f}%",
                "sell_tax": f"{sell_tax:.1f}%"
            })
            
            # ğŸš€ å‘é€æ¨é€ï¼ŒæˆåŠŸåæ‰è®¾ç½®å†·å´æœŸ
            send_success = await self.send_alert(message, target_token)
            
            if send_success:
                # âœ… æ’­æŠ¥æˆåŠŸï¼Œè®¾ç½®å†·å´æœŸ
                self.alert_success_count += 1
                if HAS_PROMETHEUS:
                    self.metrics_alerts.labels(status='success').inc()
                await self.check_and_set_alert_cooldown(target_token)
                logger.info(f"âœ… å·²è®¾ç½®å†·å´æœŸ: {target_token[:10]}... ({self.cooldown_minutes}åˆ†é’Ÿ)")
            else:
                # âŒ æ’­æŠ¥å¤±è´¥ï¼Œä¸è®¾ç½®å†·å´æœŸï¼Œå…è®¸ä¸‹æ¬¡é‡è¯•
                self.alert_fail_count += 1
                if HAS_PROMETHEUS:
                    self.metrics_alerts.labels(status='failure').inc()
                logger.warning(f"âš ï¸  æ’­æŠ¥å¤±è´¥ï¼Œæœªè®¾ç½®å†·å´æœŸ: {target_token[:10]}...")
            
            # è®°å½•åˆ°æ•°æ®åº“å¹¶æ¨é€WebSocketï¼ˆæ— è®ºé€šçŸ¥æ˜¯å¦æˆåŠŸï¼‰
            await asyncio.to_thread(
                self.alert_recorder.write_bsc_alert,
                ca=target_token,
                token_name=symbol,
                token_symbol=symbol,
                single_max=usd_value,
                total_sum=usd_value,
                alert_reasons=alert_reasons,
                block_number=0,  # WebSocketä¸å…³å¿ƒåŒºå—å·
                price_usdt=price,
                pair_address=pair_address,
                market_cap=market_cap,
                price_change=price_change,
                volume_24h=volume,
                holders=0,
                logo="",
                notify_error=None if send_success else "Telegramå‘é€å¤±è´¥"
            )
        
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å†…ç›˜äº¤æ˜“å‡ºé”™: {e}")
    
    async def _send_internal_alert(
        self,
        tx_hash: str,
        target_token: str,
        target_symbol: str,
        target_amount: int,
        target_decimals: int,
        quote_symbol: str,
        quote_amount: int,
        quote_decimals: int,
        usd_value: float,
        token_data: dict,
        proxy_type: str
    ):
        """å‘é€å†…ç›˜å‘Šè­¦ï¼ˆä¾›å¿«é€Ÿè·¯å¾„å’Œå…œåº•è·¯å¾„å…±ç”¨ï¼‰"""
        try:
            # æ ¼å¼åŒ–é‡‘é¢
            quote_formatted = self.format_amount(quote_amount, quote_decimals)
            target_formatted = self.format_amount(target_amount, target_decimals)
            
            # æå– token_data
            pool_emoji = token_data['pool_emoji']
            pool_type = token_data['pool_type']
            is_internal = token_data.get('is_internal', True)
            symbol = token_data.get('symbol', target_symbol)
            price_change = token_data.get('price_change', 0)
            volume = token_data.get('volume', 0)
            market_cap = token_data.get('market_cap', 0)
            price = token_data.get('price', 0)
            
            # æ ¼å¼åŒ–æ•°å­—ï¼ˆä½¿ç”¨å·²å¯¼å…¥çš„format_numberï¼‰
            volume_str = format_number(volume)
            market_cap_str = format_number(market_cap)
            price_str = f"${price:.5f} USDT" if price >= 0.01 else f"${price:.10f} USDT"
            
            # è·å–æ—¶é—´é—´éš”
            time_interval = self.time_interval_internal if is_internal else self.time_interval_external
            
            # æ„å»ºå‘Šè­¦åŸå› 
            triggered_events = token_data.get('triggered_events', [])
            alert_reasons = []
            for event in triggered_events:
                if hasattr(event, 'description'):
                    alert_reasons.append(event.description)
                elif isinstance(event, dict):
                    if event.get('event') == 'priceChange':
                        alert_reasons.append(f"ğŸ“ˆ {time_interval}æ¶¨å¹… {price_change:+.2f}%")
                    elif event.get('event') == 'volume':
                        alert_reasons.append(f"ğŸ’¹ {time_interval}äº¤æ˜“é‡ ${volume_str}")
            
            if not alert_reasons:
                alert_reasons.append(f"ğŸ’° å¤§é¢äº¤æ˜“ ${usd_value:.2f}")
            
            # æ„å»ºæ¶ˆæ¯
            message = f"""<b>{pool_emoji} BSC ä¿¡å·</b>

ğŸ’° ä»£å¸: {symbol}
ğŸ“ åç§°: {symbol}
ğŸ”— åˆçº¦: <code>{target_token}</code>

ğŸ“Š <b>å®æ—¶æ•°æ®</b>
ğŸ’µ å½“å‰ä»·æ ¼: {price_str}
ğŸ’ å¸‚å€¼: ${market_cap_str}
ğŸŠ çŠ¶æ€: {pool_emoji} {pool_type}

ğŸ“‰ <b>äº¤æ˜“æ•°æ®</b>
ğŸ’° æœ¬æ¬¡ä¹°å…¥: {quote_formatted} {quote_symbol} (â‰ˆ${usd_value:.2f})
ğŸ“Š {time_interval}äº¤æ˜“é‡: ${volume_str}
ğŸ“ˆ {time_interval}æ¶¨è·Œå¹…: {price_change:+.2f}%

ğŸ”” <b>è§¦å‘åŸå› </b>
{chr(10).join(alert_reasons)}
"""
            
            # ä½¿ç”¨ç°æœ‰æ–¹æ³•å‘é€ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºGMGN+AxiomæŒ‰é’®ï¼‰
            send_success = await self.send_alert(message, target_token)
            
            # è®°å½•åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨ç°æœ‰recorderï¼‰
            if hasattr(self, 'alert_recorder') and self.alert_recorder:
                try:
                    await self.alert_recorder.write_bsc_alert(
                        token=target_token,
                        symbol=symbol,
                        tx_hash=tx_hash,
                        pool_type=pool_type,
                        price_change=price_change,
                        volume=volume,
                        market_cap=market_cap,
                        amount=usd_value,
                        alert_reason=", ".join(alert_reasons),
                        notify_error=None if send_success else "Telegramå‘é€å¤±è´¥"
                    )
                except Exception as e:
                    logger.debug(f"è®°å½•å‘Šè­¦åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            
            logger.info(f"âœ… [å†…ç›˜] å‘Šè­¦å·²å‘é€: {symbol} ${usd_value:.2f}")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€å†…ç›˜å‘Šè­¦å¤±è´¥: {e}")
    
    
    def health_check_loop(self):
        """å¥åº·æ£€æŸ¥å¾ªç¯ï¼ˆæ¯åˆ†é’Ÿè¾“å‡ºä¸€æ¬¡çŠ¶æ€ï¼‰"""
        while not self.should_stop:
            try:
                time.sleep(60)  # æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡
                
                if self.should_stop:
                    break
                
                now = time.time()
                idle_seconds = int(now - self.last_message_time)
                
                # å»é‡ç¼“å­˜å®šæœŸæ¸…ç†ï¼ˆè¶…è¿‡ 80% å®¹é‡æ—¶æ¸…ç†æœ€è€çš„ 20%ï¼‰
                seen_txs_size = len(self.seen_txs)
                if seen_txs_size > self.max_seen_txs * 0.8:
                    cleanup_count = int(self.max_seen_txs * 0.2)
                    for _ in range(cleanup_count):
                        if self.seen_txs:
                            self.seen_txs.popitem(last=False)  # å¼¹å‡ºæœ€è€çš„
                    logger.info(f"ğŸ§¹ å»é‡ç¼“å­˜æ¸…ç†: ç§»é™¤ {cleanup_count} æ¡æ—§è®°å½• ({seen_txs_size} â†’ {len(self.seen_txs)})")
                
                # è®¡ç®—è¿è¡Œæ—¶é•¿
                running_seconds = int(time.time() - self.start_time)
                running_hours = running_seconds // 3600
                running_minutes = (running_seconds % 3600) // 60
                running_secs = running_seconds % 60
                uptime_str = f"{running_hours}æ—¶{running_minutes}åˆ†{running_secs}ç§’" if running_hours > 0 else f"{running_minutes}åˆ†{running_secs}ç§’"
                
                logger.info("=" * 80)
                logger.info("ğŸ’“ WebSocket å¥åº·æ£€æŸ¥")
                logger.info(f"   çŠ¶æ€: {'ğŸŸ¢ è¿è¡Œä¸­' if self.ws and not self.should_stop else 'ğŸ”´ å·²åœæ­¢'}")
                logger.info(f"   è¿è¡Œæ—¶é•¿: {uptime_str}")
                logger.info(f"   é‡è¿æ¬¡æ•°: {self.reconnect_count}")
                logger.info(f"   å›è¡¥æ¬¡æ•°: {self.backfill_count} (å†·å´æœŸ: {self.backfill_cooldown}s)")
                logger.info(f"   æ¶ˆæ¯æ€»æ•°: {self.message_count}")
                logger.info(f"   å»é‡ç¼“å­˜: {len(self.seen_txs)} / {self.max_seen_txs} ({len(self.seen_txs) / self.max_seen_txs * 100:.1f}%)")
                
                # å›æ‰§ç¼“å­˜è¯¦ç»†ç»Ÿè®¡
                total_cache_requests = self.receipt_cache_hits + self.receipt_cache_misses
                hit_rate = (self.receipt_cache_hits / total_cache_requests * 100) if total_cache_requests > 0 else 0
                avg_wait_time = (self.receipt_cache_wait_time_total / self.receipt_cache_concurrent_waits) if self.receipt_cache_concurrent_waits > 0 else 0
                
                logger.info(f"   å›æ‰§ç¼“å­˜: {len(self.receipt_cache)} æ¡")
                logger.info(f"      â”œâ”€ å‘½ä¸­: {self.receipt_cache_hits} æ¬¡ ({hit_rate:.1f}% å‘½ä¸­ç‡)")
                logger.info(f"      â”œâ”€ æœªå‘½ä¸­: {self.receipt_cache_misses} æ¬¡")
                logger.info(f"      â”œâ”€ å¹¶å‘ç­‰å¾…: {self.receipt_cache_concurrent_waits} æ¬¡ï¼ˆèŠ‚çœRPCï¼‰")
                
                # ç­‰å¾…è€—æ—¶ç»Ÿè®¡
                if self.receipt_cache_concurrent_waits > 0:
                    logger.info(f"      â”‚  â”œâ”€ å¹³å‡è€—æ—¶: {avg_wait_time:.2f}s/æ¬¡")
                    logger.info(f"      â”‚  â”œâ”€ ç´¯è®¡è€—æ—¶: {self.receipt_cache_wait_time_total:.1f}s")
                    if self.receipt_cache_wait_timeouts > 0:
                        timeout_rate = (self.receipt_cache_wait_timeouts / self.receipt_cache_concurrent_waits * 100)
                        logger.info(f"      â”‚  â””â”€ âš ï¸ è¶…æ—¶: {self.receipt_cache_wait_timeouts} æ¬¡ ({timeout_rate:.1f}%)")
                    else:
                        logger.info(f"      â”‚  â””â”€ âœ… æ— è¶…æ—¶")
                
                logger.info(f"      â””â”€ å¤±è´¥ç¼“å­˜å‘½ä¸­: {self.receipt_cache_failed_hits} æ¬¡ï¼ˆé¿å…é‡è¯•ï¼‰")
                
                logger.info(f"   eth_callç¼“å­˜: {len(self.eth_call_cache)} æ¡ (å‘½ä¸­ {self.eth_call_cache_hits} æ¬¡, èŠ‚çœRPC)")
                logger.info(f"   éfourmemeç¼“å­˜: {self.cache_hit_count} æ¬¡ï¼ˆèŠ‚çœAPIè°ƒç”¨ï¼‰")
                
                # ç¬¬ä¸€å±‚/ç¬¬äºŒå±‚ç»Ÿè®¡
                total_first_layer = self.first_layer_pass_internal + self.first_layer_pass_external
                total_second_check = self.second_layer_check_internal + self.second_layer_check_external
                total_second_pass = self.second_layer_pass_internal + self.second_layer_pass_external
                
                logger.info(f"   ç¬¬ä¸€å±‚è¿‡æ»¤: é€šè¿‡ {total_first_layer} ä¸ª")
                if total_first_layer > 0:
                    internal_pct = (self.first_layer_pass_internal / total_first_layer * 100)
                    external_pct = (self.first_layer_pass_external / total_first_layer * 100)
                    logger.info(f"      â”œâ”€ ğŸ”´ å†…ç›˜: {self.first_layer_pass_internal} ({internal_pct:.1f}%)")
                    logger.info(f"      â””â”€ ğŸŸ¢ å¤–ç›˜: {self.first_layer_pass_external} ({external_pct:.1f}%)")
                
                logger.info(f"   ç¬¬äºŒå±‚æ£€æŸ¥: {total_second_check} ä¸ª")
                if total_second_check > 0:
                    internal_check_pct = (self.second_layer_check_internal / total_second_check * 100) if total_second_check > 0 else 0
                    external_check_pct = (self.second_layer_check_external / total_second_check * 100) if total_second_check > 0 else 0
                    logger.info(f"      â”œâ”€ ğŸ”´ å†…ç›˜: {self.second_layer_check_internal} ({internal_check_pct:.1f}%)")
                    logger.info(f"      â””â”€ ğŸŸ¢ å¤–ç›˜: {self.second_layer_check_external} ({external_check_pct:.1f}%)")
                    
                    pass_rate = (total_second_pass / total_second_check * 100)
                    fail_count = total_second_check - total_second_pass
                    fail_rate = 100 - pass_rate
                    logger.info(f"      â”œâ”€ âœ… é€šè¿‡: {total_second_pass} ({pass_rate:.1f}%)")
                    logger.info(f"      â”‚  â”œâ”€ ğŸ”´ å†…ç›˜: {self.second_layer_pass_internal}")
                    logger.info(f"      â”‚  â””â”€ ğŸŸ¢ å¤–ç›˜: {self.second_layer_pass_external}")
                    logger.info(f"      â””â”€ âŒ æœªé€šè¿‡: {fail_count} ({fail_rate:.1f}%)")
                
                # å‘Šè­¦å‘é€ç»Ÿè®¡
                total_alerts = self.alert_success_count + self.alert_fail_count
                if total_alerts > 0:
                    success_rate = (self.alert_success_count / total_alerts * 100)
                    logger.info(f"   å‘Šè­¦å‘é€: {total_alerts} æ¬¡")
                    logger.info(f"      â”œâ”€ âœ… æˆåŠŸ: {self.alert_success_count} ({success_rate:.1f}%)")
                    logger.info(f"      â””â”€ âŒ å¤±è´¥: {self.alert_fail_count} ({100-success_rate:.1f}%)")
                
                logger.info(f"   ä¸Šæ¬¡æ¶ˆæ¯: {idle_seconds}ç§’å‰")
                logger.info(f"   ç©ºé—²è­¦å‘Š: {'âš ï¸ è¶…è¿‡5åˆ†é’Ÿæ— æ¶ˆæ¯ï¼' if idle_seconds > 300 else 'âœ… æ­£å¸¸'}")
                logger.info("=" * 80)
                
                # å¦‚æœè¶…è¿‡10åˆ†é’Ÿæ²¡æœ‰æ¶ˆæ¯ï¼Œä¸»åŠ¨é‡è¿
                if idle_seconds > 600 and self.ws:
                    logger.warning("âš ï¸ æ£€æµ‹åˆ°10åˆ†é’Ÿæ— æ¶ˆæ¯ï¼Œä¸»åŠ¨è§¦å‘é‡è¿...")
                    try:
                        self.ws.close()
                    except:
                        pass
                    
            except Exception as e:
                logger.error(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
    
    def on_message(self, ws, message):
        """WebSocket æ¶ˆæ¯å›è°ƒ"""
        try:
            # æ›´æ–°æœ€åæ¶ˆæ¯æ—¶é—´å’Œè®¡æ•°
            self.last_message_time = time.time()
            self.message_count += 1
            
            # Prometheus: æ¶ˆæ¯è®¡æ•°
            if HAS_PROMETHEUS:
                self.metrics_messages.inc()
            
            msg = json.loads(message)
            
            # è·³è¿‡è®¢é˜…ç¡®è®¤ï¼ˆåŒ…å«idä½†ä¸åŒ…å«methodçš„æ¶ˆæ¯ï¼‰
            if "id" in msg and "method" not in msg:
                # è¿™æ˜¯è®¢é˜…ç¡®è®¤æ¶ˆæ¯ï¼Œè®°å½•subscription ID
                sub_id = msg.get("result")
                if sub_id:
                    logger.debug(f"âœ“ è®¢é˜…æˆåŠŸï¼Œsubscription ID: {sub_id}")
                return
            
            # è·å–å®æ—¶äº‹ä»¶ï¼ˆmethod=eth_subscriptionï¼‰
            if msg.get("method") != "eth_subscription":
                logger.warning(f"âš ï¸ æ”¶åˆ°æœªçŸ¥æ¶ˆæ¯ç±»å‹: {msg.get('method', 'unknown')}")
                return
            
            params = msg.get("params", {})
            result = params.get("result", {})
            
            if not isinstance(result, dict):
                return
            
            # å»é‡ï¼ˆä½¿ç”¨ tx_hash:logIndex ç»„åˆé”®ï¼Œæ”¯æŒåŒä¸€äº¤æ˜“çš„å¤šä¸ªæ—¥å¿—ï¼‰
            tx_hash = result.get("transactionHash")
            if not tx_hash:
                # transactionHash å¯èƒ½ä¸º Noneï¼ˆè®¢é˜…ç¡®è®¤ã€éƒ¨åˆ†èŠ‚ç‚¹ bugï¼‰
                return
            
            # logIndex æ˜¯åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼Œè½¬ä¸ºæ•´æ•°é¿å…æ ¼å¼å·®å¼‚ï¼ˆ0x1 vs 0x01ï¼‰
            log_index_hex = result.get("logIndex", "0x0")
            try:
                log_index = int(log_index_hex, 16) if isinstance(log_index_hex, str) else int(log_index_hex or 0)
            except (ValueError, TypeError):
                log_index = 0
            
            # ç»„åˆé”®ï¼štx_hash:logIndex
            key = f"{tx_hash}:{log_index}"
            if key in self.seen_txs:
                logger.debug(f"â­ï¸  å»é‡è·³è¿‡: {tx_hash[:10]}...#{log_index}")
                return
            
            self.seen_txs[key] = True
            logger.debug(f"âœ… å¤„ç†æ—¥å¿—: {tx_hash[:10]}...#{log_index} (ç¼“å­˜å¤§å°: {len(self.seen_txs)})")
            
            # LRUæ·˜æ±°æœ€è€çš„æ—¥å¿—ï¼ˆFIFOï¼‰
            if len(self.seen_txs) > self.max_seen_txs:
                self.seen_txs.popitem(last=False)  # å¼¹å‡ºæœ€æ—©çš„
            
            # æ›´æ–°æœ€åå¤„ç†çš„åŒºå—å·ï¼ˆç”¨äºæ–­çº¿å›è¡¥ï¼‰
            block_number = result.get("blockNumber")
            if block_number:
                try:
                    block_num = int(block_number, 16) if isinstance(block_number, str) else block_number
                    if block_num > self.last_processed_block:
                        self.last_processed_block = block_num
                except:
                    pass
            
            # åˆ¤æ–­äº‹ä»¶ç±»å‹
            topics = result.get("topics", [])
            addr = result.get("address", "").lower()
            
            # é˜²å¾¡æ€§æ£€æŸ¥ï¼štopicså¿…é¡»å­˜åœ¨ä¸”ä¸ä¸ºç©º
            if not topics or len(topics) == 0:
                return
            
            # ç»Ÿä¸€å°å†™ï¼ˆBSCèŠ‚ç‚¹è¿”å›æ˜¯0xå¤§å†™ï¼‰
            topic0 = topics[0].lower() if topics[0] else ""
            if not topic0:
                return
            
            # ========== ç›´æ¥å¤„ç†æ¨¡å¼ï¼ˆç¦ç”¨é˜Ÿåˆ—ï¼Œçº¿ç¨‹æ± ç›´æ¥å¤„ç†ï¼‰==========
            
            # 1ï¸âƒ£ Fourmeme Proxy çš„æ‰€æœ‰äº‹ä»¶ï¼ˆå†…ç›˜äº¤æ˜“ï¼‰
            if addr == self.FOURMEME_PROXY[0].lower():
                # ç›´æ¥ç”¨çº¿ç¨‹æ± å¤„ç†ï¼ˆæ— ç¼“å†²ï¼Œä½å»¶è¿Ÿï¼‰
                self.executor.submit(self._run_async_in_thread, self.handle_proxy_event, result)
                return
            
            # 2ï¸âƒ£ Swap äº‹ä»¶ï¼ˆå¤–ç›˜ï¼šPancakeSwap V2ï¼‰
            elif topic0 == self.TOPIC_V2_SWAP:
                # ç›´æ¥ç”¨çº¿ç¨‹æ± å¤„ç†ï¼ˆæ— ç¼“å†²ï¼Œä½å»¶è¿Ÿï¼‰
                self.executor.submit(self._run_async_in_thread, self.handle_swap_event, result)
                return
            
            # å…¶ä»–äº‹ä»¶ï¼šå¿½ç•¥
            else:
                return
        
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ¶ˆæ¯å‡ºé”™: {e}")
    
    def _run_async_in_thread(self, async_func, *args, **kwargs):
        """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°ï¼ˆä½¿ç”¨ asyncio.run ç®€åŒ–äº‹ä»¶å¾ªç¯ç®¡ç†ï¼‰"""
        asyncio.run(async_func(*args, **kwargs))
    
    def on_open(self, ws):
        """WebSocket è¿æ¥æˆåŠŸå›è°ƒ"""
        is_reconnect = self.reconnect_count > 0
        
        if not is_reconnect:
            logger.info("âœ… WebSocket è¿æ¥æˆåŠŸï¼")
            logger.info(f"èŠ‚ç‚¹: {self.ws_url[:50]}")
        else:
            logger.info(f"âœ… WebSocket é‡è¿æˆåŠŸï¼(ç¬¬{self.reconnect_count}æ¬¡)")
            # é‡è¿åç«‹å³å›è¡¥é—æ¼çš„äº¤æ˜“
            self.executor.submit(self._backfill_missed_logs, f"é‡è¿#{self.reconnect_count}")
        
        self.reconnect_count += 1
        
        # ========== ä¼˜åŒ–åçš„è®¢é˜…ç­–ç•¥ ==========
        
        # 1ï¸âƒ£ è®¢é˜… Fourmeme Proxy çš„æ‰€æœ‰äº‹ä»¶ï¼ˆæ•è·å†…ç›˜äº¤æ˜“ï¼‰
        # æ³¨æ„ï¼šTransferäº‹ä»¶æ˜¯Tokenåˆçº¦å‘å‡ºçš„ï¼Œä¸æ˜¯Proxyå‘å‡ºçš„
        # æ‰€ä»¥éœ€è¦è®¢é˜…Proxyçš„æ‰€æœ‰äº‹ä»¶ï¼Œç„¶ååœ¨handle_proxy_eventä¸­è¿‡æ»¤
        ws.send(json.dumps({
            "jsonrpc": "2.0",
            "id": 1,
            "method": "eth_subscribe",
            "params": ["logs", {
                "address": [self.FOURMEME_PROXY[0]]  # åªè®¢é˜…ä¸»Proxyï¼ˆTryBuyå·²åºŸå¼ƒï¼‰
                # ä¸é™åˆ¶topics - æ•è·æ‰€æœ‰äº‹ä»¶ï¼ˆTokenPurchase/TokenSaleç­‰ï¼‰
            }]
            }))
        logger.info(f"âœ“ è®¢é˜… Fourmeme Proxy æ‰€æœ‰äº‹ä»¶ï¼ˆå†…ç›˜ï¼‰")
        logger.info(f"  ç›‘å¬åœ°å€: {self.FOURMEME_PROXY[0][:10]}...")
        logger.info(f"  æ•è·: TokenPurchase/TokenSale/Custom Events")
        
        # 2ï¸âƒ£ è®¢é˜… PancakeSwap V2 Swap äº‹ä»¶ï¼ˆå¤–ç›˜äº¤æ˜“ï¼‰
        ws.send(json.dumps({
            "jsonrpc": "2.0",
            "id": 2,
            "method": "eth_subscribe",
            "params": ["logs", {"topics": [self.TOPIC_V2_SWAP]}]
        }))
        logger.info(f"âœ“ è®¢é˜… PancakeV2 Swap äº‹ä»¶ï¼ˆå¤–ç›˜ï¼‰")
        
        logger.info("âœ… è®¢é˜…å®Œæˆ")
        logger.info(f"   å†…ç›˜: Proxyæ‰€æœ‰äº‹ä»¶ (TokenPurchase/Saleç­‰) â†’ {self.FOURMEME_PROXY[0][:10]}...")
        logger.info(f"   å¤–ç›˜: å…¨é“¾Swapäº‹ä»¶ â†’ PancakeSwap V2")
        logger.info(f"ğŸ“± Telegram é¢‘é“: {self.bsc_channel_id}")
        logger.info(f"â³ ç­‰å¾…é“¾ä¸Šäº¤æ˜“...")
    
    def on_error(self, ws, error):
        """WebSocket é”™è¯¯å›è°ƒ"""
        logger.error(f"âŒ WebSocket é”™è¯¯: {error}")
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    def on_close(self, ws, close_status_code, close_msg):
        """WebSocket å…³é—­å›è°ƒ"""
        if self.should_stop:
            logger.info(f"âœ… WebSocket è¿æ¥å·²å…³é—­")
        else:
            logger.warning(f"âš ï¸  WebSocket è¿æ¥æ–­å¼€: {close_status_code} - {close_msg}")
            logger.info("ğŸ”„ å°†åœ¨5ç§’åè‡ªåŠ¨é‡è¿...")
    
    def _backfill_missed_logs(self, reason="é‡è¿"):
        """
        æ–­çº¿å›è¡¥ï¼šä½¿ç”¨eth_getLogså›è¡¥é—æ¼çš„äº¤æ˜“ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        
        ä¼˜åŒ–ï¼š
        - 60ç§’å†·å´æœŸï¼Œé˜²æ­¢é¢‘ç¹è§¦å‘
        - ç¦»çº¿æ—¶é—´é˜ˆå€¼ï¼ˆ>30ç§’æ‰å›è¡¥ï¼‰
        - ç¼©å°åŒºå—è·¨åº¦ï¼ˆ200å—ï¼‰
        - è®°å½•è§¦å‘åŸå› å’Œç»Ÿè®¡
        """
        try:
            now = time.time()
            
            # 1. å†·å´æœŸæ£€æŸ¥ï¼ˆ60ç§’å†…ä¸é‡å¤å›è¡¥ï¼‰
            if now - self.last_backfill_time < self.backfill_cooldown:
                elapsed = int(now - self.last_backfill_time)
                logger.info(f"â­ï¸  å›è¡¥å†·å´ä¸­ ({elapsed}s/{self.backfill_cooldown}s)ï¼Œè·³è¿‡æœ¬æ¬¡å›è¡¥ï¼ˆåŸå› ï¼š{reason}ï¼‰")
                return
            
            # è®°å½•å›è¡¥æ—¶é—´å’ŒåŸå› 
            self.last_backfill_time = now
            self.reconnect_time = now
            
            # 2. è·å–å½“å‰åŒºå—
            latest_block_hex = self.rpc_call("eth_blockNumber", [])
            if not latest_block_hex:
                logger.warning("âŒ è·å–æœ€æ–°åŒºå—å¤±è´¥ï¼Œè·³è¿‡å›è¡¥")
                return
            
            latest_block = int(latest_block_hex, 16)
            
            # 3. è®¡ç®—å›è¡¥åŒºå—èŒƒå›´
            if self.last_processed_block == 0:
                # é¦–æ¬¡è¿æ¥ï¼Œåªå›è¡¥æœ€è¿‘50ä¸ªåŒºå—ï¼ˆçº¦15ç§’ï¼‰
                from_block = max(latest_block - 50, 0)
                offline_seconds = "é¦–æ¬¡è¿æ¥"
            else:
                # è®¡ç®—ç¦»çº¿æ—¶é—´ï¼ˆæŒ‰3ç§’/å—ä¼°ç®—ï¼‰
                missed_blocks = latest_block - self.last_processed_block
                offline_seconds = missed_blocks * 3  # BSC çº¦3ç§’/å—
                
                # ç¦»çº¿æ—¶é—´é˜ˆå€¼ï¼šåªåœ¨ç¦»çº¿ > 30ç§’ æ‰å›è¡¥
                if offline_seconds < 30:
                    logger.info(f"â­ï¸  ç¦»çº¿æ—¶é—´è¿‡çŸ­ ({offline_seconds:.0f}s < 30s)ï¼Œè·³è¿‡å›è¡¥ï¼ˆåŸå› ï¼š{reason}ï¼‰")
                    self.last_processed_block = latest_block
                    return
                
                # é™åˆ¶å›è¡¥åŒºå—è·¨åº¦ï¼ˆæœ€å¤š200å—ï¼Œçº¦10åˆ†é’Ÿï¼‰
                max_backfill_blocks = 200
                from_block = max(self.last_processed_block, latest_block - max_backfill_blocks)
            
            block_span = latest_block - from_block
            self.backfill_count += 1
            
            logger.info(f"ğŸ”„ [å›è¡¥ #{self.backfill_count}] å¼€å§‹: #{from_block} â†’ #{latest_block} ({block_span}å—, ç¦»çº¿â‰ˆ{offline_seconds}s, åŸå› :{reason})")
            
            # 4. åˆ†æ‰¹æŸ¥è¯¢ï¼ˆç¼©å°batchï¼Œé™ä½å•æ¬¡è¯·æ±‚å‹åŠ›ï¼‰
            batch_size = 200  # ä»1000æ”¹ä¸º200
            total_logs = 0
            
            for start in range(from_block, latest_block + 1, batch_size):
                end = min(start + batch_size - 1, latest_block)
                
                # æŸ¥è¯¢Proxyç›¸å…³çš„æ—¥å¿—
                logs = self.rpc_call("eth_getLogs", [{
                    "fromBlock": hex(start),
                    "toBlock": hex(end),
                    "address": self.FOURMEME_PROXY
                }])
                
                if logs and isinstance(logs, list):
                    total_logs += len(logs)
                    # å¤„ç†æ¯æ¡æ—¥å¿—
                    for log in logs:
                        try:
                            # å¼‚æ­¥å¤„ç†æ—¥å¿—ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­ï¼‰
                            self.executor.submit(self._run_async_in_thread, self._process_backfill_log, log)
                        except Exception as e:
                            logger.debug(f"å¤„ç†å›è¡¥æ—¥å¿—å¤±è´¥: {e}")
            
            logger.info(f"âœ… [å›è¡¥ #{self.backfill_count}] å®Œæˆ: å…±å¤„ç† {total_logs} æ¡æ—¥å¿—")
            self.last_processed_block = latest_block
            
        except Exception as e:
            logger.error(f"âŒ [å›è¡¥ #{self.backfill_count}] å¤±è´¥: {e}")
    
    async def _process_backfill_log(self, log):
        """å¤„ç†å›è¡¥çš„æ—¥å¿—"""
        try:
            # åˆ¤æ–­æ˜¯å†…ç›˜è¿˜æ˜¯å¤–ç›˜
            topics = log.get("topics", [])
            if not topics:
                return
            
            topic0 = topics[0].lower() if topics[0] else ""
            addr = log.get("address", "").lower()
            
            # å†…ç›˜äº‹ä»¶
            if topic0 in self.FOURMEME_CUSTOM_EVENTS or addr in self.FOURMEME_PROXY:
                await self.handle_proxy_event(log)
        except Exception as e:
            logger.debug(f"å¤„ç†å›è¡¥æ—¥å¿—å¼‚å¸¸: {e}")
    
    def signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼ˆCtrl+Cï¼‰"""
        logger.info("\nâš ï¸  æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
        self.should_stop = True
        
        if self.ws:
            self.ws.close()
        
        # å…³é—­ HTTP Session
        if hasattr(self, 'session'):
            try:
                self.session.close()
                logger.info("âœ… HTTP Session å·²å…³é—­")
            except Exception as e:
                logger.debug(f"å…³é—­ Session å¼‚å¸¸: {e}")
        
        self.executor.shutdown(wait=False)
        

        os._exit(0)
    
    async def start(self):
        """å¯åŠ¨ç›‘æ§"""
        # åŠ è½½é…ç½®
        await self.load_config_from_redis()
        
        # ========== ç›´æ¥å¤„ç†æ¨¡å¼ ==========
        logger.info("ğŸš€ ä½¿ç”¨ç›´æ¥å¤„ç†æ¨¡å¼ï¼ˆæ— é˜Ÿåˆ—ç¼“å†²ï¼Œçº¿ç¨‹æ± ç›´æ¥å¤„ç†ï¼‰")
        logger.info(f"âœ… çº¿ç¨‹æ± : {self.executor._max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
        logger.info(f"   æ¶æ„: WebSocket â†’ çº¿ç¨‹æ± ({self.executor._max_workers}çº¿ç¨‹) â†’ å¼‚æ­¥å¤„ç†")
        logger.info(f"   ç‰¹ç‚¹: ä½å»¶è¿Ÿã€é«˜å¹¶å‘ã€æ— ç¼“å†²ç§¯å‹")
        
        # æ³¨å†Œä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
        # åˆ›å»º WebSocketï¼ˆæ·»åŠ  ping/pong å¿ƒè·³ä¿æ´»ï¼‰
        websocket.enableTrace(False)
        
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œ WebSocketï¼ˆæ·»åŠ å¿ƒè·³å’Œè‡ªåŠ¨é‡è¿ï¼‰
        def run_ws_with_retry():
            """å¸¦é‡è¿æœºåˆ¶çš„ WebSocket è¿è¡Œå¾ªç¯"""
            retry_count = 0
            while not self.should_stop:
                try:
                    logger.info(f"ğŸ”Œ WebSocket è¿æ¥å°è¯•... (ç¬¬{retry_count + 1}æ¬¡)")
                    
                    # æ¯æ¬¡é‡è¿éƒ½åˆ›å»ºæ–°çš„ WebSocket å¯¹è±¡
                    self.ws = websocket.WebSocketApp(
                        self.ws_url,
                        on_message=self.on_message,
                        on_open=self.on_open,
                        on_error=self.on_error,
                        on_close=self.on_close
                    )
                    
                    # OPTIMIZED: å‡å°‘å¿ƒè·³é—´éš”ï¼Œæé«˜WSç¨³å®šæ€§ï¼ˆNodeRealå»¶è¿Ÿé«˜ï¼‰
                    self.ws.run_forever(
                        ping_interval=10,    # æ¯10ç§’å‘é€pingï¼ˆé™ä½é‡è¿é£é™©ï¼‰
                        ping_timeout=5,      # pingè¶…æ—¶5ç§’ï¼ˆå¿«é€Ÿæ£€æµ‹æ–­çº¿ï¼‰
                        skip_utf8_validation=True
                    )
                    
                    # å¦‚æœæ­£å¸¸é€€å‡ºï¼ˆç”¨æˆ·åœæ­¢ï¼‰ï¼Œè·³å‡ºå¾ªç¯
                    if self.should_stop:
                        break
                    
                    # å¼‚å¸¸é€€å‡ºï¼Œç­‰å¾…åé‡è¿
                    retry_count += 1
                    wait_seconds = min(5 * retry_count, 60)  # æœ€å¤šç­‰60ç§’
                    logger.warning(f"â³ WebSocket æ–­å¼€ï¼Œ{wait_seconds}ç§’åé‡è¿...")
                    time.sleep(wait_seconds)
                    
                except Exception as e:
                    logger.error(f"âŒ WebSocket è¿è¡Œå¼‚å¸¸: {e}")
                    logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                    
                    if not self.should_stop:
                        retry_count += 1
                        wait_seconds = min(5 * retry_count, 60)
                        logger.warning(f"â³ {wait_seconds}ç§’åé‡è¯•...")
                        time.sleep(wait_seconds)

        ws_thread = threading.Thread(target=run_ws_with_retry, daemon=True)
        ws_thread.start()
        
        # å¯åŠ¨å¥åº·æ£€æŸ¥çº¿ç¨‹
        health_thread = threading.Thread(target=self.health_check_loop, daemon=True)
        health_thread.start()
        logger.info("ğŸ’“ å¥åº·æ£€æŸ¥å·²å¯åŠ¨ï¼ˆæ¯60ç§’ä¸€æ¬¡ï¼‰")
        
        # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œ
        try:
            while not self.should_stop:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            logger.info("âš ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            logger.info("ğŸ›‘ æ­£åœ¨å…³é—­ç›‘æ§...")
            self.should_stop = True
            
            # å…³é—­WebSocket
            if self.ws:
                try:
                    self.ws.close()
                    logger.info("âœ… WebSocket å·²å…³é—­")
                except Exception as e:
                    logger.debug(f"å…³é—­ WebSocket å¼‚å¸¸: {e}")
            
            # å…³é—­ HTTP Session
            if hasattr(self, 'session'):
                try:
                    self.session.close()
                    logger.info("âœ… HTTP Session å·²å…³é—­")
                except Exception as e:
                    logger.debug(f"å…³é—­ Session å¼‚å¸¸: {e}")
            
            # å…³é—­çº¿ç¨‹æ± ï¼ˆç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæœ€å¤š30ç§’ï¼‰
            if hasattr(self, 'executor'):
                logger.info("ğŸ›‘ ç­‰å¾…çº¿ç¨‹æ± ä»»åŠ¡å®Œæˆï¼ˆæœ€å¤š30ç§’ï¼‰...")
                self.executor.shutdown(wait=True)
                logger.info("âœ… çº¿ç¨‹æ± å·²å…³é—­")
            
            logger.info("âœ… ç›‘æ§å·²å®Œå…¨å…³é—­")

