"""
BSC WebSocket ç›‘æ§å™¨
ä½¿ç”¨ WebSocket å®æ—¶ç›‘å¬é“¾ä¸Šäº‹ä»¶ï¼Œæ›¿ä»£ Alchemy Webhook
"""
import json
import time
import asyncio
import logging
import signal
import random
import re
import websocket
import requests
import traceback
import urllib3
import threading
import os
import time
from datetime import datetime, timezone, timedelta
from decimal import Decimal
from typing import Dict, Optional
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache
from collections import OrderedDict
from ..api.telegram_api import TelegramAPI
from ..api.dbotx_api import DBotXAPI
from ..notifiers.telegram import TelegramNotifier
from ..core.redis_client import get_redis
from ..core.config import TELEGRAM_CONFIG
from ..core.formatters import format_number
from .trigger_logic import TriggerLogic
from ..notifiers.alert_recorder import get_alert_recorder
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Prometheus Metrics
try:
    from prometheus_client import Counter, Gauge, Histogram, start_http_server, REGISTRY
    HAS_PROMETHEUS = True
except ImportError:
    HAS_PROMETHEUS = False
    Counter = Gauge = Histogram = None


# å¯é€‰ä¾èµ–ï¼šeth_abiï¼ˆç”¨äº Multicall2ï¼‰
try:
    from eth_abi import encode as eth_abi_encode, decode as eth_abi_decode
    HAS_ETH_ABI = True
except ImportError:
    HAS_ETH_ABI = False
    eth_abi_encode = None
    eth_abi_decode = None

# å¯é€‰ä¾èµ–ï¼štelegramï¼ˆç”¨äºæŒ‰é’®ï¼‰
try:
    from telegram import InlineKeyboardButton, InlineKeyboardMarkup
    HAS_TELEGRAM_BUTTONS = True
except ImportError:
    HAS_TELEGRAM_BUTTONS = False
    InlineKeyboardButton = None
    InlineKeyboardMarkup = None

# ä½¿ç”¨ç»Ÿä¸€çš„å±‚çº§loggerå‘½å
logger = logging.getLogger('solalert.monitor.bsc_ws')


class BSCWebSocketMonitor:
    """BSC WebSocket ç›‘æ§å™¨"""
    
    def __init__(
        self,
        ws_url: str,
        rpc_url: str,
        enable_telegram: bool = True
    ):
        """
        åˆå§‹åŒ– WebSocket ç›‘æ§å™¨
        
        Args:
            ws_url: WebSocket RPC URL
            rpc_url: HTTP RPC URL
            enable_telegram: æ˜¯å¦å¯ç”¨ Telegram æ¨é€
        """
        self.ws_url = ws_url
        self.rpc_url = rpc_url
        self.enable_telegram = enable_telegram
        
        # å¯åŠ¨æ—¶é—´
        self.start_time = time.time()
        
        # Redis
        self.redis_client = get_redis()
        
        # Alert Recorderï¼ˆç”¨äºè®°å½•åˆ°æ•°æ®åº“å’Œæ¨é€WebSocketï¼‰
        self.alert_recorder = get_alert_recorder()
        
        # å¸¸é‡
        self.USDT = "0x55d398326f99059ff775485246999027b3197955"
        self.WBNB = "0xbb4cdb9cbd36b01bd1cbaebf2de08d9173bc095c"
        self.USDC = "0x8ac76a51cc950d9822d68b83fe1ad97b32cd580d"
        # åªç›‘å¬ä¸»Proxyï¼ˆTry Buyå·²åºŸå¼ƒï¼Œ2025å¹´æ— æ´»åŠ¨ï¼‰
        self.FOURMEME_PROXY = [
            "0x5c952063c7fc8610ffdb798152d69f0b9550762b".lower()  # ä¸»Proxy
        ]
        self.TOPIC_V2_SWAP = "0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822"
        
        # Fourmeme è‡ªå®šä¹‰äº‹ä»¶ï¼ˆå¯æ•è·å†…éƒ¨è°ƒç”¨ï¼‰
        self.FOURMEME_CUSTOM_EVENTS = [
            "0x7db52723a3b2cdd6164364b3b766e65e540d7be48ffa89582956d8eaebe62942",  # äº‹ä»¶1
            "0x48063b1239b68b5d50123408787a6df1f644d9160f0e5f702fefddb9a855954d"   # äº‹ä»¶2
        ]
        
        # Multicall2 é…ç½®ï¼ˆBSCï¼‰
        # æ³¨æ„ï¼šBSC ä¸Šæœ‰å¤šä¸ª Multicall å®ç°ï¼Œä¼˜å…ˆä½¿ç”¨è·¨é“¾é€šç”¨çš„ Multicall3
        self.MULTICALL2_ADDRESS = "0xcA11bde05977b3631167028862bE2A173976CA11"  # Multicall3ï¼ˆè·¨é“¾é€šç”¨åœ°å€ï¼‰
        # tryAggregate å‡½æ•°é€‰æ‹©å™¨: tryAggregate(bool requireSuccess, tuple[] calls)
        # Multicall3 ä¹Ÿæ”¯æŒæ­¤å‡½æ•°ï¼Œå‘åå…¼å®¹ Multicall2
        self.MULTICALL2_TRY_AGGREGATE_SELECTOR = "bce38bd7"  # ä¸å¸¦0xå‰ç¼€
        
        # Telegram é…ç½®
        self.bsc_channel_id = str(TELEGRAM_CONFIG.get('bsc_channel_id'))
        self.telegram_notifier = TelegramNotifier(enabled=self.enable_telegram)
        
        # å†·å´æœŸé…ç½®
        self.cooldown_minutes = 3.0
        self.cooldown_jitter = 0.5
        
        # è¿‡æ»¤é…ç½®ï¼ˆä» Redis åŠ è½½ï¼‰
        self.min_amount_internal = 200  # é»˜è®¤å€¼
        self.min_amount_external = 400  # å¤–ç›˜é»˜è®¤400
        self.cumulative_min_amount_internal = 500
        self.cumulative_min_amount_external = 1000  # å¤–ç›˜ç´¯è®¡1000
        
        # æ—¶é—´é—´éš”å’ŒTopæŒæœ‰è€…é˜ˆå€¼ï¼ˆä» Redis åŠ è½½ï¼‰
        self.time_interval_internal = '1m'  # å†…ç›˜é»˜è®¤1åˆ†é’Ÿ
        self.time_interval_external = '5m'  # å¤–ç›˜é»˜è®¤5åˆ†é’Ÿ
        self.top_holders_threshold_internal = None  # å†…ç›˜TopæŒæœ‰è€…é˜ˆå€¼ï¼ˆNoneè¡¨ç¤ºä¸æ£€æŸ¥ï¼‰
        self.top_holders_threshold_external = None  # å¤–ç›˜TopæŒæœ‰è€…é˜ˆå€¼ï¼ˆNoneè¡¨ç¤ºä¸æ£€æŸ¥ï¼‰
        
        # é»˜è®¤ events_configï¼ˆåå¤‡é…ç½®ï¼‰
        self.internal_events_config = {
            'priceChange': {'enabled': True, 'risePercent': 30},  # é»˜è®¤ï¼šå†…ç›˜æ¶¨å¹… >= 30%
            'volume': {'enabled': True, 'threshold': 5000}        # é»˜è®¤ï¼šå†…ç›˜äº¤æ˜“é‡ >= $5000
        }
        self.external_events_config = {
            'priceChange': {'enabled': True, 'risePercent': 50},  # é»˜è®¤ï¼šå¤–ç›˜æ¶¨å¹… >= 50%
            'volume': {'enabled': True, 'threshold': 20000}       # é»˜è®¤ï¼šå¤–ç›˜äº¤æ˜“é‡ >= $20000
        }
        
        # è§¦å‘é€»è¾‘ï¼ˆé»˜è®¤å€¼ï¼‰
        self.trigger_logic_internal = 'any'  # å†…ç›˜è§¦å‘é€»è¾‘
        self.trigger_logic_external = 'any'  # å¤–ç›˜è§¦å‘é€»è¾‘
        
        # WebSocket
        self.ws = None
        self.should_stop = False
        self.reconnect_count = 0  # é‡è¿è®¡æ•°
        self.last_message_time = time.time()  # æœ€åä¸€æ¬¡æ”¶åˆ°æ¶ˆæ¯çš„æ—¶é—´
        self.message_count = 0  # æ¶ˆæ¯è®¡æ•°å™¨
        self.cache_hit_count = 0  # éfourmemeç¼“å­˜å‘½ä¸­è®¡æ•°
        
        # ç¬¬ä¸€å±‚/ç¬¬äºŒå±‚ç»Ÿè®¡ï¼ˆå†…å¤–ç›˜åˆ†åˆ«è®¡æ•°ï¼‰
        self.first_layer_pass_internal = 0  # å†…ç›˜é€šè¿‡ç¬¬ä¸€å±‚
        self.first_layer_pass_external = 0  # å¤–ç›˜é€šè¿‡ç¬¬ä¸€å±‚
        self.second_layer_check_internal = 0  # å†…ç›˜ç¬¬äºŒå±‚æ£€æŸ¥æ¬¡æ•°
        self.second_layer_check_external = 0  # å¤–ç›˜ç¬¬äºŒå±‚æ£€æŸ¥æ¬¡æ•°
        self.second_layer_pass_internal = 0  # å†…ç›˜é€šè¿‡ç¬¬äºŒå±‚
        self.second_layer_pass_external = 0  # å¤–ç›˜é€šè¿‡ç¬¬äºŒå±‚
        
        # å‘Šè­¦å‘é€ç»Ÿè®¡
        self.alert_success_count = 0  # å‘Šè­¦å‘é€æˆåŠŸæ¬¡æ•°
        self.alert_fail_count = 0  # å‘Šè­¦å‘é€å¤±è´¥æ¬¡æ•°
        self.alert_cooldown_blocked = 0  # å†·å´æœŸæ‹¦æˆªæ¬¡æ•°
        
        # ========== ç›´æ¥å¤„ç†æ¶æ„ï¼ˆæ— é˜Ÿåˆ—ï¼‰==========
        # å¤„ç†æµç¨‹ï¼šWebSocket â†’ çº¿ç¨‹æ±  â†’ å¼‚æ­¥å¤„ç†ï¼ˆä½å»¶è¿Ÿï¼Œé«˜ååï¼‰
        
        # çº¿ç¨‹æ± ï¼ˆç›´æ¥å¤„ç†æ¨¡å¼ï¼šWebSocketå›è°ƒ â†’ çº¿ç¨‹æ±  â†’ å¼‚æ­¥å¤„ç†ï¼‰
        # 8æ ¸24GæœåŠ¡å™¨ï¼šæ‰©å¤§çº¿ç¨‹æ± ä»¥æ”¯æŒé«˜å¹¶å‘ç›´æ¥å¤„ç†
        self.executor = ThreadPoolExecutor(max_workers=20, thread_name_prefix="BSC-WS-Direct")
        self.thread_local = threading.local()
        
        # äº¤æ˜“å»é‡ï¼ˆä½¿ç”¨ tx_hash:logIndex ç»„åˆé”®ï¼Œæ”¯æŒå¤šæ—¥å¿—å¤„ç†ï¼‰
        self.seen_txs = OrderedDict()
        self.max_seen_txs = 100000  # å¢å¤§å®¹é‡ä»¥é€‚åº” (tx_hash, logIndex) ç»„åˆé”®
        
        # WBNB ä»·æ ¼ç¼“å­˜
        self.wbnb_price = 600.0
        self.wbnb_price_timestamp = 0
        self.price_cache_ttl = 300  # 5åˆ†é’Ÿ
        

        
        self.session = requests.Session()
        # é…ç½®è¿æ¥æ± å’Œé‡è¯•ç­–ç•¥ï¼ˆé™ä½å¹¶å‘ï¼‰
        retry_strategy = Retry(
            total=3,
            backoff_factor=0.3,
            status_forcelist=[500, 502, 503, 504]
        )
        adapter = HTTPAdapter(
            pool_connections=5,   # è¿æ¥æ± å¤§å°ï¼ˆä¸çº¿ç¨‹æ± max_workersä¸€è‡´ï¼‰
            pool_maxsize=10,      # æœ€å¤§è¿æ¥æ•°ï¼ˆé™ä½å¹¶å‘å‹åŠ›ï¼‰
            max_retries=retry_strategy
        )
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        # RPC è°ƒç”¨è®¡æ•°å’Œç»Ÿè®¡
        self.rpc_id = 0
        self.rpc_stats = {}  # {method: count} ç»Ÿè®¡å„æ–¹æ³•è°ƒç”¨æ¬¡æ•°
        self.rpc_stats_start_time = time.time()  # ç»Ÿè®¡å¼€å§‹æ—¶é—´
        
        # é€Ÿç‡é™åˆ¶ï¼ˆé˜²æ­¢429é™æµï¼‰
        self.rate_limit_lock = threading.Lock()
        self.last_rpc_time = 0
        self.min_rpc_interval = 0.001  # 1ms è±¡å¾æ€§é—´éš”ï¼ŒChainstackæ— é™åˆ¶
        self.rate_limit_429_count = 0  # 429é”™è¯¯è®¡æ•°
        self.rate_limit_backoff_until = 0  # é€€é¿æˆªæ­¢æ—¶é—´ï¼ˆç§’ï¼‰
        self.rate_limit_consecutive_429 = 0  # è¿ç»­429æ¬¡æ•°
        
        # æ–­çº¿å›è¡¥
        self.last_processed_block = 0
        self.reconnect_time = 0
        self.last_backfill_time = 0  # ä¸Šæ¬¡å›è¡¥æ—¶é—´
        self.backfill_cooldown = 300  # å›è¡¥å†·å´æœŸï¼ˆ5åˆ†é’Ÿï¼Œå¤§å¹…å‡å°‘å›è¡¥é¢‘ç‡ï¼‰
        self.backfill_count = 0  # å›è¡¥æ¬¡æ•°ç»Ÿè®¡
        
        # å›æ‰§ç¼“å­˜ï¼ˆå‡å°‘ eth_getTransactionReceipt é‡å¤è°ƒç”¨ï¼Œå¸¦å¹¶å‘ä¿æŠ¤ï¼‰
        self.receipt_cache = {}  # {tx_hash: {"receipt": {}, "tx_info": {}, "cached_at": timestamp, "status": "ready|loading|failed", "event": threading.Event()}}
        # OPTIMIZED: TTLå»¶é•¿åˆ°1å°æ—¶ï¼Œæé«˜ç¼“å­˜å‘½ä¸­ç‡ï¼ˆäº¤æ˜“å›æ‰§æ°¸ä¸å˜ï¼‰
        self.receipt_cache_ttl = 3600  # 1å°æ—¶è¿‡æœŸï¼ˆä»30åˆ†é’Ÿæå‡ï¼‰
        self.receipt_cache_failed_ttl = 300  # å¤±è´¥ç»“æœç¼“å­˜5åˆ†é’Ÿï¼ˆä»2åˆ†é’Ÿæå‡ï¼Œé¿å…NodeRealæ…¢èŠ‚ç‚¹é‡è¯•ï¼‰
        self.receipt_cache_hits = 0  # å‘½ä¸­è®¡æ•°
        self.receipt_cache_misses = 0  # æœªå‘½ä¸­è®¡æ•°
        self.receipt_cache_concurrent_waits = 0  # å¹¶å‘ç­‰å¾…è®¡æ•°
        self.receipt_cache_failed_hits = 0  # å¤±è´¥ç¼“å­˜å‘½ä¸­ï¼ˆé¿å…é‡è¯•ï¼‰
        self.receipt_cache_wait_time_total = 0.0  # ç´¯è®¡ç­‰å¾…è€—æ—¶ï¼ˆç§’ï¼‰
        self.receipt_cache_wait_timeouts = 0  # ç­‰å¾…è¶…æ—¶æ¬¡æ•°
        self.receipt_cache_lock = threading.Lock()  # å…¨å±€é”ï¼ˆä»…ç”¨äºè¯»å†™ç¼“å­˜å­—å…¸ï¼‰
        
        # eth_call ç¼“å­˜ï¼ˆå‡å°‘ä»£å¸ä¿¡æ¯é‡å¤æŸ¥è¯¢ï¼‰
        self.eth_call_cache = {}  # {(to, data): (result, cached_at)}
        self.eth_call_cache_ttl = 300  # 5åˆ†é’Ÿè¿‡æœŸï¼ˆdecimals/symbolä¸ä¼šå˜ï¼‰
        self.eth_call_cache_hits = 0  # å‘½ä¸­è®¡æ•°
        self.eth_call_cache_lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
        
        # ========== Prometheus Metrics ==========
        if HAS_PROMETHEUS:
            try:
                # Counterï¼ˆè®¡æ•°å™¨ï¼‰- åªå¢ä¸å‡
                self.metrics_messages = Counter(
                    'bsc_ws_messages_total', 
                    'WebSocketæ¥æ”¶çš„æ€»æ¶ˆæ¯æ•°'
                )
                self.metrics_first_layer_pass = Counter(
                    'bsc_ws_first_layer_pass_total', 
                    'ç¬¬ä¸€å±‚è¿‡æ»¤é€šè¿‡æ¬¡æ•°',
                    ['type']  # type: internal/external
                )
                self.metrics_second_layer_check = Counter(
                    'bsc_ws_second_layer_check_total', 
                    'ç¬¬äºŒå±‚æ£€æŸ¥æ¬¡æ•°',
                    ['type', 'path']  # type: internal/external, path: fast/fallback
                )
                self.metrics_second_layer_pass = Counter(
                    'bsc_ws_second_layer_pass_total', 
                    'ç¬¬äºŒå±‚æ£€æŸ¥é€šè¿‡æ¬¡æ•°',
                    ['type', 'path']  # type: internal/external, path: fast/fallback
                )
                self.metrics_alerts = Counter(
                    'bsc_ws_alerts_total', 
                    'å‘Šè­¦å‘é€æ¬¡æ•°',
                    ['status']  # status: success/failure
                )
                self.metrics_alert_cooldown_blocked = Counter(
                    'bsc_ws_alert_cooldown_blocked_total',
                    'å†·å´æœŸæ‹¦æˆªæ¬¡æ•°ï¼ˆé¿å…é‡å¤å‘Šè­¦ï¼‰'
                )
                self.metrics_cache_hits = Counter(
                    'bsc_ws_cache_hits_total', 
                    'ç¼“å­˜å‘½ä¸­æ¬¡æ•°',
                    ['cache_type']  # cache_type: receipt/eth_call/non_fourmeme
                )
                self.metrics_non_fourmeme = Counter(
                    'bsc_ws_non_fourmeme_total',
                    'éfourmemeè·³è¿‡æ¬¡æ•°ï¼ˆAPIé¦–åˆ¤+ç¼“å­˜ï¼‰',
                    ['source']  # source: api_first_check/cache_hit
                )
                self.metrics_fallback = Counter(
                    'bsc_ws_fallback_total',
                    'æ—¶é—´çª—å£é€€è®©æ¬¡æ•°',
                    ['original', 'fallback']  # 1m->5m, 5m->1h
                )
                self.metrics_api_calls = Counter(
                    'bsc_ws_api_calls_total',
                    'APIè°ƒç”¨æ¬¡æ•°',
                    ['api_type', 'status']  # api_type: dbotx/rpc(æ— é™åˆ¶), status: success/failure
                )
                self.metrics_credits_consumed = Counter(
                    'bsc_ws_credits_consumed_total',
                    'æ¶ˆè´¹ç§¯åˆ†æ€»é‡ï¼ˆä»…DBotX APIï¼‰',
                    ['source']  # source: dbotx(10åˆ†), BSC WebSocket/RPCä½¿ç”¨Chainstackä¸è®¡è´¹
                )
                
                # ğŸ”„ ä»Redisæ¢å¤å†å²ç´¯è®¡å€¼ï¼ˆé‡å¯åç»§ç»­ç´¯åŠ ï¼‰
                self._restore_metrics_from_redis()
                
                # Histogramï¼ˆç›´æ–¹å›¾ï¼‰- ç»Ÿè®¡åˆ†å¸ƒ
                from prometheus_client import Histogram
                self.metrics_processing_time = Histogram(
                    'bsc_ws_processing_time_seconds',
                    'æ¶ˆæ¯å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰',
                    ['stage'],  # stage: first_layer/second_layer/alert
                    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
                )
                
                # Gaugeï¼ˆä»ªè¡¨ï¼‰- å¯å¢å¯å‡
                self.metrics_connections = Gauge(
                    'bsc_ws_connections', 
                    'WebSocketè¿æ¥æ•°'
                )
                self.metrics_cache_size = Gauge(
                    'bsc_ws_cache_size', 
                    'ç¼“å­˜å¤§å°',
                    ['cache_type']  # cache_type: seen_txs/receipt/eth_call
                )
                
                # ========== æŒ‡æ ‡åˆå§‹åŒ–ï¼šé¢„åˆ›å»ºæ‰€æœ‰æ ‡ç­¾ç»„åˆï¼Œé¿å… Grafana æŸ¥è¯¢ç©ºå€¼ ==========
                # åˆå§‹åŒ–æ‰€æœ‰ Counterï¼ˆinc(0) ä¸å½±å“å®é™…å€¼ï¼‰
                self.metrics_first_layer_pass.labels(type='internal').inc(0)
                self.metrics_first_layer_pass.labels(type='external').inc(0)
                
                self.metrics_second_layer_check.labels(type='internal', path='fallback').inc(0)
                self.metrics_second_layer_check.labels(type='external', path='api').inc(0)
                
                self.metrics_second_layer_pass.labels(type='internal', path='fallback').inc(0)
                self.metrics_second_layer_pass.labels(type='external', path='api').inc(0)
                
                self.metrics_alerts.labels(status='success').inc(0)
                self.metrics_alerts.labels(status='failure').inc(0)
                
                self.metrics_cache_hits.labels(cache_type='receipt').inc(0)
                self.metrics_cache_hits.labels(cache_type='eth_call').inc(0)
                self.metrics_cache_hits.labels(cache_type='non_fourmeme').inc(0)
                
                self.metrics_non_fourmeme.labels(source='api_first_check').inc(0)
                self.metrics_non_fourmeme.labels(source='cache_hit').inc(0)
                
                self.metrics_fallback.labels(original='1m', fallback='5m').inc(0)
                self.metrics_fallback.labels(original='5m', fallback='1h').inc(0)
                
                self.metrics_api_calls.labels(api_type='dbotx', status='success').inc(0)
                self.metrics_api_calls.labels(api_type='dbotx', status='failure').inc(0)
                self.metrics_api_calls.labels(api_type='rpc', status='success').inc(0)
                self.metrics_api_calls.labels(api_type='rpc', status='failure').inc(0)
                
                self.metrics_credits_consumed.labels(source='dbotx').inc(0)
                
                # åˆå§‹åŒ– Gaugeï¼ˆè¿æ¥çŠ¶æ€åˆå§‹ä¸º 0=æ–­å¼€ï¼‰
                self.metrics_connections.set(0)
                self.metrics_cache_size.labels(cache_type='seen_txs').set(0)
                self.metrics_cache_size.labels(cache_type='receipt').set(0)
                self.metrics_cache_size.labels(cache_type='eth_call').set(0)
            except Exception as e:
                logger.error(f"âŒ Prometheus Metrics åˆå§‹åŒ–å¤±è´¥: {e}")
                # æ³¨æ„ï¼šä¸ä¿®æ”¹ HAS_PROMETHEUSï¼Œå› ä¸ºå®ƒæ˜¯æ¨¡å—çº§å…¨å±€å¸¸é‡
        else:
            logger.warning("âš ï¸ Prometheus Metrics æœªå®‰è£…")
        
    async def load_config_from_redis(self):
        """ä» Redis åŠ è½½é…ç½®"""
        try:
            # åŠ è½½å†…ç›˜é…ç½®
            internal_data = await asyncio.to_thread(
                self.redis_client.client.get, 'global_monitor:config:bsc:internal'
            )
            if internal_data:
                if isinstance(internal_data, bytes):
                    internal_data = internal_data.decode('utf-8')
                
                # æ¸…ç† Java ç±»å‹æ ‡è®°

                internal_data = re.sub(r'"@type"\s*:\s*"[^"]*"\s*,?\s*', '', internal_data)
                internal_data = re.sub(r':\s*(\d+)L\b', r':\1', internal_data)
                internal_data = re.sub(r',\s*}', '}', internal_data)
                
                config = json.loads(internal_data)
                self.min_amount_internal = config.get('min_transaction_usd', 200)
                self.cumulative_min_amount_internal = config.get('cumulative_min_amount_usd', 500)
                self.time_interval_internal = config.get('timeInterval', '1m')  # å†…ç›˜æ—¶é—´é—´éš”
                self.trigger_logic_internal = config.get('triggerLogic', 'any')  # å†…ç›˜è§¦å‘é€»è¾‘
                # topHoldersThresholdï¼šå¦‚æœé…ç½®äº†å°±å¯ç”¨æ£€æŸ¥ï¼Œå¦åˆ™ä¸ºNoneï¼ˆä¸æ£€æŸ¥ï¼‰
                threshold = config.get('topHoldersThreshold')
                self.top_holders_threshold_internal = float(threshold) if threshold is not None else None
                
                events_config_str = config.get('eventsConfig', '{}')
                if events_config_str:
                    try:
                        if isinstance(events_config_str, str):
                            loaded_config = json.loads(events_config_str)
                        else:
                            loaded_config = events_config_str
                        
                        # åªåœ¨æœ‰æœ‰æ•ˆé…ç½®æ—¶æ‰è¦†ç›–é»˜è®¤å€¼
                        if loaded_config and isinstance(loaded_config, dict):
                            self.internal_events_config = loaded_config
                            
                            # ç¡®ä¿ enabled å­—æ®µ
                            if 'priceChange' in self.internal_events_config:
                                self.internal_events_config['priceChange']['enabled'] = True
                            if 'volume' in self.internal_events_config:
                                self.internal_events_config['volume']['enabled'] = True
                    except:
                        pass  # ä¿ç•™é»˜è®¤å€¼
            
            # åŠ è½½å¤–ç›˜é…ç½®
            external_data = await asyncio.to_thread(
                self.redis_client.client.get, 'global_monitor:config:bsc:external'
            )
            if external_data:
                if isinstance(external_data, bytes):
                    external_data = external_data.decode('utf-8')
                
                # æ¸…ç† Java ç±»å‹æ ‡è®°
                external_data = re.sub(r'"@type"\s*:\s*"[^"]*"\s*,?\s*', '', external_data)
                external_data = re.sub(r':\s*(\d+)L\b', r':\1', external_data)
                external_data = re.sub(r',\s*}', '}', external_data)
                
                config = json.loads(external_data)
                self.min_amount_external = config.get('min_transaction_usd', 400)
                self.cumulative_min_amount_external = config.get('cumulative_min_amount_usd', 1000)  
                self.time_interval_external = config.get('timeInterval', '5m')  # å¤–ç›˜æ—¶é—´é—´éš”
                self.trigger_logic_external = config.get('triggerLogic', 'any')  # å¤–ç›˜è§¦å‘é€»è¾‘
                
                # topHoldersThresholdï¼šå¦‚æœé…ç½®äº†å°±å¯ç”¨æ£€æŸ¥ï¼Œå¦åˆ™ä¸ºNoneï¼ˆä¸æ£€æŸ¥ï¼‰
                threshold = config.get('topHoldersThreshold')
                self.top_holders_threshold_external = float(threshold) if threshold is not None else None  
                
                events_config_str = config.get('eventsConfig', '{}')
                if events_config_str:
                    try:
                        if isinstance(events_config_str, str):
                            loaded_config = json.loads(events_config_str)
                        else:
                            loaded_config = events_config_str
                        
                        # åªåœ¨æœ‰æœ‰æ•ˆé…ç½®æ—¶æ‰è¦†ç›–é»˜è®¤å€¼
                        if loaded_config and isinstance(loaded_config, dict):
                            self.external_events_config = loaded_config
                            
                            # ç¡®ä¿ enabled å­—æ®µ
                            if 'priceChange' in self.external_events_config:
                                self.external_events_config['priceChange']['enabled'] = True
                            if 'volume' in self.external_events_config:
                                self.external_events_config['volume']['enabled'] = True
                    except:
                        pass  # ä¿ç•™é»˜è®¤å€¼

        except Exception as e:
            logger.error(f"âŒ åŠ è½½ Redis é…ç½®å¤±è´¥: {e}")
        
        # è®¡ç®—å…¨å±€æœ€å°é‡‘é¢é˜ˆå€¼ï¼ˆç”¨äºæå‰è¿‡æ»¤ï¼‰
        self.global_min_amount = min(self.min_amount_internal, self.min_amount_external)
        logger.info(f"ğŸ” å…¨å±€æœ€å°è¿‡æ»¤é˜ˆå€¼: {self.global_min_amount}Uï¼ˆå–å†…å¤–ç›˜æœ€å°å€¼ï¼Œæå‰è¿‡æ»¤å°é¢äº¤æ˜“ï¼‰")
        
        # é…ç½®å·²åŠ è½½ï¼ˆè¯¦ç»†é…ç½®å¯åœ¨ main.py å¯åŠ¨æ—¶æŸ¥çœ‹ï¼‰

        # é¢„åŠ è½½ WBNB ä»·æ ¼ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        self.wbnb_price = await asyncio.to_thread(self.get_wbnb_price)
        logger.info(f"ğŸ’° WBNB ä»·æ ¼: ${self.wbnb_price:.2f}")
        
        # ç»Ÿè®¡éfourmemeç¼“å­˜å¤§å°å¹¶ç¡®ä¿TTL
        self.NON_FOURMEME_KEY = "bsc:non_fourmeme_tokens"
        self.NON_FOURMEME_TTL = 30 * 24 * 3600  # 30å¤©
        
        # fourmemeç™½åå•ç¼“å­˜ï¼ˆé¿å…é‡å¤APIè°ƒç”¨ï¼‰
        self.FOURMEME_KEY = "bsc:fourmeme_tokens"
        self.FOURMEME_TTL = 30 * 24 * 3600  # 30å¤©
        self.fourmeme_cache_hit_count = 0  # fourmemeç¼“å­˜å‘½ä¸­è®¡æ•°
        
        if self.redis_client:
            try:
                cache_size = self.redis_client.scard(self.NON_FOURMEME_KEY)
                # ç¡®ä¿ç¼“å­˜æœ‰è¿‡æœŸæ—¶é—´ï¼ˆé˜²æ­¢æ°¸ä¹…å­˜å‚¨ï¼‰
                ttl = self.redis_client.client.ttl(self.NON_FOURMEME_KEY)
                if ttl == -1:  # -1 è¡¨ç¤ºæ²¡æœ‰è¿‡æœŸæ—¶é—´
                    self.redis_client.client.expire(self.NON_FOURMEME_KEY, self.NON_FOURMEME_TTL)
            except Exception as e:
                logger.debug(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
    
    def _restore_metrics_from_redis(self):
        """ä»Redisæ¢å¤PrometheusæŒ‡æ ‡çš„å†å²ç´¯è®¡å€¼"""
        if not self.redis_client:
            logger.warning("âš ï¸ Redisæœªè¿æ¥ï¼Œæ— æ³•æ¢å¤æŒ‡æ ‡")
            return
        
        try:
            # æ¢å¤ç§¯åˆ†æ¶ˆè€—ï¼ˆæœ€é‡è¦çš„æŒ‡æ ‡ï¼‰
            credits_key = 'prometheus:bsc_ws_credits_consumed_total:dbotx'
            saved_credits = self.redis_client.get(credits_key)
            if saved_credits:
                try:
                    credits_value = int(saved_credits)
                    if credits_value > 0:
                        self.metrics_credits_consumed.labels(source='dbotx').inc(credits_value)
                        logger.info(f"âœ… æ¢å¤ç§¯åˆ†æ¶ˆè€—ï¼š{credits_value}")
                except (ValueError, TypeError) as e:
                    logger.warning(f"âš ï¸ ç§¯åˆ†æ•°æ®æ ¼å¼é”™è¯¯: {e}")
            
            # æ¢å¤APIè°ƒç”¨æ¬¡æ•°
            api_calls_map = {
                'prometheus:bsc_ws_api_calls_total:dbotx:success': ('dbotx', 'success'),
                'prometheus:bsc_ws_api_calls_total:dbotx:failure': ('dbotx', 'failure'),
                'prometheus:bsc_ws_api_calls_total:rpc:success': ('rpc', 'success'),
                'prometheus:bsc_ws_api_calls_total:rpc:failure': ('rpc', 'failure'),
            }
            for key, (api_type, status) in api_calls_map.items():
                saved_value = self.redis_client.get(key)
                if saved_value:
                    try:
                        value = int(saved_value)
                        if value > 0:
                            self.metrics_api_calls.labels(api_type=api_type, status=status).inc(value)
                    except (ValueError, TypeError):
                        pass
            
            # æ¢å¤å‘Šè­¦æ¬¡æ•°
            for status in ['success', 'failure']:
                key = f'prometheus:bsc_ws_alerts_total:{status}'
                saved_value = self.redis_client.get(key)
                if saved_value:
                    try:
                        value = int(saved_value)
                        if value > 0:
                            self.metrics_alerts.labels(status=status).inc(value)
                    except (ValueError, TypeError):
                        pass
            
            logger.info("âœ… PrometheusæŒ‡æ ‡æ¢å¤å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æ¢å¤PrometheusæŒ‡æ ‡å¤±è´¥: {e}")
    
    def _save_all_metrics_to_redis(self):
        """æ‰¹é‡ä¿å­˜æ‰€æœ‰PrometheusæŒ‡æ ‡åˆ°Redisï¼ˆå®šæœŸè°ƒç”¨ï¼‰"""
        if not HAS_PROMETHEUS or not self.redis_client:
            return
        
        try:
            # ä»Prometheusè·å–å½“å‰å€¼å¹¶ä¿å­˜åˆ°Redis
            from prometheus_client import REGISTRY
            
            for metric in REGISTRY.collect():
                if metric.name.startswith('bsc_ws_'):
                    for sample in metric.samples:
                        # åªä¿å­˜Counterç±»å‹ï¼ˆç´¯è®¡å€¼ï¼‰
                        if sample.name.endswith('_total') or sample.name == 'bsc_ws_messages':
                            # æ„é€ Redis key
                            labels_str = ':'.join(f"{sample.labels[k]}" for k in sorted(sample.labels.keys())) if sample.labels else ''
                            redis_key = f"prometheus:{sample.name}" + (f":{labels_str}" if labels_str else '')
                            
                            # ä¿å­˜åˆ°Redisï¼ˆ7å¤©è¿‡æœŸï¼‰
                            self.redis_client.set(redis_key, str(int(sample.value)), ex=86400*7)
            
            logger.debug("ğŸ’¾ PrometheusæŒ‡æ ‡å·²æ‰¹é‡ä¿å­˜åˆ°Redis")
        except Exception as e:
            logger.debug(f"æ‰¹é‡ä¿å­˜æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _save_metric_to_redis(self, metric_name: str, value: int):
        """ä¿å­˜æŒ‡æ ‡åˆ°Redisï¼ˆå¼‚æ­¥ï¼Œé¿å…é˜»å¡ï¼‰"""
        if not self.redis_client:
            return
        
        try:
            self.redis_client.set(metric_name, str(value), ex=86400*7)  # ä¿ç•™7å¤©
        except Exception as e:
            logger.debug(f"ä¿å­˜æŒ‡æ ‡åˆ°Rediså¤±è´¥: {e}")
    
    def _inc_credits_and_save(self, amount: int = 10):
        """å¢åŠ ç§¯åˆ†å¹¶ä¿å­˜åˆ°Redisï¼ˆæŒä¹…åŒ–ï¼‰"""
        if HAS_PROMETHEUS:
            # 1. å¢åŠ Prometheus Counter
            self.metrics_api_calls.labels(api_type='dbotx', status='success').inc()
            self.metrics_credits_consumed.labels(source='dbotx').inc(amount)
            
            # 2. ä¿å­˜åˆ°Redisï¼ˆæ¯æ¬¡éƒ½ä¿å­˜ï¼Œç¡®ä¿é‡å¯åèƒ½æ¢å¤ï¼‰
            if self.redis_client:
                try:
                    # ä½¿ç”¨Redisçš„INCRåŸå­æ“ä½œ
                    key = 'prometheus:bsc_ws_credits_consumed_total:dbotx'
                    new_value = self.redis_client.client.incr(key, amount)
                    self.redis_client.client.expire(key, 86400*7)  # 7å¤©è¿‡æœŸ
                    logger.debug(f"ğŸ’¾ ç§¯åˆ†å·²ä¿å­˜åˆ°Redis: {new_value}")
                except Exception as e:
                    logger.debug(f"ä¿å­˜ç§¯åˆ†åˆ°Rediså¤±è´¥: {e}")
    
    def get_thread_dbotx_api(self) -> DBotXAPI:
        """è·å–å½“å‰çº¿ç¨‹çš„ DBotX API å®ä¾‹"""
        if not hasattr(self.thread_local, 'dbotx_api'):
            self.thread_local.dbotx_api = DBotXAPI()
        return self.thread_local.dbotx_api
    
    def get_receipt_cached(self, tx_hash: str) -> tuple:
        """
        è·å–äº¤æ˜“å›æ‰§ï¼ˆå¸¦ç¼“å­˜ï¼Œå¹¶å‘ä¿æŠ¤ï¼Œå¤±è´¥ç¼“å­˜ï¼‰
        
        ä¼˜åŒ–ï¼š
        1. LoadingçŠ¶æ€ï¼šé˜²æ­¢å¤šä¸ªçº¿ç¨‹åŒæ—¶æ‹‰å–åŒä¸€äº¤æ˜“
        2. Eventç­‰å¾…ï¼šåç»­çº¿ç¨‹ç­‰å¾…ç¬¬ä¸€ä¸ªçº¿ç¨‹å®Œæˆ
        3. å¤±è´¥ç¼“å­˜ï¼šRPCå¤±è´¥æ—¶ç¼“å­˜5ç§’ï¼Œé¿å…é£æš´å¼é‡è¯•
        4. è¯¦ç»†ç»Ÿè®¡ï¼šhits/misses/waits/failed_hits
        
        Returns:
            (receipt, tx_info) æˆ– (None, None) å¦‚æœå¤±è´¥
        """
        now = time.time()
        event_to_wait = None
        
        # === é˜¶æ®µ1: æ£€æŸ¥ç¼“å­˜ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰ ===
        with self.receipt_cache_lock:
            if tx_hash in self.receipt_cache:
                cached_data = self.receipt_cache[tx_hash]
                status = cached_data.get("status", "ready")
                cached_at = cached_data.get("cached_at", 0)
                
                # æƒ…å†µ1: æ­£åœ¨åŠ è½½ä¸­ â†’ å…¶ä»–çº¿ç¨‹æ­£åœ¨æ‹‰å–ï¼Œç­‰å¾…å®ƒå®Œæˆ
                if status == "loading":
                    event_to_wait = cached_data.get("event")
                    self.receipt_cache_concurrent_waits += 1
                    logger.info(f"â³ å¹¶å‘ç­‰å¾…ï¼ˆå…¶ä»–çº¿ç¨‹æ­£åœ¨æ‹‰å–ï¼‰: {tx_hash[:10]}... (ç­‰å¾…#{self.receipt_cache_concurrent_waits})")
                
                # æƒ…å†µ2: æˆåŠŸç¼“å­˜ï¼Œæœªè¿‡æœŸ
                elif status == "ready" and now - cached_at < self.receipt_cache_ttl:
                    receipt = cached_data.get("receipt")
                    tx_info = cached_data.get("tx_info")
                    
                    # éªŒè¯æ•°æ®å®Œæ•´æ€§
                    if receipt and isinstance(receipt, dict) and receipt.get("logs"):
                        self.receipt_cache_hits += 1
                        if HAS_PROMETHEUS:
                            self.metrics_cache_hits.labels(cache_type='receipt').inc()
                        logger.debug(f"âœ… å›æ‰§ç¼“å­˜å‘½ä¸­: {tx_hash[:10]}... (å‘½ä¸­#{self.receipt_cache_hits})")
                        return receipt, tx_info
                    else:
                        # è„æ•°æ®ï¼Œåˆ é™¤
                        logger.debug(f"âš ï¸ è„æ•°æ®ï¼Œé‡æ–°æ‹‰å–: {tx_hash[:10]}...")
                        del self.receipt_cache[tx_hash]
                
                # æƒ…å†µ3: å¤±è´¥ç¼“å­˜ï¼Œæœªè¿‡æœŸ â†’ é¿å…çŸ­æœŸå†…é‡è¯•
                elif status == "failed" and now - cached_at < self.receipt_cache_failed_ttl:
                    self.receipt_cache_failed_hits += 1
                    logger.debug(f"ğŸš« å¤±è´¥ç¼“å­˜å‘½ä¸­ï¼ˆè·³è¿‡é‡è¯•ï¼‰: {tx_hash[:10]}... (å¤±è´¥ç¼“å­˜#{self.receipt_cache_failed_hits})")
                    return None, None
                
                # æƒ…å†µ4: è¿‡æœŸï¼Œåˆ é™¤
                else:
                    del self.receipt_cache[tx_hash]
        
        # === é˜¶æ®µ2: å¦‚æœéœ€è¦ç­‰å¾…å…¶ä»–çº¿ç¨‹ ===
        if event_to_wait:
            # OPTIMIZED: ç­‰å¾…5ç§’é€‚é…NodeRealé«˜å»¶è¿Ÿ
            wait_start = time.time()
            wait_result = event_to_wait.wait(timeout=5)
            wait_elapsed = time.time() - wait_start
            
            # ç»Ÿè®¡ç­‰å¾…è€—æ—¶
            self.receipt_cache_wait_time_total += wait_elapsed
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if not wait_result or wait_elapsed >= 5.5:  # æ¥è¿‘6ç§’è§†ä¸ºè¶…æ—¶
                self.receipt_cache_wait_timeouts += 1
                logger.warning(
                    f"âš ï¸ å¹¶å‘ç­‰å¾…è¶…æ—¶: {tx_hash[:10]}... (è€—æ—¶{wait_elapsed:.2f}s, "
                    f"è¶…æ—¶#{self.receipt_cache_wait_timeouts}æ¬¡ï¼Œå°†è‡ªè¡Œæ‹‰å–)"
                )
            else:
                logger.info(f"âœ… å¹¶å‘ç­‰å¾…å®Œæˆ: {tx_hash[:10]}... (è€—æ—¶{wait_elapsed:.2f}s)")
            
            # ç­‰å¾…å®Œæˆåï¼Œå†æ¬¡å°è¯•è¯»ç¼“å­˜
            with self.receipt_cache_lock:
                if tx_hash in self.receipt_cache:
                    cached_data = self.receipt_cache[tx_hash]
                    if cached_data.get("status") == "ready":
                        receipt = cached_data.get("receipt")
                        tx_info = cached_data.get("tx_info")
                        if receipt:
                            logger.info(f"âœ… ç­‰å¾…åè·å–ç»“æœæˆåŠŸ: {tx_hash[:10]}...")
                            return receipt, tx_info
            
            # å¦‚æœç­‰å¾…åä»æœªè·å–åˆ°ï¼Œè¯´æ˜ç¬¬ä¸€ä¸ªçº¿ç¨‹å¤±è´¥äº†ï¼Œç»§ç»­åç»­æµç¨‹
            logger.warning(f"âš ï¸ ç­‰å¾…åä»æœªè·å–åˆ°æ•°æ®ï¼Œè‡ªè¡Œæ‹‰å–: {tx_hash[:10]}...")
        
        # === é˜¶æ®µ3: ç¼“å­˜æœªå‘½ä¸­ï¼Œå ä½å¹¶æ‹‰å– ===
        loading_event = threading.Event()
        
        with self.receipt_cache_lock:
            # åŒé‡æ£€æŸ¥ï¼šå¯èƒ½åˆšæ‰ç­‰å¾…æ—¶å…¶ä»–çº¿ç¨‹å·²å†™å…¥
            if tx_hash in self.receipt_cache and self.receipt_cache[tx_hash].get("status") == "ready":
                cached_data = self.receipt_cache[tx_hash]
                receipt = cached_data.get("receipt")
                tx_info = cached_data.get("tx_info")
                if receipt:
                    return receipt, tx_info
            
            # è®¾ç½® loading çŠ¶æ€ï¼ˆå ä½ï¼‰
            self.receipt_cache[tx_hash] = {
                "status": "loading",
                "event": loading_event,
                "cached_at": now
            }
            self.receipt_cache_misses += 1
            logger.debug(f"ğŸ” å›æ‰§ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨RPC: {tx_hash[:10]}... (æœªå‘½ä¸­#{self.receipt_cache_misses})")
        
        # === é˜¶æ®µ4: é”å¤–æ‰§è¡Œ RPCï¼ˆé¿å…é˜»å¡ï¼‰ ===
        try:
            receipt = self.rpc_call("eth_getTransactionReceipt", [tx_hash])
            tx_info = self.rpc_call("eth_getTransactionByHash", [tx_hash])
            
            # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
            success = receipt and isinstance(receipt, dict) and receipt.get("logs")
            
            # å†™å…¥ç¼“å­˜
            with self.receipt_cache_lock:
                if success:
                    # æˆåŠŸï¼šç¼“å­˜ 5 åˆ†é’Ÿ
                    self.receipt_cache[tx_hash] = {
                        "status": "ready",
                        "receipt": receipt,
                        "tx_info": tx_info,
                        "cached_at": now,
                        "event": None
                    }
                else:
                    # å¤±è´¥ï¼šç¼“å­˜ 5 ç§’ï¼ˆé˜²æ­¢é£æš´å¼é‡è¯•ï¼‰
                    self.receipt_cache[tx_hash] = {
                        "status": "failed",
                        "receipt": None,
                        "tx_info": None,
                        "cached_at": now,
                        "event": None
                    }
                    logger.debug(f"âŒ RPCå¤±è´¥ï¼Œç¼“å­˜å¤±è´¥çŠ¶æ€5ç§’: {tx_hash[:10]}...")
                
                # æ¸…ç†è¿‡æœŸç¼“å­˜
                if len(self.receipt_cache) > 5000:
                    to_delete = [
                        k for k, v in self.receipt_cache.items()
                        if now - v.get("cached_at", 0) > max(self.receipt_cache_ttl, self.receipt_cache_failed_ttl)
                    ]
                    for k in to_delete:
                        del self.receipt_cache[k]
                    if to_delete:
                        logger.debug(f"ğŸ§¹ æ¸…ç†è¿‡æœŸå›æ‰§ç¼“å­˜: {len(to_delete)} æ¡")
            
            # é€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹
            loading_event.set()
            
            return receipt, tx_info
            
        except Exception as e:
            logger.debug(f"âŒ RPCå¼‚å¸¸: {tx_hash[:10]}... - {e}")
            
            # å¼‚å¸¸ä¹Ÿç¼“å­˜ä¸ºå¤±è´¥çŠ¶æ€
            with self.receipt_cache_lock:
                self.receipt_cache[tx_hash] = {
                    "status": "failed",
                    "receipt": None,
                    "tx_info": None,
                    "cached_at": now,
                    "event": None
                }
            
            loading_event.set()
            return None, None
    
    def cached_eth_call(self, to: str, data: str):
        """
        å¸¦ç¼“å­˜çš„ eth_callï¼ˆç”¨äºä»£å¸ä¿¡æ¯æŸ¥è¯¢ï¼‰
        
        ä¼˜åŒ–ï¼š
        - ç¼“å­˜ decimals/symbol ç­‰ä¸å˜çš„æ•°æ®
        - USDT/WBNBç­‰å¸¸è§ä»£å¸100%å‘½ä¸­
        - å‡å°‘30-50% eth_call
        """
        cache_key = (to.lower(), data.lower())
        now = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        with self.eth_call_cache_lock:
            if cache_key in self.eth_call_cache:
                result, cached_at = self.eth_call_cache[cache_key]
                if now - cached_at < self.eth_call_cache_ttl:
                    self.eth_call_cache_hits += 1
                    return result
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨RPC
        result = self.rpc_call("eth_call", [{"to": to, "data": data}, "latest"])
        
        # å†™å…¥ç¼“å­˜
        if result:  # åªç¼“å­˜æˆåŠŸçš„ç»“æœ
            with self.eth_call_cache_lock:
                self.eth_call_cache[cache_key] = (result, now)
                
                # æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
                if len(self.eth_call_cache) > 5000:
                    to_delete = [
                        k for k, (_, t) in self.eth_call_cache.items()
                        if now - t > self.eth_call_cache_ttl
                    ]
                    for k in to_delete:
                        del self.eth_call_cache[k]
        
        return result
    
    def rpc_call(self, method: str, params: list):
        """
        å‘é€ HTTP RPC è¯·æ±‚ï¼ˆå¸¦429å¤„ç† + æ…¢è°ƒç”¨ç›‘æ§ï¼‰
        
        ä¼˜åŒ–ï¼š
        1. æœ€å°é—´éš”ï¼šè±¡å¾æ€§1msé—´éš”ï¼ˆChainstackæ— é™åˆ¶ï¼‰
        2. 429æ£€æµ‹ï¼šæ£€æµ‹é™æµé”™è¯¯å¹¶æŒ‡æ•°é€€é¿
        3. é€€é¿æœºåˆ¶ï¼šè¿ç»­429æ—¶å»¶é•¿é€€é¿æ—¶é—´ï¼ˆæœ€é«˜16sï¼‰
        4. ç»Ÿè®¡ç›‘æ§ï¼šè®°å½•429æ¬¡æ•°å’Œæ…¢è°ƒç”¨
        """
        self.rpc_id += 1
        
        # === é˜¶æ®µ1: é€Ÿç‡é™åˆ¶ï¼ˆé˜²æ­¢429ï¼‰ ===
        with self.rate_limit_lock:
            # æ£€æŸ¥æ˜¯å¦åœ¨é€€é¿æœŸå†…
            now = time.time()
            if now < self.rate_limit_backoff_until:
                backoff_wait = self.rate_limit_backoff_until - now
                logger.warning(f"â¸ï¸  é€Ÿç‡é™åˆ¶é€€é¿ä¸­ï¼Œç­‰å¾… {backoff_wait:.2f}s...")
                time.sleep(backoff_wait)
            
            # é™åˆ¶æœ€å°è¯·æ±‚é—´éš”
            elapsed_since_last = now - self.last_rpc_time
            if elapsed_since_last < self.min_rpc_interval:
                time.sleep(self.min_rpc_interval - elapsed_since_last)
            
            self.last_rpc_time = time.time()
        
        # === é˜¶æ®µ2: å‘é€RPCè¯·æ±‚ ===
        start_time = time.time()
        self.rpc_stats[method] = self.rpc_stats.get(method, 0) + 1
        
        try:
            resp = self.session.post(
                self.rpc_url,
                json={"jsonrpc": "2.0", "id": self.rpc_id, "method": method, "params": params},
                timeout=10
            )
            
            # ğŸ“Š Prometheus: è®°å½•RPCè°ƒç”¨ï¼ˆæˆåŠŸï¼Œä½†ä¸è®¡ç§¯åˆ†ï¼Œå› ä¸ºRPCæ— é™åˆ¶ï¼‰
            if HAS_PROMETHEUS:
                self.metrics_api_calls.labels(api_type='rpc', status='success').inc()
            
            # === é˜¶æ®µ3: æ£€æŸ¥429é™æµ ===
            if resp.status_code == 429:
                self.rate_limit_429_count += 1
                self.rate_limit_consecutive_429 += 1
                
                # æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s, 8s, æœ€é«˜16s
                backoff_time = min(2 ** self.rate_limit_consecutive_429, 16)
                self.rate_limit_backoff_until = time.time() + backoff_time
                
                logger.warning(
                    f"ğŸš« é‡åˆ°429é™æµ (ç´¯è®¡#{self.rate_limit_429_count}, è¿ç»­#{self.rate_limit_consecutive_429}æ¬¡), "
                    f"é€€é¿ {backoff_time}s, method={method}"
                )
                
                # è¿”å›Noneï¼Œè®©ä¸Šå±‚ç¼“å­˜ä¸ºfailedçŠ¶æ€
                return None
            
            # === é˜¶æ®µ4: æˆåŠŸå“åº”ï¼Œé‡ç½®è¿ç»­429è®¡æ•° ===
            if resp.status_code == 200:
                self.rate_limit_consecutive_429 = 0  # é‡ç½®è¿ç»­429è®¡æ•°
            
            result = resp.json().get("result")
            
            # === é˜¶æ®µ5: æ…¢è°ƒç”¨ç›‘æ§ ===
            latency = time.time() - start_time
            if latency > 1.0:
                logger.warning("RPCæ…¢è°ƒç”¨", extra={
                    "method": method,
                    "latency": f"{latency:.2f}s",
                    "params_count": len(params)
                })
            
            return result
            
        except Exception as e:
            latency = time.time() - start_time
            logger.debug(f"RPC é”™è¯¯: {e}", extra={
                "method": method,
                "latency": f"{latency:.2f}s"
            })
            return None
    
    def multicall2_try_aggregate(self, calls: list) -> list:
        """
        ä½¿ç”¨ Multicall2.tryAggregate æ‰¹é‡æŸ¥è¯¢
        ä¼˜å…ˆä½¿ç”¨ eth_abiï¼Œæ— åº“æ—¶ä½¿ç”¨ä¿®æ­£åçš„æ‰‹åŠ¨ç¼–ç 
        
        Args:
            calls: [(target_address, calldata), ...] è°ƒç”¨åˆ—è¡¨
        
        Returns:
            [result1, result2, ...] ç»“æœåˆ—è¡¨ï¼ˆå¤±è´¥è¿”å› Noneï¼‰
        """
        if not calls:
            return []
        
        try:
            # è·¯å¾„1: ä½¿ç”¨ eth_abiï¼ˆæ¨èï¼Œç»“æ„å‡†ç¡®ï¼‰
            if HAS_ETH_ABI:
                # tryAggregate(bool requireSuccess, (address,bytes)[] calls)
                call_tuples = []
                for target, calldata in calls:
                    target_bytes = bytes.fromhex(target[2:] if target.startswith('0x') else target)
                    calldata_bytes = bytes.fromhex(calldata[2:] if calldata.startswith('0x') else calldata)
                    call_tuples.append((target_bytes, calldata_bytes))
                
                # ç¼–ç å‚æ•°ï¼šrequireSuccess=false, calls
                encoded_args = eth_abi_encode(
                    ['bool', '(address,bytes)[]'],
                    [False, call_tuples]
                )
                
                # æ„å»ºå®Œæ•´çš„ calldata
                full_calldata = self.MULTICALL2_TRY_AGGREGATE_SELECTOR + encoded_args.hex()
                
                # è°ƒç”¨ Multicall2
                result = self.rpc_call("eth_call", [{
                    "to": self.MULTICALL2_ADDRESS,
                    "data": "0x" + full_calldata
                }, "latest"])
                
                if not result or result == "0x":
                    logger.warning(f"âš ï¸ Multicall2 è¿”å›ç©ºç»“æœ (eth_abi)ï¼Œå›é€€åˆ°é€ä¸ªè°ƒç”¨")
                    logger.debug(f"è°ƒç”¨æ•°é‡: {len(calls)}, Calldataé•¿åº¦: {len(full_calldata)}")
                    return self._fallback_individual_calls(calls)
                
                # è§£ç ç»“æœ
                try:
                    result_bytes = bytes.fromhex(result[2:] if result.startswith('0x') else result)
                    decoded = eth_abi_decode(['(bool,bytes)[]'], result_bytes)[0]
                    
                    results = []
                    for success, return_data in decoded:
                        if success and return_data:
                            results.append('0x' + return_data.hex())
                        else:
                            results.append(None)
                    
                    return results
                except Exception as decode_error:
                    logger.warning(f"âš ï¸ eth_abi è§£ç å¤±è´¥: {decode_error}, å›é€€åˆ°é€ä¸ªè°ƒç”¨")
                    return self._fallback_individual_calls(calls)
            
            # è·¯å¾„2: æ‰‹åŠ¨ç¼–ç ï¼ˆä¿®æ­£åï¼Œæ— ä¾èµ–ï¼‰
            sig = "bce38bd7"  # tryAggregate selector
            ignore_results = "00" * 32  # bool False (32 bytes)
            
            # Array offset: 0x20 (after bool)
            array_offset = format(0x20, '064x')  # 32 bytes padded
            
            # Array length
            array_len_hex = format(len(calls), '064x')
            
            # Array data: å¯¹äº tuple[] ç±»å‹ï¼Œéœ€è¦åµŒå¥—åç§»
            # æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª tupleï¼ŒåŒ…å« address + bytesï¼ˆåŠ¨æ€ï¼‰
            # ç»“æ„ï¼š[offset1, offset2, ...] + [tuple1_data, tuple2_data, ...]
            
            tuple_offsets = []
            tuple_contents = []
            
            # åç§»åŸºå‡†ï¼šlen(calls) * 32ï¼ˆæ¯ä¸ªåç§»å 32å­—èŠ‚ï¼‰
            base_offset = len(calls) * 32
            current_offset = base_offset
            
            for target, calldata in calls:
                target_clean = target[2:] if target.startswith('0x') else target
                calldata_clean = calldata[2:] if calldata.startswith('0x') else calldata
                
                # è®°å½•å½“å‰ tuple çš„åç§»
                tuple_offsets.append(format(current_offset, '064x'))
                
                # æ„å»º tuple å†…å®¹ï¼šaddress (32b) + bytes_offset (0x20) + bytes_len + bytes_data
                address_padded = target_clean.zfill(64)  # 32 bytes
                bytes_offset_in_tuple = format(0x20, '064x')  # bytes åœ¨ tuple å†…åç§» 32 å­—èŠ‚ï¼ˆaddress åï¼‰
                
                calldata_len = len(calldata_clean) // 2
                calldata_len_hex = format(calldata_len, '064x')
                calldata_full = calldata_clean  # åŠ¨æ€æ•°æ®ï¼Œä¸éœ€è¦ padding
                
                tuple_content = address_padded + bytes_offset_in_tuple + calldata_len_hex + calldata_full
                tuple_contents.append(tuple_content)
                
                # æ›´æ–°åç§»ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰
                current_offset += len(tuple_content) // 2
            
            # ç»„è£…æ•°ç»„æ•°æ®
            array_data = "".join(tuple_offsets) + "".join(tuple_contents)
            
            # å®Œæ•´ç¼–ç 
            encoded_args = ignore_results + array_offset + array_len_hex + array_data
            full_data = sig + encoded_args
            
            # è°ƒç”¨ RPC
            result = self.rpc_call("eth_call", [{
                "to": self.MULTICALL2_ADDRESS,
                "data": "0x" + full_data
            }, "latest"])
            
            if not result or result == "0x":
                logger.debug(f"Full data len: {len(full_data)}, first 100: {full_data[:100]}")
                return self._fallback_individual_calls(calls)
            
            # æ‰‹åŠ¨è§£æè¿”å›å€¼: (bool success, bytes returnData)[] æ•°ç»„
            result_hex = result[2:] if result.startswith('0x') else result
            
            # æ•°ç»„åç§»ï¼ˆé€šå¸¸æ˜¯0x20ï¼‰
            array_start = int(result_hex[0:64], 16) * 2
            # æ•°ç»„é•¿åº¦
            array_len = int(result_hex[array_start:array_start+64], 16)
            
            results = []
            offset = array_start + 64  # è·³è¿‡é•¿åº¦å­—æ®µ
            
            # è¯»å–æ¯ä¸ªå…ƒç´ çš„åç§»ï¼ˆç›¸å¯¹äºæ•°ç»„å¼€å§‹ä½ç½®ï¼‰
            result_offsets = []
            for i in range(array_len):
                elem_offset = int(result_hex[offset:offset+64], 16) * 2
                result_offsets.append(array_start + elem_offset)
                offset += 64
            
            # è§£ææ¯ä¸ª (bool, bytes) tuple
            for elem_offset in result_offsets:
                success = int(result_hex[elem_offset:elem_offset+64], 16)
                bytes_offset = int(result_hex[elem_offset+64:elem_offset+128], 16) * 2
                bytes_start = elem_offset + bytes_offset
                bytes_len = int(result_hex[bytes_start:bytes_start+64], 16)
                
                if success == 1 and bytes_len > 0:
                    ret_data = "0x" + result_hex[bytes_start+64:bytes_start+64+bytes_len*2]
                    results.append(ret_data)
                else:
                    results.append(None)
            
            return results
            
        except Exception as e:
            logger.warning(f"âš ï¸ Multicall2 è°ƒç”¨å¤±è´¥: {e}, å›é€€åˆ°é€ä¸ªè°ƒç”¨")
            logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return self._fallback_individual_calls(calls)
    
    def _fallback_individual_calls(self, calls: list) -> list:
        """å›é€€æ–¹æ¡ˆï¼šé€ä¸ªè°ƒç”¨"""
        results = []
        for target, calldata in calls:
            try:
                result = self.rpc_call("eth_call", [{
                    "to": target,
                    "data": calldata
                }, "latest"])
                results.append(result)
            except Exception as e:
                logger.debug(f"è°ƒç”¨å¤±è´¥ {target}: {e}")
                results.append(None)
        return results
    
    def _extract_pair_from_receipt(self, logs: list) -> str:
        """ä» receipt logs ä¸­æå– PancakeV2 Pair åœ°å€"""
        try:
            swap_topic = "0xd78ad95fa46c994b6551d0da85fc275fe613ce37657fb8d5e3d130840159d822"
            for log in logs:
                topics = log.get("topics", [])
                if topics and topics[0] == swap_topic:
                    # Swap äº‹ä»¶çš„åœ°å€å°±æ˜¯ Pair åœ°å€
                    return log.get("address", "").lower()
        except Exception as e:
            logger.debug(f"æå– pair å¤±è´¥: {e}")
        return None
    
    def get_wbnb_price(self) -> float:
        """åŠ¨æ€è·å– WBNB ä»·æ ¼ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        now = time.time()
        if now - self.wbnb_price_timestamp < self.price_cache_ttl:
            return self.wbnb_price
        
        try:
            # ç¦ç”¨ SSL è­¦å‘Š
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
            
            # ä½¿ç”¨é•¿è¿æ¥ï¼ˆSessionï¼‰
            resp = self.session.get(
                'https://api.gateio.ws/api/v4/spot/tickers?currency_pair=BNB_USDT',
                timeout=5,
                verify=False  # ç¦ç”¨ SSL è¯ä¹¦éªŒè¯
            )
            data = resp.json()
            
            if data and isinstance(data, list) and len(data) > 0:
                price = float(data[0].get('last', self.wbnb_price))
                self.wbnb_price = price
                self.wbnb_price_timestamp = now
                logger.info(f"âœ… æ›´æ–° WBNB ä»·æ ¼: ${price}")
                return price
        except Exception as e:
            logger.warning(f"âš ï¸ è·å– WBNB ä»·æ ¼å¤±è´¥: {e}")
        
        return self.wbnb_price
    
    @lru_cache(maxsize=10000)
    def get_decimals(self, token: str) -> int:
        """è·å–ä»£å¸ç²¾åº¦ï¼ˆL1 å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜ + L3 é“¾ä¸ŠæŸ¥è¯¢ï¼‰"""
        # L1: LRU Cache å·²é€šè¿‡è£…é¥°å™¨å¤„ç†
        
        try:
            # L2: Redis ç¼“å­˜
            redis_key = f"token:{token}:decimals"
            cached_value = self.redis_client.client.get(redis_key)
            if cached_value:
                try:
                    value = int(cached_value)
                    return value
                except:
                    pass
            
            # L3: é“¾ä¸ŠæŸ¥è¯¢ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            data = self.cached_eth_call(token, "0x313ce567")
            
            result = int(data, 16) if data else 18
            
            # å†™å…¥ Redis (TTL=1å¤©)
            try:
                self.redis_client.client.setex(redis_key, 86400, str(result))
            except:
                pass
            
            return result
        except:
            return 18
    
    def parse_symbol_data(self, data: str) -> str:
        """è§£æ symbol() è¿”å›çš„æ•°æ®"""
        if not data or data == "0x":
            return "???"
        
        try:
            hex_data = data[2:] if data.startswith('0x') else data
            
            # åŠ¨æ€å­—ç¬¦ä¸²ï¼šoffset(32) + length(32) + data
            if len(hex_data) >= 128:
                length = int(hex_data[64:128], 16)
                data_hex = hex_data[128:128 + length * 2]
                if data_hex:
                    return bytes.fromhex(data_hex).decode('utf-8', errors='ignore').rstrip('\x00')
            
            # å›ºå®šé•¿åº¦å­—ç¬¦ä¸²ï¼ˆç›´æ¥ç¼–ç ï¼‰
            if len(hex_data) == 64:
                return bytes.fromhex(hex_data).decode('utf-8', errors='ignore').rstrip('\x00')
            
            return "???"
        except Exception as e:
            logger.debug(f"è§£æ symbol å¤±è´¥: {e}")
            return "???"
    
    @lru_cache(maxsize=10000)
    def get_token_symbol(self, token: str) -> str:
        """è·å–ä»£å¸ç¬¦å·ï¼ˆL1 å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜ + L3 é“¾ä¸ŠæŸ¥è¯¢ï¼‰"""
        # L1: LRU Cache å·²é€šè¿‡è£…é¥°å™¨å¤„ç†
        
        try:
            # L2: Redis ç¼“å­˜
            redis_key = f"token:{token}:symbol"
            cached_value = self.redis_client.client.get(redis_key)
            if cached_value:
                if isinstance(cached_value, bytes):
                    cached_value = cached_value.decode('utf-8')
                return cached_value
            
            # L3: é“¾ä¸ŠæŸ¥è¯¢ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            data = self.cached_eth_call(token, "0x95d89b41")
            
            # ä½¿ç”¨æ”¹è¿›çš„è§£æå‡½æ•°
            result = self.parse_symbol_data(data)
            
            # å†™å…¥ Redis (TTL=1å¤©)
            try:
                self.redis_client.client.setex(redis_key, 86400, result)
            except:
                pass
            
            return result
        except:
            return "???"
    
    @lru_cache(maxsize=5000)
    def get_pair_tokens(self, pair: str) -> tuple:
        """è·å–äº¤æ˜“å¯¹çš„ token0 å’Œ token1ï¼ˆL1 å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜ + L3 é“¾ä¸ŠæŸ¥è¯¢ï¼‰"""
        # L1: LRU Cache å·²é€šè¿‡è£…é¥°å™¨å¤„ç†
        
        try:
            # L2: Redis ç¼“å­˜
            redis_key = f"pair:{pair}:tokens"
            cached_value = self.redis_client.client.get(redis_key)
            if cached_value:
                if isinstance(cached_value, bytes):
                    cached_value = cached_value.decode('utf-8')
                parts = cached_value.split(',')
                if len(parts) == 2:
                    return parts[0], parts[1]
            
            # L3: é“¾ä¸ŠæŸ¥è¯¢ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            token0_data = self.cached_eth_call(pair, "0x0dfe1681")
            token1_data = self.cached_eth_call(pair, "0xd21220a7")
            
            if token0_data and token1_data:
                token0 = "0x" + token0_data[-40:]
                token1 = "0x" + token1_data[-40:]
                token0 = token0.lower()
                token1 = token1.lower()
                
                # å†™å…¥ Redis (TTL=1å¤©)
                try:
                    self.redis_client.client.setex(redis_key, 86400, f"{token0},{token1}")
                except:
                    pass
                
                return token0, token1
        except:
            pass
        return None, None
    
    def get_pair_full_info(self, pair_address: str) -> Optional[Dict]:
        """
        è·å–äº¤æ˜“å¯¹å®Œæ•´ä¿¡æ¯ï¼ˆä¼˜åŒ–ç‰ˆï¼šç¼“å­˜ â†’ Multicall2æ‰¹é‡æŸ¥è¯¢ï¼‰
        
        Returns:
            {
                'token0': '0x...',
                'token1': '0x...',
                'decimals0': 18,
                'symbol0': 'USDT',
                'decimals1': 18,
                'symbol1': 'TOKEN'
            }
        """
        try:
            # ç¬¬ä¸€æ­¥ï¼šè·å– token0 å’Œ token1ï¼ˆèµ°ç¼“å­˜ï¼‰
            token0, token1 = self.get_pair_tokens(pair_address)
            
            if not token0 or not token1:
                return None
            
            # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½æ‰¹é‡æŸ¥è¯¢ï¼ˆå…ˆæŸ¥ç¼“å­˜ï¼Œæ”¶é›† missï¼Œæ‰¹é‡è°ƒç”¨ï¼‰
            result = {
                'token0': token0,
                'token1': token1,
                'decimals0': None,
                'symbol0': None,
                'decimals1': None,
                'symbol1': None
            }
            
            # æ£€æŸ¥ L1 (LRU) ç¼“å­˜
            # æ³¨æ„ï¼š@lru_cache çš„ç¼“å­˜æ£€æŸ¥éœ€è¦å®é™…è°ƒç”¨ï¼Œä½†ä¼šèµ°å†…éƒ¨çš„ L2 (Redis) é€»è¾‘
            miss_calls = []  # [(token, calldata, field_name)]
            
            # æ£€æŸ¥ token0 decimals ç¼“å­˜ï¼ˆç›´æ¥æŸ¥ Redisï¼Œä¸è§¦å‘é“¾ä¸ŠæŸ¥è¯¢ï¼‰
            try:
                cached = self.redis_client.client.get(f"token:{token0}:decimals")
                if cached:
                    result['decimals0'] = int(cached)
                else:
                    miss_calls.append((token0, "0x313ce567", 'decimals0'))
            except:
                miss_calls.append((token0, "0x313ce567", 'decimals0'))
            
            # æ£€æŸ¥ token0 symbol ç¼“å­˜
            try:
                cached = self.redis_client.client.get(f"token:{token0}:symbol")
                if cached:
                    if isinstance(cached, bytes):
                        cached = cached.decode('utf-8')
                    result['symbol0'] = cached
                else:
                    miss_calls.append((token0, "0x95d89b41", 'symbol0'))
            except:
                miss_calls.append((token0, "0x95d89b41", 'symbol0'))
            
            # æ£€æŸ¥ token1 decimals ç¼“å­˜
            try:
                cached = self.redis_client.client.get(f"token:{token1}:decimals")
                if cached:
                    result['decimals1'] = int(cached)
                else:
                    miss_calls.append((token1, "0x313ce567", 'decimals1'))
            except:
                miss_calls.append((token1, "0x313ce567", 'decimals1'))
            
            # æ£€æŸ¥ token1 symbol ç¼“å­˜
            try:
                cached = self.redis_client.client.get(f"token:{token1}:symbol")
                if cached:
                    if isinstance(cached, bytes):
                        cached = cached.decode('utf-8')
                    result['symbol1'] = cached
                else:
                    miss_calls.append((token1, "0x95d89b41", 'symbol1'))
            except:
                miss_calls.append((token1, "0x95d89b41", 'symbol1'))
            
            # å¦‚æœæœ‰æœªå‘½ä¸­çš„ï¼Œä½¿ç”¨ Multicall2 æ‰¹é‡æŸ¥è¯¢
            if not miss_calls:
                # å…¨éƒ¨å‘½ä¸­ï¼Œç›´æ¥è¿”å›
                return result
            
            multicall_params = [(target, calldata) for target, calldata, _ in miss_calls]
            multicall_results = self.multicall2_try_aggregate(multicall_params)
            
            # è§£æç»“æœå¹¶æ›´æ–°ç¼“å­˜
            for (target, calldata, field_name), call_result in zip(miss_calls, multicall_results):
                if call_result:
                    if 'decimals' in field_name:
                        try:
                            value = int(call_result, 16) if call_result else 18
                            result[field_name] = value
                            # å†™å…¥ Redis ç¼“å­˜
                            try:
                                redis_key = f"token:{target}:decimals"
                                self.redis_client.client.setex(redis_key, 86400, str(value))
                            except:
                                pass
                        except:
                            result[field_name] = 18
                    elif 'symbol' in field_name:
                        try:
                            # ä½¿ç”¨ parse_symbol_data å¤„ç†åŠ¨æ€/å›ºå®šé•¿åº¦ç¼–ç 
                            value = self.parse_symbol_data(call_result)
                            result[field_name] = value
                            # å†™å…¥ Redis ç¼“å­˜
                            try:
                                redis_key = f"token:{target}:symbol"
                                self.redis_client.client.setex(redis_key, 86400, value)
                            except:
                                pass
                        except:
                            result[field_name] = "???"
                else:
                    # è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    if 'decimals' in field_name:
                        result[field_name] = 18
                    else:
                        result[field_name] = "???"
            
            # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æœ‰é»˜è®¤å€¼
            for key in ['decimals0', 'decimals1']:
                if result[key] is None:
                    result[key] = 18
            for key in ['symbol0', 'symbol1']:
                if result[key] is None:
                    result[key] = "???"
            
            return result
        
        except Exception as e:
            logger.error(f"âŒ è·å–äº¤æ˜“å¯¹ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def parse_swap_data(self, data: str) -> Optional[Dict]:
        """è§£æ Swap äº‹ä»¶æ•°æ®"""
        try:
            if not data or data == "0x":
                return None
            
            hex_data = data[2:] if data.startswith("0x") else data
            
            if len(hex_data) < 256:
                return None
            
            return {
                "amount0In": int(hex_data[0:64], 16),
                "amount1In": int(hex_data[64:128], 16),
                "amount0Out": int(hex_data[128:192], 16),
                "amount1Out": int(hex_data[192:256], 16)
            }
        except:
            return None
    
    def format_amount(self, amount: int, decimals: int) -> str:
        """æ ¼å¼åŒ–æ•°é‡"""
        value = Decimal(amount) / (Decimal(10) ** Decimal(decimals))
        if value >= 1000:
            return f"{value:,.2f}"
        elif value >= 1:
            return f"{value:.4f}"
        else:
            return f"{value:.8f}"
    
    def first_layer_filter(self, usd_value: float, is_internal: bool) -> bool:
        """ç¬¬ä¸€å±‚è¿‡æ»¤ï¼šé‡‘é¢"""
        threshold = self.min_amount_internal if is_internal else self.min_amount_external
        return usd_value >= threshold
    
    async def check_and_set_alert_cooldown(self, token_address: str) -> bool:
        """
        åŸå­åŒ–æ£€æŸ¥å†·å´æœŸå¹¶è®¾ç½®ï¼ˆä½¿ç”¨Luaè„šæœ¬ï¼‰
        è¿”å› True = å…è®¸æ¨é€å¹¶å·²è®¾ç½®å†·å´æœŸ
        è¿”å› False = åœ¨å†·å´æœŸå†…ï¼Œè·³è¿‡
        """
        redis_key = f"bsc:alert:last:{token_address.lower()}"
        
        try:
            now_timestamp = int(time.time())
            # ä½¿ç”¨ uniform è·å¾—æ›´ç²¾ç¡®çš„æŠ–åŠ¨ï¼ˆfloat â†’ intï¼‰
            jitter_seconds = random.uniform(0, self.cooldown_jitter * 60)
            cooldown_seconds = int(self.cooldown_minutes * 60 + jitter_seconds)
            
            # Luaè„šæœ¬ï¼šåŸå­åŒ–æ£€æŸ¥å¹¶è®¾ç½®å†·å´æœŸ
            lua_script = """
            local key = KEYS[1]
            local now = tonumber(ARGV[1])
            local cooldown = tonumber(ARGV[2])
            
            -- è·å–ä¸Šæ¬¡è®°å½•
            local last_data = redis.call('GET', key)
            
            -- é¦–æ¬¡æˆ–æ— è®°å½•
            if not last_data then
                local new_data = string.format('{"timestamp":%d,"cooldown_seconds":%d,"alert_count":1}', now, cooldown)
                redis.call('SETEX', key, 86400, new_data)
                return 1  -- å…è®¸æ¨é€
            end
            
            -- è§£æJSONï¼ˆç®€åŒ–ï¼šç›´æ¥æå–timestampä¸ä¸Šæ¬¡çš„å†·å´ç§’æ•°ï¼‰
            local last_timestamp = tonumber(string.match(last_data, '"timestamp":(%d+)'))
            local last_cooldown = tonumber(string.match(last_data, '"cooldown_seconds":(%d+)'))
            
            -- æ— æ³•è§£æï¼Œè§†ä¸ºé¦–æ¬¡
            if not last_timestamp then
                local new_data = string.format('{"timestamp":%d,"cooldown_seconds":%d,"alert_count":1}', now, cooldown)
                redis.call('SETEX', key, 86400, new_data)
                return 1
            end
            
            -- å¤ç”¨ä¸Šæ¬¡å­˜å‚¨çš„å†·å´æ—¶é•¿ï¼Œé¿å…æ–°çš„æŠ–åŠ¨å€¼æ‹‰é•¿å†·å´çª—å£
            if not last_cooldown then
                last_cooldown = cooldown
            end
            
            -- æ£€æŸ¥å†·å´æœŸ
            if now - last_timestamp < last_cooldown then
                return 0  -- å†·å´æœŸå†…ï¼Œæ‹’ç»
            end
            
            -- é€šè¿‡å†·å´æœŸï¼Œæ›´æ–°è®°å½•
            local alert_count = tonumber(string.match(last_data, '"alert_count":(%d+)')) or 0
            local new_data = string.format('{"timestamp":%d,"cooldown_seconds":%d,"alert_count":%d}', now, cooldown, alert_count + 1)
            redis.call('SETEX', key, 86400, new_data)
            return 1  -- å…è®¸æ¨é€
            """
            
            # æ‰§è¡ŒLuaè„šæœ¬
            result = await asyncio.to_thread(
                self.redis_client.client.eval,
                lua_script,
                1,  # numkeys
                redis_key,
                now_timestamp,
                cooldown_seconds
            )
            
            if result == 1:
                return True  # å…è®¸æ¨é€
            else:
                logger.info(f"â³ å†·å´æœŸå†…ï¼Œè·³è¿‡: {token_address}")
                return False
        
        except Exception as e:
            logger.error(f"æ£€æŸ¥å†·å´æœŸå¤±è´¥: {e}")
            # å‡ºé”™æ—¶å…è®¸æ¨é€ï¼ˆé¿å…è¯¯é˜»æ­¢ï¼‰
            return True
    
    async def remove_alert_cooldown(self, token_address: str):
        """
        åˆ é™¤å†·å´æœŸè®°å½•ï¼ˆç”¨äºå‘é€å¤±è´¥åè§£é”ï¼‰
        """
        redis_key = f"bsc:alert:last:{token_address.lower()}"
        try:
            await asyncio.to_thread(self.redis_client.delete, redis_key)
            logger.debug(f"ğŸ”“ å·²åˆ é™¤å†·å´æœŸ: {token_address}")
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤å†·å´æœŸå¤±è´¥: {e}")
    
    async def check_alert_cooldown_readonly(self, token_address: str) -> bool:
        """
        åªè¯»æ£€æŸ¥ä»£å¸æ˜¯å¦åœ¨å†·å´æœŸå†…ï¼ˆä¸è®¾ç½®å†·å´æœŸï¼‰
        ç”¨äºç¬¬ä¸€å±‚è¿‡æ»¤åï¼Œé¿å…æµªè´¹APIè°ƒç”¨
        """
        redis_key = f"bsc:alert:last:{token_address.lower()}"
        
        try:
            last_alert_data = await asyncio.to_thread(self.redis_client.get, redis_key)
            
            if not last_alert_data:
                return True  # æ²¡æœ‰è®°å½•ï¼Œå…è®¸ç»§ç»­
            
            # å®‰å…¨è§£æ JSON
            try:
                if isinstance(last_alert_data, dict):
                    last_alert = last_alert_data
                elif isinstance(last_alert_data, (str, bytes)):
                    if isinstance(last_alert_data, bytes):
                        last_alert_data = last_alert_data.decode('utf-8')
                    if not last_alert_data or last_alert_data == 'null':
                        return True
                    last_alert = json.loads(last_alert_data)
                else:
                    return True
            except:
                return True
            
            last_timestamp = last_alert.get('timestamp', 0)
            cooldown_seconds = last_alert.get('cooldown_seconds', int(self.cooldown_minutes * 60))
            now_timestamp = int(time.time())
            
            if now_timestamp - last_timestamp < cooldown_seconds:
                logger.info(f"â³ å†·å´æœŸå†…ï¼Œè·³è¿‡: {token_address} (å‰©ä½™ {cooldown_seconds - (now_timestamp - last_timestamp)}ç§’)")
                return False
            
            return True
        except Exception as e:
            logger.error(f"æ£€æŸ¥å†·å´æœŸå¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶å…è®¸ç»§ç»­
    
    async def check_alert_cooldown(self, token_address: str) -> bool:
        """
        æ£€æŸ¥ä»£å¸æ˜¯å¦åœ¨å†·å´æœŸå†…ï¼ˆå…¼å®¹æ—§æ¥å£ï¼Œåªè¯»ï¼‰
        """
        return await self.check_alert_cooldown_readonly(token_address)
    
    # update_alert_historyå·²åºŸå¼ƒï¼Œé€»è¾‘å·²åˆå¹¶åˆ°check_and_set_alert_cooldownä¸­
    
    def create_token_buttons(self, token_address: str):
        """åˆ›å»ºä»£å¸çš„ Telegram å†…è”æŒ‰é’®"""
        if not HAS_TELEGRAM_BUTTONS:
            return None
        
        buttons = [
            [
                InlineKeyboardButton("ğŸ“Š GMGN", url=f"https://gmgn.ai/bsc/token/{token_address}"),
                InlineKeyboardButton("ğŸ” OKX", url=f"https://www.okx.com/web3/dex-swap#inputChain=56&inputCurrency={token_address}&outputChain=56&outputCurrency=0x55d398326f99059fF775485246999027B3197955")
            ]
        ]
        return InlineKeyboardMarkup(buttons)
    
    async def send_alert(self, message: str, token_address: str) -> bool:
        """
        å‘é€ Telegram é€šçŸ¥
        
        Returns:
            bool: æ˜¯å¦å‘é€æˆåŠŸ
        """
        if not self.enable_telegram:
            logger.debug(f"â­ï¸  Telegramæœªå¯ç”¨ï¼Œè·³è¿‡å‘é€")
            return False
        
        try:
            # è¯¦ç»†æ—¥å¿—ï¼šå‡†å¤‡å‘é€
            logger.info(f"ğŸ“¤ å‡†å¤‡å‘é€å‘Šè­¦: {token_address} -> é¢‘é“{self.bsc_channel_id}")
            
            reply_markup = self.create_token_buttons(token_address)
            
            result = await self.telegram_notifier.send(
                target=self.bsc_channel_id,
                message=message,
                parse_mode="HTML",
                reply_markup=reply_markup
            )
            
            if result:
                logger.info(f"âœ… Telegramé€šçŸ¥å·²å‘é€ - {token_address[:10]}...")
                self.alert_success_count += 1  # å‘é€æˆåŠŸè®¡æ•°
                return True
            else:
                logger.error(f"âŒâŒâŒ Telegramå‘é€å¤±è´¥ - {token_address} | é¢‘é“{self.bsc_channel_id} | telegram_notifier.sendè¿”å›False")
                self.alert_fail_count += 1  # å‘é€å¤±è´¥è®¡æ•°
                return False
        
        except Exception as e:
            logger.error(f"âŒâŒâŒ å‘é€é€šçŸ¥å¼‚å¸¸: {token_address} | é”™è¯¯: {e}", exc_info=True)
            self.alert_fail_count += 1  # å¼‚å¸¸ä¹Ÿç®—å‘é€å¤±è´¥
            return False
    
    async def check_external_is_fourmeme(self, token_address: str) -> tuple[bool, bool, Optional[Dict]]:
        """
        æ£€æŸ¥å¤–ç›˜ä»£å¸æ˜¯å¦æ¥è‡ª fourmeme å¹³å°
        
        Returns:
            (is_fourmeme, is_confirmed, launchpad_info):
            - is_fourmeme: æ˜¯å¦æ˜¯fourmeme
            - is_confirmed: æ˜¯å¦ç¡®è®¤ç»“æœï¼ˆFalseè¡¨ç¤ºAPIå¤±è´¥ï¼Œç»“æœä¸ç¡®å®šï¼‰
            - launchpad_info: è¯¦ç»†ä¿¡æ¯ï¼ˆä»…å½“is_fourmeme=Trueæ—¶æœ‰å€¼ï¼‰
            
        ç¤ºä¾‹:
            (True, True, {...})   - ç¡®è®¤æ˜¯fourmeme
            (False, True, None)   - ç¡®è®¤ä¸æ˜¯fourmemeï¼ˆå¯ä»¥åŠ é»‘åå•ï¼‰
            (False, False, None)  - APIå¤±è´¥ï¼ŒæœªçŸ¥ï¼ˆä¸åº”åŠ é»‘åå•ï¼‰
        """
        dbotx_api = self.get_thread_dbotx_api()
        
        try:
            launchpad_info = await dbotx_api.get_token_launchpad_info('bsc', token_address)
            
            # ğŸ“Š Prometheus: è®°å½•DBotX APIè°ƒç”¨ + ç§¯åˆ†æ¶ˆè´¹ï¼ˆ10åˆ†/æ¬¡ï¼‰+ ä¿å­˜åˆ°Redis
            self._inc_credits_and_save(10)
            
            if not launchpad_info:
                # APIå¤±è´¥æˆ–æ— æ•°æ®ï¼Œç»“æœä¸ç¡®å®š
                # è¿™å¯èƒ½æ˜¯ï¼š1) APIæ•…éšœ  2) ç½‘ç»œé—®é¢˜  3) tokenå¤ªæ–°è¿˜æ²¡æ•°æ®
                # ä¸ºå®‰å…¨èµ·è§ï¼Œä¸ç¡®è®¤ç»“æœ
                return (False, False, None)
            
            launchpad = launchpad_info.get('launchpad', '').lower()
            
            if launchpad == 'fourmeme':
                # ç¡®è®¤æ˜¯fourmeme
                return (True, True, launchpad_info)
            elif launchpad:
                # æœ‰æ˜ç¡®çš„launchpadä¿¡æ¯ï¼ˆå¦‚pancake_v2ï¼‰ï¼Œç¡®è®¤ä¸æ˜¯fourmeme
                return (False, True, None)
            else:
                # launchpadä¸ºç©ºï¼Œå¯èƒ½æ˜¯æ•°æ®ä¸å®Œæ•´ï¼Œä¸ç¡®è®¤
                return (False, False, None)
        
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ Launchpad å¤±è´¥: {e}")
            # APIå¼‚å¸¸ï¼Œç»“æœä¸ç¡®å®š
            return (False, False, None)
    
    def _save_second_layer_result(
        self,
        tx_hash: str,
        ca: str,
        pair_address: str,
        pool_type: str,
        is_internal: bool,
        usd_value: float,
        pass_second_layer: bool,
        filter_reason: str = None,
        token_data: dict = None,
        alert_sent: bool = False,
        alert_blocked_reason: str = None
    ):
        """
        ä¿å­˜ç¬¬äºŒå±‚è¿‡æ»¤ç»“æœåˆ°æ•°æ®åº“ï¼ˆç”¨äºå¤ç›˜åˆ†æï¼‰
        
        Args:
            tx_hash: äº¤æ˜“å“ˆå¸Œ
            ca: ä»£å¸åœ°å€
            pair_address: äº¤æ˜“å¯¹åœ°å€
            pool_type: æ± ç±»å‹ï¼ˆå†…ç›˜/å¤–ç›˜ï¼‰
            is_internal: æ˜¯å¦å†…ç›˜
            usd_value: äº¤æ˜“é‡‘é¢
            pass_second_layer: æ˜¯å¦é€šè¿‡ç¬¬äºŒå±‚
            filter_reason: æœªé€šè¿‡åŸå› 
            token_data: ä»£å¸æ•°æ®ï¼ˆå¦‚æœé€šè¿‡ï¼‰
            alert_sent: æ˜¯å¦å‘é€å‘Šè­¦
            alert_blocked_reason: å‘Šè­¦è¢«æ‹¦æˆªåŸå› 
        """
        try:
            # æå–æ•°æ®
            symbol = token_data.get('symbol') if token_data else None
            name = token_data.get('name') if token_data else None
            price = token_data.get('price') if token_data else 0
            market_cap = token_data.get('market_cap') if token_data else 0
            price_change = token_data.get('price_change') if token_data else 0
            volume = token_data.get('volume') if token_data else 0
            top10_holder_rate = token_data.get('top10_holder_rate', 0) * 100 if token_data and token_data.get('top10_holder_rate') else 0
            holder_count = token_data.get('holder_count') if token_data else 0
            
            # è§¦å‘äº‹ä»¶JSONåŒ–
            triggered_events = token_data.get('triggered_events') if token_data else None
            if triggered_events:
                triggered_events_json = json.dumps([
                    {
                        'event': e.get('event') if isinstance(e, dict) else str(e),
                        'description': e.get('description') if isinstance(e, dict) else str(e)
                    } for e in triggered_events
                ], ensure_ascii=False)
            else:
                triggered_events_json = None
            
            # SQLæ’å…¥ï¼ˆæ”¯æŒå‘Šè­¦çŠ¶æ€å­—æ®µï¼‰
            # æ³¨æ„ï¼šä¸ä½¿ç”¨UNIQUE KEYï¼Œå› ä¸ºåŒä¸€tx_hash+caå¯èƒ½æœ‰å¤šæ¡è®°å½•
            sql = """
            INSERT INTO bsc_second_layer_filter_log (
                tx_hash, ca, token_symbol, token_name, pair_address,
                pool_type, is_internal, usd_value,
                pass_second_layer, filter_reason,
                price_usd, market_cap, price_change, volume,
                top10_holder_rate, holder_count,
                triggered_events, 
                alert_sent, alert_blocked_reason,
                created_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
            """
            
            params = (
                tx_hash, ca, symbol, name, pair_address,
                pool_type, 1 if is_internal else 0, usd_value,
                1 if pass_second_layer else 0, filter_reason,
                price, market_cap, price_change, volume,
                top10_holder_rate, holder_count,
                triggered_events_json,
                1 if alert_sent else 0, alert_blocked_reason
            )
            
            # åŒæ­¥æ‰§è¡Œï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            from src.solalert.core.database import get_db
            db = get_db()
            db.execute_update(sql, params)
            
            logger.debug(f"ğŸ“ å·²è®°å½•ç¬¬äºŒå±‚è¿‡æ»¤ç»“æœ: {symbol or ca[:10]} (é€šè¿‡={pass_second_layer})")
            
        except Exception as e:
            # è®°å½•å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            logger.warning(f"âš ï¸  è®°å½•ç¬¬äºŒå±‚è¿‡æ»¤ç»“æœå¤±è´¥: {e}")
    
    def _update_alert_status(self, tx_hash: str, ca: str, alert_sent: bool = False, alert_blocked_reason: str = None):
        """
        æ›´æ–°ç¬¬äºŒå±‚è¿‡æ»¤è®°å½•çš„å‘Šè­¦çŠ¶æ€ï¼ˆåªæ›´æ–°æœ€æ–°çš„è®°å½•ï¼‰
        
        Args:
            tx_hash: äº¤æ˜“å“ˆå¸Œ
            ca: ä»£å¸åœ°å€
            alert_sent: æ˜¯å¦å‘é€å‘Šè­¦
            alert_blocked_reason: å‘Šè­¦è¢«æ‹¦æˆªåŸå› 
        
        Note:
            ç”±äºåŒä¸€tx_hash+caå¯èƒ½æœ‰å¤šæ¡è®°å½•ï¼ˆå¿«é€Ÿè·¯å¾„+å…œåº•è·¯å¾„ï¼‰ï¼Œ
            è¿™é‡Œåªæ›´æ–°idæœ€å¤§çš„é‚£æ¡ï¼ˆæœ€æ–°è®°å½•ï¼‰
        """
        try:
            sql = """
            UPDATE bsc_second_layer_filter_log
            SET alert_sent = %s, alert_blocked_reason = %s
            WHERE tx_hash = %s AND ca = %s
            ORDER BY id DESC
            LIMIT 1
            """
            
            from src.solalert.core.database import get_db
            db = get_db()
            db.execute_update(sql, (1 if alert_sent else 0, alert_blocked_reason, tx_hash, ca))
            
            logger.debug(f"ğŸ“ æ›´æ–°å‘Šè­¦çŠ¶æ€: {ca[:10]} (å‘é€={alert_sent}, åŸå› ={alert_blocked_reason})")
            
        except Exception as e:
            logger.warning(f"âš ï¸  æ›´æ–°å‘Šè­¦çŠ¶æ€å¤±è´¥: {e}")
    
    async def second_layer_filter(
        self,
        token_address: str,
        pair_address: str,
        launchpad_info: Dict,
        is_internal: bool,
        path: str = 'fallback'
    ) -> Optional[Dict]:
        """
        ç¬¬äºŒå±‚è¿‡æ»¤ï¼šæŒ‡æ ‡æ£€æŸ¥
        Args:
            path: 'fast' æˆ– 'fallback'ï¼Œç”¨äºPrometheusæ ‡ç­¾
        """
        dbotx_api = self.get_thread_dbotx_api()
        
        try:
            # 1. ä½¿ç”¨ launchpad_info ä¸­çš„ pair_addressï¼ˆå¦‚æœæœ‰ï¼‰
            api_pair_address = launchpad_info.get('pair_address')
            if api_pair_address:
                pair_address = api_pair_address
            
            # 2. è°ƒç”¨ DBotX API è·å–ä»£å¸æŒ‡æ ‡
            raw_data = await dbotx_api.get_pair_info('bsc', pair_address)
            
            # ğŸ“Š Prometheus: è®°å½•DBotX APIè°ƒç”¨ + ç§¯åˆ†æ¶ˆè´¹ï¼ˆ10åˆ†/æ¬¡ï¼‰+ ä¿å­˜åˆ°Redis
            # æ³¨æ„ï¼šAPIè¿”å›Noneæ˜¯æ­£å¸¸ä¸šåŠ¡é€»è¾‘ï¼ˆä»£å¸æœªæ”¶å½•ï¼‰ï¼Œä¸ç®—å¤±è´¥
            self._inc_credits_and_save(10)
            
            if not raw_data:
                logger.debug("ç¬¬äºŒå±‚è¿‡æ»¤-æ— DBotXæ•°æ®", extra={"token": token_address[:10]})
                # è®°å½•å¤±è´¥ç»“æœ
                if hasattr(self.thread_local, 'current_tx_context'):
                    ctx = self.thread_local.current_tx_context
                    self._save_second_layer_result(
                        tx_hash=ctx.get('tx_hash'),
                        ca=token_address,
                        pair_address=pair_address,
                        pool_type="å†…ç›˜" if is_internal else "å¤–ç›˜",
                        is_internal=is_internal,
                        usd_value=ctx.get('usd_value', 0),
                        pass_second_layer=False,
                        filter_reason="DBotX APIæ— æ•°æ®ï¼ˆä»£å¸æœªæ”¶å½•ï¼‰"
                    )
                return None
            
            # 3. åˆ¤æ–­å†…å¤–ç›˜
            launchpad_status = launchpad_info.get('launchpad_status', 0)
            is_internal = (launchpad_status == 0)
            pool_type = "å†…ç›˜" if is_internal else "å¤–ç›˜"
            pool_emoji = "ğŸ”´" if is_internal else "ğŸŸ¢"
            
            # 4. æ ¹æ®å†…å¤–ç›˜é€‰æ‹©æ—¶é—´é—´éš”
            time_interval = self.time_interval_internal if is_internal else self.time_interval_external
            
            # 5. è§£ææ•°æ®ï¼ˆä½¿ç”¨åŠ¨æ€æ—¶é—´é—´éš”ï¼‰
            token_data = dbotx_api.parse_token_data(raw_data, time_interval)
            if not token_data:
                logger.debug(f"â­ï¸  [ç¬¬äºŒå±‚] è§£æå¤±è´¥: {token_address}...")
                # è®°å½•å¤±è´¥ç»“æœ
                if hasattr(self.thread_local, 'current_tx_context'):
                    ctx = self.thread_local.current_tx_context
                    self._save_second_layer_result(
                        tx_hash=ctx.get('tx_hash'),
                        ca=token_address,
                        pair_address=pair_address,
                        pool_type=pool_type,
                        is_internal=is_internal,
                        usd_value=ctx.get('usd_value', 0),
                        pass_second_layer=False,
                        filter_reason="è§£æDBotXæ•°æ®å¤±è´¥"
                    )
                return None
            
            # 6. TopæŒæœ‰è€…è¿‡æ»¤ï¼ˆå†…ç›˜å’Œå¤–ç›˜éƒ½æ£€æŸ¥ï¼‰
            # å…ˆåˆ¤æ–­ Redis é…ç½®æ˜¯å¦æœ‰ topHoldersThreshold
            top_holders_threshold = self.top_holders_threshold_internal if is_internal else self.top_holders_threshold_external
            top10_holder_check_passed = None  # ç”¨äºæ—¥å¿—æ˜¾ç¤º
            if top_holders_threshold is not None:
                # å†åˆ¤æ–­ API è¿”å›æ•°æ®æ˜¯å¦æœ‰ top10_holder_rate
                top10_holder_rate = token_data.get('top10_holder_rate')
                if top10_holder_rate is not None:
                    # API è¿”å›çš„æ˜¯å°æ•°ï¼ˆ0-1ï¼‰ï¼Œéœ€è¦è½¬æˆç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰å†æ¯”è¾ƒ
                    top10_holder_percent = top10_holder_rate * 100
                    top10_holder_check_passed = top10_holder_percent < top_holders_threshold
                    # ä¸¤ä¸ªéƒ½æœ‰ï¼Œæ‰è¿›è¡Œæ ¡éªŒ
                    if top10_holder_percent >= top_holders_threshold:
                        symbol = token_data.get('symbol', 'Unknown')
                        logger.info(f"â­ï¸  [ç¬¬äºŒå±‚] Top10æŒæœ‰è€…æ¯”ä¾‹è¿‡é«˜: {symbol} ({top10_holder_percent:.1f}% >= {top_holders_threshold:.1f}%)")
                        # è®°å½•å¤±è´¥ç»“æœ
                        if hasattr(self.thread_local, 'current_tx_context'):
                            ctx = self.thread_local.current_tx_context
                            self._save_second_layer_result(
                                tx_hash=ctx.get('tx_hash'),
                                ca=token_address,
                                pair_address=pair_address,
                                pool_type=pool_type,
                                is_internal=is_internal,
                                usd_value=ctx.get('usd_value', 0),
                                pass_second_layer=False,
                                filter_reason=f"Top10æŒæœ‰è€…æ¯”ä¾‹è¿‡é«˜: {top10_holder_percent:.1f}% >= {top_holders_threshold:.1f}%",
                                token_data=token_data
                            )
                        return None
                else:
                    top10_holder_check_passed = "N/A"  # APIæ²¡è¿”å›æ•°æ®ï¼Œè·³è¿‡æ£€æŸ¥
            else:
                top10_holder_check_passed = "æœªé…ç½®"  # Redisæœªé…ç½®ï¼Œè·³è¿‡æ£€æŸ¥
            
            # 7. è·å–æŒ‡æ ‡æ•°æ® + æ—¶é—´çª—å£é€€è®©ç­–ç•¥
            price_change = token_data.get('price_change', 0)
            volume = token_data.get('volume', 0)
            symbol = token_data.get('symbol', 'Unknown')
            fallback_info = None  # ç”¨äºè®°å½•é€€è®©ä¿¡æ¯ï¼ˆç»™TGæ’­æŠ¥ç”¨ï¼‰
            
            # æ—¶é—´çª—å£é€€è®©ï¼šå¦‚æœæ•°æ®ä¸º0ï¼Œè‡ªåŠ¨é€€è®©åˆ°æ›´é•¿æ—¶é—´çª—å£
            if price_change == 0 and volume == 0:
                original_interval = time_interval
                fallback_interval = None
                
                # å®šä¹‰é€€è®©é“¾ï¼ˆ1mâ†’5måœæ­¢ï¼Œ5mâ†’1håœæ­¢ï¼‰
                if time_interval == '1m':
                    fallback_interval = '5m'
                elif time_interval == '5m':
                    fallback_interval = '1h'
                
                # å°è¯•é€€è®©
                if fallback_interval:
                    logger.info(f"   ğŸ”„ {original_interval}æ•°æ®ä¸º0ï¼Œå°è¯•é€€è®©è‡³{fallback_interval}")
                    fallback_data = dbotx_api.parse_token_data(raw_data, fallback_interval)
                    if fallback_data:
                        fallback_price_change = fallback_data.get('price_change', 0)
                        fallback_volume = fallback_data.get('volume', 0)
                        
                        if fallback_price_change != 0 or fallback_volume != 0:
                            # é€€è®©æˆåŠŸï¼Œä½¿ç”¨é€€è®©æ•°æ®
                            price_change = fallback_price_change
                            volume = fallback_volume
                            time_interval = fallback_interval  # æ›´æ–°æ—¶é—´çª—å£
                            fallback_info = {
                                'original': original_interval,
                                'fallback': fallback_interval,
                                'reason': f'{original_interval}æ•°æ®ä¸º0'
                            }
                            # Prometheus: æ—¶é—´çª—å£é€€è®©è®¡æ•°
                            if HAS_PROMETHEUS:
                                self.metrics_fallback.labels(original=original_interval, fallback=fallback_interval).inc()
                            logger.info(f"   âœ… é€€è®©æˆåŠŸ: ä½¿ç”¨{fallback_interval}æ•°æ® (æ¶¨å¹…{price_change:+.2f}%, äº¤æ˜“é‡${volume:,.2f})")
                        else:
                            logger.info(f"   âŒ {fallback_interval}æ•°æ®ä¹Ÿä¸º0ï¼Œæ— æ³•é€€è®©")
                    else:
                        logger.warning(f"   âš ï¸ è§£æ{fallback_interval}æ•°æ®å¤±è´¥")
            
            # 8. æ„é€  stats æ•°æ®ï¼ˆç”¨äº TriggerLogicï¼‰
            stats = {
                'priceChange': price_change,
                'volume': volume,
                'holderChange': 0
            }
            
            # 9. é€‰æ‹©å¯¹åº”çš„ events_config å’Œ trigger_logic
            events_config = self.internal_events_config if is_internal else self.external_events_config
            trigger_logic = self.trigger_logic_internal if is_internal else self.trigger_logic_external
            
            # ç¬¬äºŒå±‚æ£€æŸ¥è®¡æ•°
            if is_internal:
                self.second_layer_check_internal += 1
                if HAS_PROMETHEUS:
                    self.metrics_second_layer_check.labels(type='internal', path=path).inc()
            else:
                self.second_layer_check_external += 1
                if HAS_PROMETHEUS:
                    self.metrics_second_layer_check.labels(type='external', path=path).inc()
            
            logger.info(f"ğŸ” [ç¬¬äºŒå±‚æ£€æŸ¥] {pool_emoji}{pool_type} {symbol} ({token_address})")
            logger.info(f"   â”œâ”€ {time_interval}æ¶¨å¹…: {price_change:+.2f}%")
            logger.info(f"   â”œâ”€ {time_interval}äº¤æ˜“é‡: ${volume:,.2f}")
            
            # æ˜¾ç¤º Top10 æŒæœ‰è€…æ£€æŸ¥çŠ¶æ€
            if top10_holder_check_passed == "æœªé…ç½®":
                logger.info(f"   â”œâ”€ Top10æŒæœ‰è€…: æœªé…ç½®é˜ˆå€¼ï¼ˆè·³è¿‡æ­¤é¡¹ï¼‰")
            elif top10_holder_check_passed == "N/A":
                logger.info(f"   â”œâ”€ Top10æŒæœ‰è€…: APIæœªè¿”å›ï¼ˆè·³è¿‡æ­¤é¡¹ï¼‰")
            elif top10_holder_check_passed is True:
                top10_holder_rate = token_data.get('top10_holder_rate', 0)
                logger.info(f"   â”œâ”€ Top10æŒæœ‰è€…: {top10_holder_rate * 100:.1f}% (âœ… < {top_holders_threshold:.1f}%)")
            elif top10_holder_check_passed is False:
                # è¿™ä¸ªåˆ†æ”¯ä¸ä¼šæ‰§è¡Œï¼Œå› ä¸ºå¦‚æœæœªé€šè¿‡å·²ç»returnäº†
                pass
            
            # æ˜¾ç¤ºè§¦å‘é€»è¾‘
            logic_text = "AND" if trigger_logic == "all" else "OR"
            logger.info(f"   â””â”€ é…ç½®é˜ˆå€¼: æ¶¨å¹…>={events_config.get('priceChange', {}).get('risePercent')}% {logic_text} äº¤æ˜“é‡>=${events_config.get('volume', {}).get('threshold')}")
            logger.debug(f"   é…ç½®è¯¦æƒ…: {events_config}")
            logger.debug(f"   ç»Ÿè®¡æ•°æ®: {stats}")
            
            # 10. ä½¿ç”¨ TriggerLogic è¯„ä¼°ï¼ˆä½¿ç”¨é…ç½®çš„è§¦å‘é€»è¾‘ï¼‰
            should_trigger, triggered_events = TriggerLogic.evaluate_trigger(
                stats, events_config, trigger_logic
            )
            
            logger.debug(f"   è§¦å‘ç»“æœ: should_trigger={should_trigger}, triggered_events={len(triggered_events) if triggered_events else 0}")
            
            if not should_trigger:
                logger.info(f"   âŒ æœªè¾¾åˆ°è§¦å‘æ¡ä»¶")
                # è®°å½•å¤±è´¥ç»“æœ - ç”Ÿæˆå¤±è´¥åŸå› 
                logic_text = "all(éœ€è¦æ‰€æœ‰æŒ‡æ ‡)" if trigger_logic == "all" else "any(éœ€è¦ä»»ä¸€æŒ‡æ ‡)"
                price_threshold = events_config.get('priceChange', {}).get('risePercent', 0)
                volume_threshold = events_config.get('volume', {}).get('threshold', 0)
                filter_reason = f"æœªæ»¡è¶³è§¦å‘é€»è¾‘({logic_text}): æ¶¨å¹…{price_change:+.2f}% < {price_threshold}% ä¸” äº¤æ˜“é‡${volume:,.2f} < ${volume_threshold:,.2f}"
                
                if hasattr(self.thread_local, 'current_tx_context'):
                    ctx = self.thread_local.current_tx_context
                    self._save_second_layer_result(
                        tx_hash=ctx.get('tx_hash'),
                        ca=token_address,
                        pair_address=pair_address,
                        pool_type=pool_type,
                        is_internal=is_internal,
                        usd_value=ctx.get('usd_value', 0),
                        pass_second_layer=False,
                        filter_reason=filter_reason,
                        token_data=token_data
                    )
                return None
            
            # 11. é€šè¿‡ç­›é€‰ï¼Œè¿”å›æ•°æ®
            logger.info(f"   âœ… æ»¡è¶³æ¡ä»¶ï¼è§¦å‘ {len(triggered_events)} ä¸ªäº‹ä»¶")
            
            # ç¬¬äºŒå±‚é€šè¿‡è®¡æ•°
            if is_internal:
                self.second_layer_pass_internal += 1
                if HAS_PROMETHEUS:
                    self.metrics_second_layer_pass.labels(type='internal', path=path).inc()
            else:
                self.second_layer_pass_external += 1
                if HAS_PROMETHEUS:
                    self.metrics_second_layer_pass.labels(type='external', path=path).inc()
            
            token_data['pool_type'] = pool_type
            token_data['is_internal'] = is_internal
            token_data['pool_emoji'] = pool_emoji
            token_data['triggered_events'] = triggered_events
            token_data['fallback_info'] = fallback_info  # æ—¶é—´çª—å£é€€è®©ä¿¡æ¯
            
            # è®°å½•æˆåŠŸç»“æœ
            if hasattr(self.thread_local, 'current_tx_context'):
                ctx = self.thread_local.current_tx_context
                self._save_second_layer_result(
                    tx_hash=ctx.get('tx_hash'),
                    ca=token_address,
                    pair_address=pair_address,
                    pool_type=pool_type,
                    is_internal=is_internal,
                    usd_value=ctx.get('usd_value', 0),
                    pass_second_layer=True,
                    filter_reason=None,
                    token_data=token_data
                )
            
            return token_data
        
        except Exception as e:
            logger.error(f"âŒ ç¬¬äºŒå±‚è¿‡æ»¤å¤±è´¥: {e}")
            return None
    
    async def handle_swap_event(self, log: Dict):
        """
        å¤„ç† PancakeSwap Swap äº‹ä»¶ï¼ˆå¤–ç›˜ï¼‰
        
        ğŸš€ ä¼˜åŒ–æ¶æ„ï¼šå…ˆRPCè¿‡æ»¤ï¼Œå†DBotXè·å–æŒ‡æ ‡ï¼ˆèŠ‚çœ90%+ APIè°ƒç”¨ï¼‰
        
        æµç¨‹ï¼š
        1. RPCè·å–pairåŸºç¡€ä¿¡æ¯ï¼ˆtoken0/token1/symbolï¼‰- å…è´¹æ— é™ï¼Œ25req/s
        2. ç¬¬ä¸€å±‚è¿‡æ»¤ï¼ˆé‡‘é¢ï¼‰- è¿‡æ»¤æ‰å°é¢äº¤æ˜“
        3. fourmemeæ£€æŸ¥ï¼ˆå…ˆç¼“å­˜ï¼Œç¼“å­˜æœªå‘½ä¸­æ‰è°ƒç”¨APIï¼‰
        4. ç¡®è®¤æ˜¯fourmemeåï¼Œæ‰è°ƒç”¨DBotX APIè·å–æŒ‡æ ‡æ•°æ®
        5. ç¬¬äºŒå±‚è¿‡æ»¤ï¼ˆæŒ‡æ ‡ï¼šæ¶¨è·Œå¹…ã€äº¤æ˜“é‡ç­‰ï¼‰
        
        ä¼˜åŒ–æ•ˆæœï¼š
        - åŸæ¶æ„ï¼šæ¯ä¸ªswapäº‹ä»¶ç«‹å³è°ƒç”¨APIï¼ˆ10Mç§¯åˆ†/å¤©ï¼Œ11.6æ¬¡/ç§’ï¼‰
        - æ–°æ¶æ„ï¼šä»…fourmemeä»£å¸è°ƒç”¨APIï¼ˆé¢„è®¡å‡å°‘95%æ¶ˆè€—ï¼‰
          - ç¬¬ä¸€å±‚è¿‡æ»¤æ‹¦æˆªï¼š~80%ï¼ˆå°é¢äº¤æ˜“ï¼‰
          - Redisç¼“å­˜æ‹¦æˆªï¼š~15%ï¼ˆéfourmemeå·²çŸ¥ä»£å¸ï¼‰
          - æœ€ç»ˆè°ƒç”¨APIï¼š~5%ï¼ˆfourmemeæ–°å¸/æœªç¼“å­˜ï¼‰
        
        é¢„è®¡ç§¯åˆ†æ¶ˆè€—ï¼š10M â†’ 0.5M/å¤©ï¼ˆå»¶é•¿20å€ä½¿ç”¨æ—¶é—´ï¼‰
        """
        tx_hash = log.get("transactionHash")
        pair_address = log.get("address", "").lower()
        swap_data = self.parse_swap_data(log.get("data"))
        
        if not swap_data:
            # WebSocketæ•°æ®è§£æå¤±è´¥ï¼Œå°è¯•ä»receiptå…œåº•
            await self._handle_swap_with_receipt_fallback(tx_hash, pair_address)
            return
        
        # ============================================
        # é˜¶æ®µ1ï¼šRPCè·å–åŸºç¡€ä¿¡æ¯ï¼ˆå…è´¹ï¼Œå¿«é€Ÿè¿‡æ»¤ï¼‰
        # ============================================
        mint = None
        base_mint = None
        base_symbol = None
        token_symbol = None
        pair_info_rpc = None
        
        # ä½¿ç”¨ RPC è·å– token0/token1
        pair_info_rpc = self.get_pair_full_info(pair_address)
        if not pair_info_rpc:
            logger.debug(f"â­ï¸  RPCè·å–pairä¿¡æ¯å¤±è´¥ï¼Œè·³è¿‡: {pair_address}")
            return
        
        mint = pair_info_rpc['token0'].lower()  # token0 = mint
        base_mint = pair_info_rpc['token1'].lower()  # token1 = baseMint
        token_symbol = pair_info_rpc.get('symbol0', '???')
        base_symbol = pair_info_rpc.get('symbol1', '???')
        base_decimals = pair_info_rpc.get('decimals0', 18)
        
        # å¿«é€Ÿè¿‡æ»¤ï¼šæ£€æŸ¥åŸºç¡€è´§å¸æ˜¯å¦æ˜¯æˆ‘ä»¬å…³æ³¨çš„ç¨³å®šå¸
        if base_mint not in (self.USDT, self.USDC, self.WBNB):
            return
        
        # ============================================
        # é˜¶æ®µ2ï¼šè§£æäº¤æ˜“é‡‘é¢å¹¶è®¡ç®—USDä»·å€¼
        # ============================================
        amount0_in = swap_data["amount0In"]
        amount1_in = swap_data["amount1In"]
        amount0_out = swap_data["amount0Out"]
        amount1_out = swap_data["amount1Out"]
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯ä¹°å…¥è¡Œä¸ºï¼ˆç¨³å®šå¸è¾“å…¥ â†’ ä¸»ä»£å¸è¾“å‡ºï¼‰
        # æ ¹æ®æµ‹è¯•ç»“æœï¼šmint=token0, baseMint=token1 (100%åŒ¹é…)
        quote_token = None
        base_token = None
        quote_amount = 0
        base_amount = 0
        quote_decimals = 18  # ç¨³å®šå¸ç²¾åº¦é»˜è®¤18
        quote_symbol = base_symbol
        base_symbol = token_symbol
        
        if amount0_in > 0 and amount1_out > 0:
            # token0è¾“å…¥ â†’ token1è¾“å‡º
            # è¿™ç§æƒ…å†µé€šå¸¸ä¸æ˜¯ä¹°å…¥ï¼ˆtoken0æ˜¯ä¸»ä»£å¸ï¼Œtoken1æ˜¯ç¨³å®šå¸ï¼‰
            # ä½†æˆ‘ä»¬ä»éœ€æ£€æŸ¥
            if mint == base_mint:  # ç‰¹æ®Šæƒ…å†µï¼šç¨³å®šå¸å¯¹
                return
            logger.debug(f"â­ï¸  å¯èƒ½æ˜¯å–å‡ºï¼štoken0è¾“å…¥ â†’ token1è¾“å‡º")
            return
            
        elif amount1_in > 0 and amount0_out > 0:
            # token1è¾“å…¥ â†’ token0è¾“å‡º
            # æ ¹æ®æµ‹è¯•ï¼štoken1=baseMintï¼ˆç¨³å®šå¸ï¼‰ï¼Œtoken0=mintï¼ˆä¸»ä»£å¸ï¼‰
            # è¿™æ˜¯æ ‡å‡†çš„ä¹°å…¥è¡Œä¸º âœ“
            quote_token = base_mint  # ç¨³å®šå¸
            base_token = mint  # ä¸»ä»£å¸
            quote_amount = amount1_in
            base_amount = amount0_out
        else:
            # å…¶ä»–æƒ…å†µï¼šå¯èƒ½æ˜¯å¤æ‚äº¤æ˜“
            return
        
        if not quote_token or not base_token:
            return
        
        quote_value = Decimal(quote_amount) / (Decimal(10) ** Decimal(quote_decimals))
        if quote_token == self.WBNB:
            wbnb_price = self.get_wbnb_price()
            usd_value = float(quote_value) * wbnb_price
        else:
            usd_value = float(quote_value)
        
        # ç¬¬ä¸€å±‚è¿‡æ»¤ï¼ˆè®¡æ—¶ï¼‰
        start_time = time.time()
        if not self.first_layer_filter(usd_value, is_internal=False):
            return
        first_layer_time = time.time() - start_time
        if HAS_PROMETHEUS:
            self.metrics_processing_time.labels(stage='first_layer').observe(first_layer_time)
        
        # ä¸œå…«åŒºæ—¶é—´
        cn_time = datetime.now(timezone(timedelta(hours=8))).strftime('%H:%M:%S')
        logger.info(f"âœ… [å¤–ç›˜] é€šè¿‡ç¬¬ä¸€å±‚: {base_symbol} (${usd_value:.2f}) [{cn_time}] - {base_token[:10]}...")
        self.first_layer_pass_external += 1  # å¤–ç›˜ç¬¬ä¸€å±‚è®¡æ•°
        
        # Prometheus: ç¬¬ä¸€å±‚é€šè¿‡è®¡æ•°
        if HAS_PROMETHEUS:
            self.metrics_first_layer_pass.labels(type='external').inc()
        
        # ============================================
        # é˜¶æ®µ3ï¼šfourmemeæ£€æŸ¥ï¼ˆå…ˆç¼“å­˜ï¼Œå†APIï¼‰
        # ============================================
        # å…ˆæ£€æŸ¥fourmemeç™½åå•ç¼“å­˜
        is_cached_fourmeme = False
        if self.redis_client:
            try:
                is_cached_fourmeme = self.redis_client.sismember(self.FOURMEME_KEY, base_token)
                if is_cached_fourmeme:
                    self.fourmeme_cache_hit_count += 1
                    logger.info(f"âš¡ [å¤–ç›˜] fourmemeç¼“å­˜å‘½ä¸­ #{self.fourmeme_cache_hit_count}: {base_symbol} (${usd_value:.2f}) - {base_token[:10]}...")
                    # è·³è¿‡åç»­APIè°ƒç”¨ï¼Œç›´æ¥è¿›å…¥ç¬¬äºŒå±‚
            except Exception as e:
                logger.warning(f"âš ï¸  fourmemeç¼“å­˜æŸ¥è¯¢å¤±è´¥: {e}")
        
        # å†æ£€æŸ¥ Redis ç¼“å­˜ï¼ˆéfourmeme tokené»‘åå•ï¼‰
        if not is_cached_fourmeme and self.redis_client:
            try:
                is_cached_non_fourmeme = self.redis_client.sismember(self.NON_FOURMEME_KEY, base_token)
                if is_cached_non_fourmeme:
                    self.cache_hit_count += 1
                    logger.info(f"â­ï¸  [å¤–ç›˜] éfourmeme (ç¼“å­˜å‘½ä¸­ #{self.cache_hit_count}): {base_symbol} (${usd_value:.2f}) - {base_token[:10]}...")
                    
                    # ğŸ“Š Prometheus: ç¼“å­˜å‘½ä¸­éfourmeme
                    if HAS_PROMETHEUS:
                        self.metrics_non_fourmeme.labels(source='cache_hit').inc()
                    
                    return
            except Exception as e:
                logger.warning(f"âš ï¸  Redisç¼“å­˜æŸ¥è¯¢å¤±è´¥: {e}")
        
        # ç¼“å­˜éƒ½æœªå‘½ä¸­ï¼Œè°ƒç”¨APIæ£€æŸ¥æ˜¯å¦æ˜¯fourmemeï¼ˆä¼šæ¶ˆè€—10ç§¯åˆ†ï¼‰
        if not is_cached_fourmeme:
            is_fourmeme, is_confirmed, launchpad_info = await self.check_external_is_fourmeme(base_token)
            
            if not is_fourmeme:
                if is_confirmed:
                    # ğŸ“Š Prometheus: APIé¦–æ¬¡åˆ¤æ–­ä¸ºéfourmeme
                    if HAS_PROMETHEUS:
                        self.metrics_non_fourmeme.labels(source='api_first_check').inc()
                    
                    # ç¡®è®¤ä¸æ˜¯fourmeme â†’ åŠ å…¥Redisé»‘åå•ï¼ˆ30å¤©è¿‡æœŸï¼‰
                    if self.redis_client:
                        try:
                            self.redis_client.client.sadd(self.NON_FOURMEME_KEY, base_token)
                            self.redis_client.client.expire(self.NON_FOURMEME_KEY, self.NON_FOURMEME_TTL)
                            logger.debug(f"âœ… å·²åŠ å…¥é»‘åå•: {base_symbol} - {base_token[:10]}...")
                        except Exception as e:
                            logger.warning(f"âš ï¸  Redisç¼“å­˜å†™å…¥å¤±è´¥: {e}")
                    
                    logger.info(f"â­ï¸  [å¤–ç›˜] éfourmemeï¼Œè·³è¿‡: {base_symbol} (${usd_value:.2f}) | {base_token[:10]}...")
                else:
                    # API å¤±è´¥ï¼Œä¸ç¡®å®š â†’ ä¸åŠ é»‘åå•
                    logger.info(f"âš ï¸  [å¤–ç›˜] fourmemeæ£€æŸ¥å¤±è´¥ï¼ˆAPIæ•…éšœï¼‰ï¼Œè·³è¿‡ä½†ä¸åŠ é»‘åå•: {base_symbol} - {base_token[:10]}...")
                return
            
            # æ˜¯fourmemeï¼ŒåŠ å…¥ç™½åå•ç¼“å­˜ï¼ˆé¿å…é‡å¤APIè°ƒç”¨ï¼‰
            if self.redis_client and is_confirmed:
                try:
                    self.redis_client.client.sadd(self.FOURMEME_KEY, base_token)
                    self.redis_client.client.expire(self.FOURMEME_KEY, self.FOURMEME_TTL)
                    logger.debug(f"âœ… å·²åŠ å…¥fourmemeç™½åå•: {base_symbol} - {base_token[:10]}...")
                except Exception as e:
                    logger.warning(f"âš ï¸  fourmemeç¼“å­˜å†™å…¥å¤±è´¥: {e}")
            
            logger.info(f"âœ… [å¤–ç›˜] æ˜¯fourmeme: {base_symbol} (${usd_value:.2f}) | {base_token[:10]}...")
        else:
            # fourmemeç¼“å­˜å‘½ä¸­ï¼Œå·²ç»åœ¨ä¸Šé¢è¾“å‡ºæ—¥å¿—
            launchpad_info = {'launchpad': 'fourmeme'}  # è®¾ç½®åŸºç¡€ä¿¡æ¯
        
        # ============================================
        # é˜¶æ®µ4ï¼šè°ƒç”¨DBotX APIè·å–æŒ‡æ ‡æ•°æ®ï¼ˆä»…fourmemeä»£å¸ï¼‰
        # ============================================
        # åˆ°è¿™ä¸€æ­¥æ‰è°ƒç”¨APIï¼Œå¤§å¤§å‡å°‘äº†APIè°ƒç”¨æ¬¡æ•°
        dbotx_api = self.get_thread_dbotx_api()
        pair_info_raw = await dbotx_api.get_pair_info('bsc', pair_address)
        
        # ğŸ“Š Prometheus: è®°å½•DBotX APIè°ƒç”¨ + ç§¯åˆ†æ¶ˆè´¹ï¼ˆ10åˆ†/æ¬¡ï¼‰+ ä¿å­˜åˆ°Redis
        self._inc_credits_and_save(10)
        
        # è®¾ç½®ä¸Šä¸‹æ–‡ï¼ˆç”¨äºæ•°æ®åº“è®°å½•ï¼‰
        self.thread_local.current_tx_context = {
            'tx_hash': tx_hash,
            'usd_value': usd_value
        }
        
        # æ£€æŸ¥APIæ˜¯å¦è¿”å›æœ‰æ•ˆæ•°æ®
        if pair_info_raw and pair_info_raw.get('mint') and pair_info_raw.get('baseMint'):
            # ============================================
            # é˜¶æ®µ5ï¼šç¬¬äºŒå±‚è¿‡æ»¤ï¼ˆä½¿ç”¨APIè¿”å›çš„æŒ‡æ ‡æ•°æ®ï¼‰
            # ============================================
            second_layer_start = time.time()
            logger.info(f"âš¡ ä½¿ç”¨DBotX APIæ•°æ®è¿›è¡Œç¬¬äºŒå±‚æ£€æŸ¥: {base_token}")
            
            token_price_usd = pair_info_raw.get('tokenPriceUsd', 0)
            market_cap = pair_info_raw.get('marketCap', 0)
            
            # è·å–é…ç½®çš„æ—¶é—´é—´éš”
            time_interval = self.time_interval_external  # å¤–ç›˜
            
            # æ ¹æ®æ—¶é—´é—´éš”é€‰æ‹©å¯¹åº”çš„æ¶¨è·Œå¹…å’Œäº¤æ˜“é‡ + é€€è®©ç­–ç•¥
            fallback_info = None  # é€€è®©ä¿¡æ¯
            
            if time_interval == '1m':
                price_change = pair_info_raw.get('priceChange1m', 0) * 100
                volume = pair_info_raw.get('buyAndSellVolume1m', 0)
            elif time_interval == '5m':
                price_change = pair_info_raw.get('priceChange5m', 0) * 100
                volume = pair_info_raw.get('buyAndSellVolume5m', 0)
            elif time_interval == '1h':
                price_change = pair_info_raw.get('priceChange1h', 0) * 100
                volume = pair_info_raw.get('buyAndSellVolume1h', 0)
            else:
                price_change = pair_info_raw.get('priceChange5m', 0) * 100  # é»˜è®¤5åˆ†é’Ÿ
                volume = pair_info_raw.get('buyAndSellVolume5m', 0)
            
            # æ—¶é—´çª—å£é€€è®©ï¼šå¦‚æœæ•°æ®ä¸º0ï¼Œè‡ªåŠ¨é€€è®©åˆ°æ›´é•¿æ—¶é—´çª—å£
            if price_change == 0 and volume == 0:
                original_interval = time_interval
                fallback_interval = None
                
                # å®šä¹‰é€€è®©é“¾ï¼ˆ1mâ†’5måœæ­¢ï¼Œ5mâ†’1håœæ­¢ï¼‰
                if time_interval == '1m':
                    fallback_interval = '5m'
                elif time_interval == '5m':
                    fallback_interval = '1h'
                
                # å°è¯•é€€è®©
                if fallback_interval:

                    if fallback_interval == '5m':
                        fallback_price_change = pair_info_raw.get('priceChange5m', 0) * 100
                        fallback_volume = pair_info_raw.get('buyAndSellVolume5m', 0)
                    elif fallback_interval == '1h':
                        fallback_price_change = pair_info_raw.get('priceChange1h', 0) * 100
                        fallback_volume = pair_info_raw.get('buyAndSellVolume1h', 0)
                    else:
                        fallback_price_change = 0
                        fallback_volume = 0
                    
                    if fallback_price_change != 0 or fallback_volume != 0:
                        # é€€è®©æˆåŠŸ
                        price_change = fallback_price_change
                        volume = fallback_volume
                        time_interval = fallback_interval
                        fallback_info = {
                            'original': original_interval,
                            'fallback': fallback_interval,
                            'reason': f'{original_interval}æ•°æ®ä¸º0'
                        }
                        # Prometheus: æ—¶é—´çª—å£é€€è®©è®¡æ•°
                        if HAS_PROMETHEUS:
                            self.metrics_fallback.labels(original=original_interval, fallback=fallback_interval).inc()
                    else:
                        logger.info(f"   âŒ {fallback_interval}æ•°æ®ä¹Ÿä¸º0ï¼Œæ— æ³•é€€è®©")
            
            # è·å–å¤–ç›˜é…ç½®ï¼ˆä» external_events_config è¯»å–ï¼‰
            external_config = self.external_events_config
            
            # Prometheus: å¤–ç›˜ç¬¬äºŒå±‚æ£€æŸ¥è®¡æ•°
            if HAS_PROMETHEUS:
                self.metrics_second_layer_check.labels(type='external', path='api').inc()
            
            # ç¬¬äºŒå±‚åˆ¤æ–­ï¼šæ¶¨è·Œå¹…å’Œäº¤æ˜“é‡
            min_price_change = external_config.get('priceChange', {}).get('risePercent', 50)  # é»˜è®¤50%
            min_volume = external_config.get('volume', {}).get('threshold', 20000)  # é»˜è®¤$20000
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ¡ä»¶
            triggered_events = []
            
            # æ£€æŸ¥æ¶¨è·Œå¹…
            price_change_enabled = external_config.get('priceChange', {}).get('enabled', True)
            if price_change_enabled:
                if price_change >= min_price_change:
                    triggered_events.append({'event': 'priceChange', 'value': price_change})
                    logger.info(f"   âœ… æ¶¨è·Œå¹…è¾¾æ ‡: {price_change:+.2f}% >= {min_price_change}%")
                else:
                    logger.info(f"   â­ï¸  æ¶¨è·Œå¹…ä¸è¶³: {price_change:.2f}% < {min_price_change}%")
            
            # æ£€æŸ¥äº¤æ˜“é‡
            volume_enabled = external_config.get('volume', {}).get('enabled', True)
            if volume_enabled:
                if volume >= min_volume:
                    triggered_events.append({'event': 'volume', 'value': volume})
                    logger.info(f"   âœ… äº¤æ˜“é‡è¾¾æ ‡: ${volume:.2f} >= ${min_volume}")
                else:
                    logger.info(f"   â­ï¸  äº¤æ˜“é‡ä¸è¶³: ${volume:.2f} < ${min_volume}")
            
            # æ ¹æ®è§¦å‘é€»è¾‘åˆ¤æ–­æ˜¯å¦é€šè¿‡ç¬¬äºŒå±‚
            trigger_logic = self.trigger_logic_external  # 'any' æˆ– 'all'
            
            if trigger_logic == 'all':
                # è¦æ±‚æ‰€æœ‰å¯ç”¨çš„æŒ‡æ ‡éƒ½è¾¾æ ‡
                required_events = []
                if price_change_enabled:
                    required_events.append('priceChange')
                if volume_enabled:
                    required_events.append('volume')
                
                triggered_event_names = {e['event'] for e in triggered_events}
                if not all(evt in triggered_event_names for evt in required_events):
                    logger.info(f"   â­ï¸  æœªæ»¡è¶³'all'è§¦å‘é€»è¾‘ï¼ˆéœ€è¦æ‰€æœ‰æŒ‡æ ‡ï¼‰")
                    # è®°å½•å¤±è´¥ç»“æœ
                    filter_reason = f"æœªæ»¡è¶³'all'è§¦å‘é€»è¾‘: æ¶¨å¹…{price_change:+.2f}% < {min_price_change}% ä¸” äº¤æ˜“é‡${volume:,.2f} < ${min_volume:,.2f}"
                    self._save_second_layer_result(
                        tx_hash=tx_hash,
                        ca=base_token,
                        pair_address=pair_address,
                        pool_type="å¤–ç›˜",
                        is_internal=False,
                        usd_value=usd_value,
                        pass_second_layer=False,
                        filter_reason=filter_reason,
                        token_data={'symbol': token_symbol, 'price': token_price_usd, 'market_cap': market_cap, 
                                   'price_change': price_change, 'volume': volume}
                    )
                    return
            elif trigger_logic == 'any':
                # åªè¦æœ‰ä¸€ä¸ªæŒ‡æ ‡è¾¾æ ‡å³å¯
                if not triggered_events:
                    logger.info(f"   â­ï¸  æœªæ»¡è¶³'any'è§¦å‘é€»è¾‘ï¼ˆè‡³å°‘ä¸€ä¸ªæŒ‡æ ‡ï¼‰")
                    # è®°å½•å¤±è´¥ç»“æœ
                    filter_reason = f"æœªæ»¡è¶³'any'è§¦å‘é€»è¾‘: æ¶¨å¹…{price_change:+.2f}% < {min_price_change}% æˆ– äº¤æ˜“é‡${volume:,.2f} < ${min_volume:,.2f}"
                    self._save_second_layer_result(
                        tx_hash=tx_hash,
                        ca=base_token,
                        pair_address=pair_address,
                        pool_type="å¤–ç›˜",
                        is_internal=False,
                        usd_value=usd_value,
                        pass_second_layer=False,
                        filter_reason=filter_reason,
                        token_data={'symbol': token_symbol, 'price': token_price_usd, 'market_cap': market_cap,
                                   'price_change': price_change, 'volume': volume}
                    )
                    return
            
            logger.info(f"âœ… é€šè¿‡ç¬¬äºŒå±‚: è§¦å‘äº‹ä»¶={[e['event'] for e in triggered_events]}")
            
            # è®°å½•ç¬¬äºŒå±‚å¤„ç†è€—æ—¶
            second_layer_time = time.time() - second_layer_start
            if HAS_PROMETHEUS:
                self.metrics_processing_time.labels(stage='second_layer').observe(second_layer_time)
            
            # å¤–ç›˜é€šè¿‡ç¬¬äºŒå±‚è®¡æ•°
            self.second_layer_pass_external += 1
            if HAS_PROMETHEUS:
                self.metrics_second_layer_pass.labels(type='external', path='api').inc()
            
            # æ„å»º token_dataï¼ˆå…¼å®¹åŸæœ‰æ ¼å¼ï¼‰
            token_data = {
                'symbol': token_symbol,
                'price': token_price_usd,
                'price_change': price_change,
                'volume': volume,
                'market_cap': market_cap,
                'buy_tax': pair_info_raw.get('safetyInfo', {}).get('buyTax', 0) if pair_info_raw.get('safetyInfo') else 0,
                'sell_tax': pair_info_raw.get('safetyInfo', {}).get('sellTax', 0) if pair_info_raw.get('safetyInfo') else 0,
                'pool_type': 'pancake_v2',
                'pool_emoji': 'ğŸ”¥',
                'is_internal': False,
                'triggered_events': triggered_events,
                'fallback_info': fallback_info  # æ—¶é—´çª—å£é€€è®©ä¿¡æ¯
            }
            
            # è®°å½•æˆåŠŸç»“æœ
            self._save_second_layer_result(
                tx_hash=tx_hash,
                ca=base_token,
                pair_address=pair_address,
                pool_type="å¤–ç›˜",
                is_internal=False,
                usd_value=usd_value,
                pass_second_layer=True,
                filter_reason=None,
                token_data=token_data
            )
        else:
            # APIæœªè¿”å›æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡
            logger.warning(f"âš ï¸ DBotX APIæœªè¿”å›æœ‰æ•ˆæ•°æ®: {base_token[:10]}...")
            # è®°å½•å¤±è´¥ç»“æœ
            self._save_second_layer_result(
                tx_hash=tx_hash,
                ca=base_token,
                pair_address=pair_address,
                pool_type="å¤–ç›˜",
                is_internal=False,
                usd_value=usd_value,
                pass_second_layer=False,
                filter_reason="DBotX APIæœªè¿”å›æœ‰æ•ˆæ•°æ®"
            )
            return
        
        # ğŸ”’ ç¬¬ä¸€æ­¥ï¼šåªè¯»æ£€æŸ¥å†·å´æœŸï¼ˆå¿«é€Ÿè¿‡æ»¤ï¼‰
        if not await self.check_alert_cooldown_readonly(base_token):
            self.alert_cooldown_blocked += 1
            if HAS_PROMETHEUS:
                self.metrics_alert_cooldown_blocked.inc()
            logger.info(f"â³ å†·å´æœŸå†…ï¼Œè·³è¿‡: {base_token}")
            # æ›´æ–°æ•°æ®åº“è®°å½•ï¼šæ ‡è®°ä¸ºå†·å´æœŸæ‹¦æˆª
            self._update_alert_status(tx_hash, base_token, alert_sent=False, alert_blocked_reason="å†·å´æœŸæ‹¦æˆª")
            return
        
        # ğŸ”’ ç¬¬äºŒæ­¥ï¼šåŸå­æ“ä½œè®¾ç½®å†·å´æœŸï¼ˆé˜²æ­¢ç«æ€æ¡ä»¶å¯¼è‡´é‡å¤å‘é€ï¼‰
        if not await self.check_and_set_alert_cooldown(base_token):
            self.alert_cooldown_blocked += 1
            if HAS_PROMETHEUS:
                self.metrics_alert_cooldown_blocked.inc()
            logger.info(f"â³ å†·å´æœŸå†…ï¼ˆç«æ€ï¼‰ï¼Œè·³è¿‡: {base_token}")
            # æ›´æ–°æ•°æ®åº“è®°å½•ï¼šæ ‡è®°ä¸ºå†·å´æœŸæ‹¦æˆª
            self._update_alert_status(tx_hash, base_token, alert_sent=False, alert_blocked_reason="å†·å´æœŸæ‹¦æˆª")
            return
        
        # æ„å»ºæ¶ˆæ¯
        quote_formatted = self.format_amount(quote_amount, quote_decimals)
        base_formatted = self.format_amount(base_amount, base_decimals)
        
        pool_emoji = token_data['pool_emoji']
        pool_type = token_data['pool_type']
        is_internal = token_data.get('is_internal', False)
        symbol = token_data.get('symbol', base_symbol)
        price_change = token_data.get('price_change', 0)
        volume = token_data.get('volume', 0)
        market_cap = token_data.get('market_cap', 0)  # parse_token_data å·²è§£æä¸º market_capï¼ˆä¸‹åˆ’çº¿ï¼‰
        buy_tax = token_data.get('buy_tax', 0)
        sell_tax = token_data.get('sell_tax', 0)
        price = token_data.get('price', 0)
        
        # è·å–æ—¶é—´é—´éš”ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
        time_interval = self.time_interval_internal if is_internal else self.time_interval_external
        
        volume_str = format_number(volume)
        market_cap_str = format_number(market_cap)
        
        price_str = f"${price:.5f} USDT" if price >= 0.01 else f"${price:.10f} USDT"
        
        triggered_events = token_data.get('triggered_events', [])
        fallback_info = token_data.get('fallback_info')  # è·å–é€€è®©ä¿¡æ¯
        
        alert_reasons = []
        for event in triggered_events:
            if hasattr(event, 'description'):
                alert_reasons.append(event.description)
            elif isinstance(event, dict):
                if event.get('event') == 'priceChange':
                    alert_reasons.append(f"ğŸ“ˆ {time_interval}æ¶¨å¹… {price_change:+.2f}%")
                elif event.get('event') == 'volume':
                    alert_reasons.append(f"ğŸ’¹ {time_interval}äº¤æ˜“é‡ ${volume_str}")
        
        # å¦‚æœæœ‰é€€è®©ä¿¡æ¯ï¼Œæ·»åŠ åˆ°å‘Šè­¦åŸå› 
        if fallback_info:
            original = fallback_info['original']
            fallback = fallback_info['fallback']
            reason = fallback_info['reason']
            alert_reasons.append(f"âš ï¸ {reason}ï¼Œé‡‡ç”¨{fallback}æ•°æ®")
        
        if not alert_reasons:
            alert_reasons.append(f"ğŸ’° å¤§é¢äº¤æ˜“ ${usd_value:.2f}")
        
        message = f"""<b>ğŸŸ¢ BSC ä¿¡å·</b>

ğŸ’° ä»£å¸: {symbol}
ğŸ“ åç§°: {symbol}
ğŸ”— åˆçº¦: <code>{base_token}</code>
ğŸ”— äº¤æ˜“å“ˆå¸Œ: <code>{tx_hash}</code>

ğŸ“Š <b>å®æ—¶æ•°æ®</b>
ğŸ’µ å½“å‰ä»·æ ¼: {price_str}
ğŸ’ å¸‚å€¼: ${market_cap_str}
ğŸŠ çŠ¶æ€: {pool_emoji} {pool_type}

ğŸ“‰ <b>äº¤æ˜“æ•°æ®</b>
ğŸ’° æœ¬æ¬¡ä¹°å…¥: {quote_formatted} {quote_symbol} (â‰ˆ${usd_value:.2f})
ğŸ è·å¾—ä»£å¸: {base_formatted} {symbol}

âœ¨ <b>è§¦å‘åŸå› </b>
{chr(10).join('â€¢ ' + reason for reason in alert_reasons)}

â° æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        # ç»“æ„åŒ–æ—¥å¿—è¾“å‡ºï¼ˆå¤–ç›˜ï¼‰
        logger.info("å¤–ç›˜äº¤æ˜“è§¦å‘", extra={
            "pool_type": pool_type,
            "symbol": symbol,
            "token": base_token[:10],
            "tx_hash": tx_hash[:10],
            "quote_amount": f"{quote_formatted} {quote_symbol}",
            "usd_value": f"${usd_value:.2f}",
            "base_amount": f"{base_formatted} {symbol}",
            "price_change": f"{price_change:+.2f}%",
            "volume": f"${volume:,.0f}",
            "market_cap": f"${market_cap:,.0f}",
            "buy_tax": f"{buy_tax:.1f}%",
            "sell_tax": f"{sell_tax:.1f}%"
        })
        
        # ğŸš€ å‘é€æ¨é€ï¼ˆå†·å´æœŸå·²åœ¨å‰é¢è®¾ç½®ï¼Œæ— è®ºæˆè´¥éƒ½ä¸ä¼šé‡å¤å‘é€ï¼‰
        alert_start = time.time()
        send_success = await self.send_alert(message, base_token)
        alert_time = time.time() - alert_start
        if HAS_PROMETHEUS:
            self.metrics_processing_time.labels(stage='alert').observe(alert_time)
        
        if send_success:
            # âœ… æ’­æŠ¥æˆåŠŸ
            self.alert_success_count += 1
            if HAS_PROMETHEUS:
                self.metrics_alerts.labels(status='success').inc()
            
            # æ›´æ–°æ•°æ®åº“è®°å½•ï¼šæ ‡è®°ä¸ºå·²å‘é€å‘Šè­¦
            self._update_alert_status(tx_hash, base_token, alert_sent=True, alert_blocked_reason=None)
            logger.info(f"âœ…âœ…âœ… å‘Šè­¦å·²å‘é€: {base_token} | æ¶¨å¹…+{token_data.get('price_change', 0):.2f}% äº¤æ˜“é‡${token_data.get('volume', 0):,.0f}")
        else:
            # âŒ æ’­æŠ¥å¤±è´¥ â†’ åˆ é™¤å†·å´æœŸï¼ˆè§£é”ï¼Œå…è®¸ä¸‹æ¬¡é‡è¯•ï¼‰
            self.alert_fail_count += 1
            if HAS_PROMETHEUS:
                self.metrics_alerts.labels(status='failure').inc()
            await self.remove_alert_cooldown(base_token)
            logger.warning(f"âš ï¸  æ’­æŠ¥å¤±è´¥ï¼Œå·²è§£é”å†·å´æœŸ: {base_token[:10]}...")
        
        # è®°å½•åˆ°æ•°æ®åº“å¹¶æ¨é€WebSocketï¼ˆæ— è®ºé€šçŸ¥æ˜¯å¦æˆåŠŸï¼‰
        await asyncio.to_thread(
            self.alert_recorder.write_bsc_alert,
            ca=base_token,
            token_name=symbol,
            token_symbol=symbol,
            single_max=usd_value,
            total_sum=usd_value,
            alert_reasons=alert_reasons,
            block_number=0,  # WebSocketä¸å…³å¿ƒåŒºå—å·
            price_usdt=price,
            pair_address=pair_address,
            market_cap=market_cap,
            price_change=price_change,
            volume_24h=volume,
            holders=0,
            logo="",
            notify_error=None if send_success else "Telegramå‘é€å¤±è´¥"
        )
    
    async def _handle_swap_with_receipt_fallback(self, tx_hash: str, pair_address: str):
        """å¤–ç›˜receiptå…œåº•ï¼šä»äº¤æ˜“å›æ‰§ä¸­æå–Swapäº‹ä»¶"""
        try:
            # è·å–äº¤æ˜“å›æ‰§ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            receipt, _ = self.get_receipt_cached(tx_hash)
            if not receipt:
                logger.debug(f"âš ï¸ è·å–receiptå¤±è´¥: {tx_hash}")
                return
            
            logs = receipt.get("logs", [])
            swap_topic = self.TOPIC_V2_SWAP
            
            # æŸ¥æ‰¾Swapäº‹ä»¶
            for log in logs:
                topics = log.get("topics", [])
                log_addr = log.get("address", "").lower()
                
                # åŒ¹é…Swapäº‹ä»¶
                if topics and topics[0].lower() == swap_topic and log_addr == pair_address:
                    logger.info(f"âœ… Receiptå…œåº•æˆåŠŸ: {tx_hash} (å¤–ç›˜)")
                    # é€’å½’è°ƒç”¨åŸå‡½æ•°å¤„ç†
                    await self.handle_swap_event(log)
                    return
            
            logger.debug(f"âš ï¸ Receiptä¸­æœªæ‰¾åˆ°Swapäº‹ä»¶: {tx_hash}")
        except Exception as e:
            logger.debug(f"âŒ Receiptå…œåº•å¤±è´¥: {e}")
    
    async def handle_proxy_event(self, log: Dict):
        """å¤„ç† Fourmeme Proxy äº‹ä»¶ï¼ˆå†…ç›˜ï¼‰"""
        tx_hash = log.get("transactionHash")
        addr = log.get("address", "").lower()
        topics = log.get("topics", [])
        
        proxy_type = "ä¸»Proxy" if addr == self.FOURMEME_PROXY[0] else "Try Buy"
        
        try:
            dbotx_api = self.get_thread_dbotx_api()
            
            # ========== å¿«é€Ÿè·¯å¾„ï¼šCustom Eventsï¼ˆTokenPurchase/Saleï¼‰==========
            if topics and topics[0] in self.FOURMEME_CUSTOM_EVENTS:
                try:
                    # TokenPurchase/Sale äº‹ä»¶æ ¼å¼ï¼š
                    # event TokenPurchase(address indexed token, address indexed buyer, uint256 cost, uint256 amount)
                    # topics[0]: event signature
                    # topics[1]: token address (indexed)
                    # topics[2]: buyer address (indexed)  
                    # data: cost (uint256) + amount (uint256)
                    
                    if len(topics) < 3:
                        logger.debug(f"âš ï¸ Custom Event topicsä¸è¶³: {len(topics)}")
                        # ç»§ç»­èµ°å…œåº•é€»è¾‘
                    else:
                        target_token = ("0x" + topics[1][-40:]).lower()
                        buyer = ("0x" + topics[2][-40:]).lower()
                        
                        # è§£ç  data
                        # TokenPurchaseäº‹ä»¶å®Œæ•´æ ¼å¼ï¼š8ä¸ªéç´¢å¼•å‚æ•°
                        # (address indexed token, address indexed buyer, 
                        #  address payToken, uint256 payAmount, uint256 getAmount, 
                        #  uint256 curvePrice, uint256 protocolFee, uint256 subjectFee, 
                        #  uint256 referralFee, uint256 supply)
                        data = log.get("data", "0x")
                        if data and len(data) >= 66:
                            try:
                                # ä½¿ç”¨eth_abiè§£ç ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                                if HAS_ETH_ABI:
                                    try:
                                        decoded = eth_abi_decode(['address', 'uint256', 'uint256', 'uint256', 'uint256', 'uint256', 'uint256', 'uint256'], bytes.fromhex(data[2:]))
                                        pay_token = decoded[0]  # æ”¯ä»˜ä»£å¸åœ°å€
                                        cost = decoded[1]  # æ”¯ä»˜é‡‘é¢
                                        amount = decoded[2]  # è·å¾—ä»£å¸æ•°é‡
                                    except:
                                        # Fallback: æ‰‹åŠ¨è§£æå‰2ä¸ªuint256
                                        cost = int(data[2:66], 16) if len(data) >= 66 else 0
                                        amount = int(data[66:130], 16) if len(data) >= 130 else 0
                                else:
                                    # Fallback: æ‰‹åŠ¨è§£æ
                                    # è·³è¿‡ç¬¬ä¸€ä¸ªaddress(32å­—èŠ‚)ï¼Œå–ç¬¬2ã€3ä¸ªuint256
                                    cost = int(data[66:130], 16) if len(data) >= 130 else 0
                                    amount = int(data[130:194], 16) if len(data) >= 194 else 0
                                
                                if cost > 0:
                                    # ç›´æ¥å¤„ç†ï¼ˆè·³è¿‡ receiptï¼ï¼‰
                                    # å‡è®¾ cost æ˜¯ USDTï¼ˆ18 decimalsï¼‰ï¼Œå¦‚æœæ˜¯ WBNB éœ€è¦è¿›ä¸€æ­¥åˆ¤æ–­
                                    quote_token = self.USDT  # é»˜è®¤ USDTï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                                    quote_amount = cost
                                    quote_symbol = "USDT"
                                    target_amount = amount
                                    
                                    # è·å– token symbol å’Œ decimals
                                    target_symbol = self.get_token_symbol(target_token)
                                    quote_decimals = self.get_decimals(quote_token)
                                    target_decimals = self.get_decimals(target_token)
                                    
                                    # è®¡ç®— USD ä»·å€¼ï¼ˆcost å°±æ˜¯æ”¯ä»˜çš„ USDTï¼‰
                                    quote_value = Decimal(quote_amount) / (Decimal(10) ** Decimal(quote_decimals))
                                    usd_value = float(quote_value)  # USDT â‰ˆ $1
                                    
                                    # ç¬¬ä¸€å±‚è¿‡æ»¤ï¼šé‡‘é¢æ£€æŸ¥
                                    if not self.first_layer_filter(usd_value, is_internal=True):
                                        logger.debug(f"â­ï¸  [å†…ç›˜å¿«é€Ÿ] é‡‘é¢ä¸è¶³: {target_symbol} (${usd_value:.2f})")
                                        return
                                    
                                    logger.info(f"âœ… [å†…ç›˜å¿«é€Ÿ] {target_symbol} ä¹°å…¥ ${usd_value:.2f}")
                                    
                                    # å†·å´æœŸæ£€æŸ¥ï¼ˆåªè¯»ï¼‰
                                    if not await self.check_alert_cooldown_readonly(target_token):
                                        self.alert_cooldown_blocked += 1
                                        if HAS_PROMETHEUS:
                                            self.metrics_alert_cooldown_blocked.inc()
                                        logger.info(f"â³ [å†…ç›˜å¿«é€Ÿ] å†·å´æœŸå†…ï¼Œè·³è¿‡: {target_token[:10]}...")
                                        return
                                    
                                    # è·å– launchpad ä¿¡æ¯ï¼ˆè½»é‡ API è°ƒç”¨ï¼‰
                                    launchpad_info = await dbotx_api.get_token_launchpad_info('bsc', target_token)
                                    
                                    # ğŸ“Š Prometheus: è®°å½•DBotX APIè°ƒç”¨ + ç§¯åˆ†æ¶ˆè´¹ï¼ˆ10åˆ†/æ¬¡ï¼‰+ ä¿å­˜åˆ°Redis
                                    self._inc_credits_and_save(10)
                                    
                                    if not launchpad_info:
                                        # Fallbackï¼šæ„é€ åŸºç¡€ä¿¡æ¯
                                        launchpad_info = {
                                            'launchpad': 'fourmeme',
                                            'pair_address': None
                                        }
                                    
                                    pair_address = launchpad_info.get('pair_address')
                                    if not pair_address:
                                        logger.debug(f"âš ï¸ [å†…ç›˜å¿«é€Ÿ] æ— pairåœ°å€: {target_token[:10]}...")
                                        return
                                    
                                    # è®¾ç½®ä¸Šä¸‹æ–‡ï¼ˆç”¨äºæ•°æ®åº“è®°å½•ï¼‰
                                    self.thread_local.current_tx_context = {
                                        'tx_hash': tx_hash,
                                        'usd_value': usd_value
                                    }
                                    
                                    # ç¬¬äºŒå±‚è¿‡æ»¤ï¼ˆè·å–å¸‚å€¼ç­‰ï¼‰
                                    token_data = await self.second_layer_filter(target_token, pair_address, launchpad_info, is_internal=True)
                                    if not token_data:
                                        logger.debug(f"â­ï¸  [å†…ç›˜å¿«é€Ÿ] æœªé€šè¿‡ç¬¬äºŒå±‚è¿‡æ»¤: {target_token[:10]}...")
                                        return
                                    
                                    # ğŸ”’ ç¬¬äºŒæ­¥ï¼šåŸå­æ“ä½œè®¾ç½®å†·å´æœŸï¼ˆé˜²æ­¢ç«æ€æ¡ä»¶å¯¼è‡´é‡å¤å‘é€ï¼‰
                                    if not await self.check_and_set_alert_cooldown(target_token):
                                        self.alert_cooldown_blocked += 1
                                        if HAS_PROMETHEUS:
                                            self.metrics_alert_cooldown_blocked.inc()
                                        logger.info(f"â³ [å†…ç›˜å¿«é€Ÿ] å†·å´æœŸå†…ï¼ˆç«æ€ï¼‰ï¼Œè·³è¿‡: {target_token[:10]}...")
                                        # æ›´æ–°æ•°æ®åº“è®°å½•ï¼šæ ‡è®°ä¸ºå†·å´æœŸæ‹¦æˆª
                                        self._update_alert_status(tx_hash, target_token, alert_sent=False, alert_blocked_reason="å†·å´æœŸæ‹¦æˆª")
                                        return
                                    
                                    # æ„å»ºå¹¶å‘é€å‘Šè­¦
                                    await self._send_internal_alert(
                                        tx_hash=tx_hash,
                                        target_token=target_token,
                                        target_symbol=target_symbol,
                                        target_amount=target_amount,
                                        target_decimals=target_decimals,
                                        quote_symbol=quote_symbol,
                                        quote_amount=quote_amount,
                                        quote_decimals=quote_decimals,
                                        usd_value=usd_value,
                                        token_data=token_data,
                                        proxy_type=proxy_type
                                    )
                                    
                                    logger.info(f"ğŸ“¤ [å†…ç›˜å¿«é€Ÿ] å‘Šè­¦å·²å‘é€: {target_symbol} ${usd_value:.2f}")
                                    return  # âš¡ å¿«é€Ÿè¿”å›ï¼Œä¸èµ° receipt é€»è¾‘
                            except Exception as e:
                                logger.debug(f"Custom Event è§£ç å¤±è´¥: {e}")
                                # ç»§ç»­èµ°å…œåº•é€»è¾‘
                except Exception as e:
                    logger.debug(f"Custom Event å¿«é€Ÿè·¯å¾„å¤±è´¥: {e}")
                    # ç»§ç»­èµ°å…œåº•é€»è¾‘
            
            # ========== å…œåº•è·¯å¾„ï¼šä» Receipt è§£æ Transfer ==========
            # è·å–äº¤æ˜“å›æ‰§ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            receipt, tx_info = self.get_receipt_cached(tx_hash)
            if not receipt:
                return
            
            logs = receipt.get("logs", [])
            
            # è§£æ Transfer äº‹ä»¶
            transfer_topic = "0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef"
            transfers = []
            
            for log in logs:
                topics = log.get("topics", [])
                if not topics or topics[0] != transfer_topic:
                    continue
                
                token_addr = log.get("address", "").lower()
                data = log.get("data", "0x")
                
                if len(topics) >= 3:
                    from_addr = "0x" + topics[1][-40:]
                    to_addr = "0x" + topics[2][-40:]
                    
                    try:
                        value = int(data, 16) if data and data != "0x" else 0
                    except:
                        value = 0
                    
                    transfers.append({
                        "token": token_addr,
                        "from": from_addr.lower(),
                        "to": to_addr.lower(),
                        "value": value
                    })
            
            if not transfers:
                return
            
            # æ‰¾å‡ºä¹°å…¥çš„ USDT/WBNB/USDC
            usdt_in = sum(t["value"] for t in transfers 
                         if t["token"] == self.USDT and t["to"] in self.FOURMEME_PROXY)
            wbnb_in = sum(t["value"] for t in transfers 
                         if t["token"] == self.WBNB and t["to"] in self.FOURMEME_PROXY)
            usdc_in = sum(t["value"] for t in transfers 
                         if t["token"] == self.USDC and t["to"] in self.FOURMEME_PROXY)
            
            # è·å–äº¤æ˜“ä¿¡æ¯ï¼ˆBNB ä¹°å…¥ï¼Œå·²ä»ç¼“å­˜è·å–ï¼‰
            tx_value = 0
            if tx_info and tx_info.get("value"):
                try:
                    tx_value = int(tx_info["value"], 16)
                except:
                    pass
            
            # ç¡®å®šä»˜å‡ºçš„åŸºå‡†å¸
            quote_token = None
            quote_amount = 0
            quote_symbol = ""
            
            if usdt_in > 0:
                quote_token = self.USDT
                quote_amount = usdt_in
                quote_symbol = "USDT"
            elif usdc_in > 0:
                quote_token = self.USDC
                quote_amount = usdc_in
                quote_symbol = "USDC"
            elif wbnb_in > 0:
                quote_token = self.WBNB
                quote_amount = wbnb_in
                quote_symbol = "WBNB"
            elif tx_value > 0:
                quote_token = self.WBNB
                quote_amount = tx_value
                quote_symbol = "BNB"
            else:
                return
            
            # æ‰¾å‡ºç›®æ ‡ä»£å¸
            target_tokens = {}
            for t in transfers:
                if (t["from"] in self.FOURMEME_PROXY and 
                    t["token"] not in (self.USDT, self.WBNB, self.USDC)):
                    target_tokens[t["token"]] = target_tokens.get(t["token"], 0) + t["value"]
            
            if not target_tokens:
                return
            
            target_token = max(target_tokens.items(), key=lambda x: x[1])[0]
            target_amount = target_tokens[target_token]
            
            target_symbol = self.get_token_symbol(target_token)
            quote_decimals = self.get_decimals(quote_token)
            target_decimals = self.get_decimals(target_token)
            
            # è®¡ç®— USD ä»·å€¼
            quote_value = Decimal(quote_amount) / (Decimal(10) ** Decimal(quote_decimals))
            if quote_token == self.WBNB:
                wbnb_price = self.get_wbnb_price()
                usd_value = float(quote_value) * wbnb_price
            else:
                usd_value = float(quote_value)

            # ç¬¬ä¸€å±‚è¿‡æ»¤
            if not self.first_layer_filter(usd_value, is_internal=True):
                logger.debug(f"â­ï¸  å†…ç›˜é‡‘é¢ä¸è¶³: {target_symbol} (${usd_value:.2f}) - {target_token[:10]}...")
                return
            
            # ä¸œå…«åŒºæ—¶é—´
            cn_time = datetime.now(timezone(timedelta(hours=8))).strftime('%H:%M:%S')
            logger.info(f"âœ… [å†…ç›˜] é€šè¿‡ç¬¬ä¸€å±‚: {target_symbol} (${usd_value:.2f}) [{cn_time}]")
            self.first_layer_pass_internal += 1  # å†…ç›˜ç¬¬ä¸€å±‚è®¡æ•°
            
            # Prometheus: ç¬¬ä¸€å±‚é€šè¿‡è®¡æ•°
            if HAS_PROMETHEUS:
                self.metrics_first_layer_pass.labels(type='internal').inc()
            
            # è·å– launchpad ä¿¡æ¯
            launchpad_info = await dbotx_api.get_token_launchpad_info('bsc', target_token)
            
            # ğŸ“Š Prometheus: è®°å½•DBotX APIè°ƒç”¨ + ç§¯åˆ†æ¶ˆè´¹ï¼ˆ10åˆ†/æ¬¡ï¼‰+ ä¿å­˜åˆ°Redis
            self._inc_credits_and_save(10)
            
            if not launchpad_info:
                logger.warning(f"âš ï¸ API miss: hash={tx_hash}, token={target_token} - ä½¿ç”¨ fallback")
                # Fallbackï¼šæ„é€ åŸºç¡€ launchpad_info
                launchpad_info = {
                    'launchpad': 'fourmeme',
                    'pair_address': None  # ç¨åå°è¯•ä» receipt æå–
                }
            
            pair_address = launchpad_info.get('pair_address')
            if not pair_address:
                # å°è¯•ä» receipt çš„ logs ä¸­æå– PancakeV2 Pair åœ°å€
                pair_address = self._extract_pair_from_receipt(logs)
                if pair_address:
                    logger.info(f"âœ… ä» receipt æå–åˆ° pair: {pair_address}")
                    launchpad_info['pair_address'] = pair_address
                else:
                    logger.debug("å†…ç›˜æ— äº¤æ˜“å¯¹åœ°å€", extra={
                        "token": target_token[:10],
                        "symbol": target_symbol
                    })
                    return
            
            # è®¾ç½®ä¸Šä¸‹æ–‡ï¼ˆç”¨äºæ•°æ®åº“è®°å½•ï¼‰
            self.thread_local.current_tx_context = {
                'tx_hash': tx_hash,
                'usd_value': usd_value
            }
            
            # ç¬¬äºŒå±‚è¿‡æ»¤
            token_data = await self.second_layer_filter(target_token, pair_address, launchpad_info, is_internal=True)
            if not token_data:
                return
            
            # æ›´æ–°symbolç¼“å­˜ï¼ˆå¦‚æœç¬¬ä¸€å±‚è·å–å¤±è´¥ï¼Œè¿™é‡Œç”¨DBotXçš„æ­£ç¡®symbolæ›´æ–°ï¼‰
            if target_symbol == "???" and token_data.get('symbol'):
                correct_symbol = token_data.get('symbol')
                try:
                    redis_key = f"token:{target_token}:symbol"
                    self.redis_client.client.setex(redis_key, 86400, correct_symbol)
                    logger.debug(f"âœ… æ›´æ–°symbolç¼“å­˜: {target_token} â†’ {correct_symbol}")
                except:
                    pass
            
            # ğŸ”’ ç¬¬ä¸€æ­¥ï¼šåªè¯»æ£€æŸ¥å†·å´æœŸï¼ˆå¿«é€Ÿè¿‡æ»¤ï¼‰
            if not await self.check_alert_cooldown_readonly(target_token):
                self.alert_cooldown_blocked += 1
                if HAS_PROMETHEUS:
                    self.metrics_alert_cooldown_blocked.inc()
                logger.info(f"â³ å†·å´æœŸå†…ï¼Œè·³è¿‡: {target_token}")
                # æ›´æ–°æ•°æ®åº“è®°å½•ï¼šæ ‡è®°ä¸ºå†·å´æœŸæ‹¦æˆª
                self._update_alert_status(tx_hash, target_token, alert_sent=False, alert_blocked_reason="å†·å´æœŸæ‹¦æˆª")
                return
            
            # ğŸ”’ ç¬¬äºŒæ­¥ï¼šåŸå­æ“ä½œè®¾ç½®å†·å´æœŸï¼ˆé˜²æ­¢ç«æ€æ¡ä»¶å¯¼è‡´é‡å¤å‘é€ï¼‰
            if not await self.check_and_set_alert_cooldown(target_token):
                self.alert_cooldown_blocked += 1
                if HAS_PROMETHEUS:
                    self.metrics_alert_cooldown_blocked.inc()
                logger.info(f"â³ å†·å´æœŸå†…ï¼ˆç«æ€ï¼‰ï¼Œè·³è¿‡: {target_token}")
                # æ›´æ–°æ•°æ®åº“è®°å½•ï¼šæ ‡è®°ä¸ºå†·å´æœŸæ‹¦æˆª
                self._update_alert_status(tx_hash, target_token, alert_sent=False, alert_blocked_reason="å†·å´æœŸæ‹¦æˆª")
                return
            
            # æ„å»ºæ¶ˆæ¯
            quote_formatted = self.format_amount(quote_amount, quote_decimals)
            target_formatted = self.format_amount(target_amount, target_decimals)
            
            pool_emoji = token_data['pool_emoji']
            pool_type = token_data['pool_type']
            is_internal = token_data.get('is_internal', True)  # Proxyäº‹ä»¶é»˜è®¤æ˜¯å†…ç›˜
            symbol = token_data.get('symbol', target_symbol)
            price_change = token_data.get('price_change', 0)
            volume = token_data.get('volume', 0)
            market_cap = token_data.get('market_cap', 0)  # parse_token_data å·²è§£æä¸º market_capï¼ˆä¸‹åˆ’çº¿ï¼‰
            buy_tax = token_data.get('buy_tax', 0)
            sell_tax = token_data.get('sell_tax', 0)
            price = token_data.get('price', 0)
            
            # è·å–æ—¶é—´é—´éš”ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
            time_interval = self.time_interval_internal if is_internal else self.time_interval_external
            
            volume_str = format_number(volume)
            market_cap_str = format_number(market_cap)
            
            price_str = f"${price:.5f} USDT" if price >= 0.01 else f"${price:.10f} USDT"
            
            triggered_events = token_data.get('triggered_events', [])
            fallback_info = token_data.get('fallback_info')  # è·å–é€€è®©ä¿¡æ¯
            
            alert_reasons = []
            for event in triggered_events:
                if hasattr(event, 'description'):
                    alert_reasons.append(event.description)
                elif isinstance(event, dict):
                    if event.get('event') == 'priceChange':
                        alert_reasons.append(f"ğŸ“ˆ {time_interval}æ¶¨å¹… {price_change:+.2f}%")
                    elif event.get('event') == 'volume':
                        alert_reasons.append(f"ğŸ’¹ {time_interval}äº¤æ˜“é‡ ${volume_str}")
            
            # å¦‚æœæœ‰é€€è®©ä¿¡æ¯ï¼Œæ·»åŠ åˆ°å‘Šè­¦åŸå› 
            if fallback_info:
                original = fallback_info['original']
                fallback = fallback_info['fallback']
                reason = fallback_info['reason']
                alert_reasons.append(f"âš ï¸ {reason}ï¼Œé‡‡ç”¨{fallback}æ•°æ®")
            
            if not alert_reasons:
                alert_reasons.append(f"ğŸ’° å¤§é¢äº¤æ˜“ ${usd_value:.2f}")
            
            message = f"""<b>{pool_emoji} BSC ä¿¡å·</b>

ğŸ’° ä»£å¸: {symbol}
ğŸ“ åç§°: {symbol}
ğŸ”— åˆçº¦: <code>{target_token}</code>
ğŸ”— äº¤æ˜“å“ˆå¸Œ: <code>{tx_hash}</code>

ğŸ“Š <b>å®æ—¶æ•°æ®</b>
ğŸ’µ å½“å‰ä»·æ ¼: {price_str}
ğŸ’ å¸‚å€¼: ${market_cap_str}
ğŸŠ çŠ¶æ€: {pool_emoji} {pool_type}

ğŸ“‰ <b>äº¤æ˜“æ•°æ®</b>
ğŸ’° æœ¬æ¬¡ä¹°å…¥: {quote_formatted} {quote_symbol} (â‰ˆ${usd_value:.2f})
ğŸ è·å¾—ä»£å¸: {target_formatted} {symbol}

âœ¨ <b>è§¦å‘åŸå› </b>
{chr(10).join('â€¢ ' + reason for reason in alert_reasons)}

â° æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            # ç»“æ„åŒ–æ—¥å¿—è¾“å‡ºï¼ˆå†…ç›˜ï¼‰
            logger.info("å†…ç›˜äº¤æ˜“è§¦å‘", extra={
                "pool_type": pool_type,
                "proxy_type": proxy_type,
                "symbol": symbol,
                "token": target_token[:10],
                "tx_hash": tx_hash[:10],
                "quote_amount": f"{quote_formatted} {quote_symbol}",
                "usd_value": f"${usd_value:.2f}",
                "target_amount": f"{target_formatted} {symbol}",
                "price_change": f"{price_change:+.2f}%",
                "volume": f"${volume:,.0f}",
                "market_cap": f"${market_cap:,.0f}",
                "buy_tax": f"{buy_tax:.1f}%",
                "sell_tax": f"{sell_tax:.1f}%"
            })
            
            # ğŸš€ å‘é€æ¨é€ï¼ˆå†·å´æœŸå·²åœ¨å‰é¢è®¾ç½®ï¼Œæ— è®ºæˆè´¥éƒ½ä¸ä¼šé‡å¤å‘é€ï¼‰
            alert_start = time.time()
            send_success = await self.send_alert(message, target_token)
            alert_time = time.time() - alert_start
            if HAS_PROMETHEUS:
                self.metrics_processing_time.labels(stage='alert').observe(alert_time)
            
            if send_success:
                # âœ… æ’­æŠ¥æˆåŠŸ
                self.alert_success_count += 1
                if HAS_PROMETHEUS:
                    self.metrics_alerts.labels(status='success').inc()
                # æ›´æ–°æ•°æ®åº“è®°å½•ï¼šæ ‡è®°ä¸ºå·²å‘é€å‘Šè­¦
                self._update_alert_status(tx_hash, target_token, alert_sent=True, alert_blocked_reason=None)
                logger.info(f"âœ…âœ…âœ… å‘Šè­¦å·²å‘é€: {target_token} | æ¶¨å¹…+{token_data.get('price_change', 0):.2f}% äº¤æ˜“é‡${token_data.get('volume', 0):,.0f}")
            else:
                # âŒ æ’­æŠ¥å¤±è´¥ â†’ åˆ é™¤å†·å´æœŸï¼ˆè§£é”ï¼Œå…è®¸ä¸‹æ¬¡é‡è¯•ï¼‰
                self.alert_fail_count += 1
                if HAS_PROMETHEUS:
                    self.metrics_alerts.labels(status='failure').inc()
                await self.remove_alert_cooldown(target_token)
                logger.warning(f"âš ï¸  æ’­æŠ¥å¤±è´¥ï¼Œå·²è§£é”å†·å´æœŸ: {target_token[:10]}...")
            
            # è®°å½•åˆ°æ•°æ®åº“å¹¶æ¨é€WebSocketï¼ˆæ— è®ºé€šçŸ¥æ˜¯å¦æˆåŠŸï¼‰
            await asyncio.to_thread(
                self.alert_recorder.write_bsc_alert,
                ca=target_token,
                token_name=symbol,
                token_symbol=symbol,
                single_max=usd_value,
                total_sum=usd_value,
                alert_reasons=alert_reasons,
                block_number=0,  # WebSocketä¸å…³å¿ƒåŒºå—å·
                price_usdt=price,
                pair_address=pair_address,
                market_cap=market_cap,
                price_change=price_change,
                volume_24h=volume,
                holders=0,
                logo="",
                notify_error=None if send_success else "Telegramå‘é€å¤±è´¥"
            )
        
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å†…ç›˜äº¤æ˜“å‡ºé”™: {e}")
    
    async def _send_internal_alert(
        self,
        tx_hash: str,
        target_token: str,
        target_symbol: str,
        target_amount: int,
        target_decimals: int,
        quote_symbol: str,
        quote_amount: int,
        quote_decimals: int,
        usd_value: float,
        token_data: dict,
        proxy_type: str
    ):
        """å‘é€å†…ç›˜å‘Šè­¦ï¼ˆä¾›å¿«é€Ÿè·¯å¾„å’Œå…œåº•è·¯å¾„å…±ç”¨ï¼‰"""
        try:
            # æ ¼å¼åŒ–é‡‘é¢
            quote_formatted = self.format_amount(quote_amount, quote_decimals)
            target_formatted = self.format_amount(target_amount, target_decimals)
            
            # æå– token_data
            pool_emoji = token_data['pool_emoji']
            pool_type = token_data['pool_type']
            is_internal = token_data.get('is_internal', True)
            symbol = token_data.get('symbol', target_symbol)
            price_change = token_data.get('price_change', 0)
            volume = token_data.get('volume', 0)
            market_cap = token_data.get('market_cap', 0)
            price = token_data.get('price', 0)
            
            # æ ¼å¼åŒ–æ•°å­—ï¼ˆä½¿ç”¨å·²å¯¼å…¥çš„format_numberï¼‰
            volume_str = format_number(volume)
            market_cap_str = format_number(market_cap)
            price_str = f"${price:.5f} USDT" if price >= 0.01 else f"${price:.10f} USDT"
            
            # è·å–æ—¶é—´é—´éš”
            time_interval = self.time_interval_internal if is_internal else self.time_interval_external
            
            # æ„å»ºå‘Šè­¦åŸå› 
            triggered_events = token_data.get('triggered_events', [])
            alert_reasons = []
            for event in triggered_events:
                if hasattr(event, 'description'):
                    alert_reasons.append(event.description)
                elif isinstance(event, dict):
                    if event.get('event') == 'priceChange':
                        alert_reasons.append(f"ğŸ“ˆ {time_interval}æ¶¨å¹… {price_change:+.2f}%")
                    elif event.get('event') == 'volume':
                        alert_reasons.append(f"ğŸ’¹ {time_interval}äº¤æ˜“é‡ ${volume_str}")
            
            if not alert_reasons:
                alert_reasons.append(f"ğŸ’° å¤§é¢äº¤æ˜“ ${usd_value:.2f}")
            
            # æ„å»ºæ¶ˆæ¯
            message = f"""<b>{pool_emoji} BSC ä¿¡å·</b>

ğŸ’° ä»£å¸: {symbol}
ğŸ“ åç§°: {symbol}
ğŸ”— åˆçº¦: <code>{target_token}</code>

ğŸ“Š <b>å®æ—¶æ•°æ®</b>
ğŸ’µ å½“å‰ä»·æ ¼: {price_str}
ğŸ’ å¸‚å€¼: ${market_cap_str}
ğŸŠ çŠ¶æ€: {pool_emoji} {pool_type}

ğŸ“‰ <b>äº¤æ˜“æ•°æ®</b>
ğŸ’° æœ¬æ¬¡ä¹°å…¥: {quote_formatted} {quote_symbol} (â‰ˆ${usd_value:.2f})
ğŸ“Š {time_interval}äº¤æ˜“é‡: ${volume_str}
ğŸ“ˆ {time_interval}æ¶¨è·Œå¹…: {price_change:+.2f}%

ğŸ”” <b>è§¦å‘åŸå› </b>
{chr(10).join(alert_reasons)}
"""
            
            # ä½¿ç”¨ç°æœ‰æ–¹æ³•å‘é€ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºGMGN+AxiomæŒ‰é’®ï¼‰
            send_success = await self.send_alert(message, target_token)
            
            if send_success:
                logger.info(f"âœ…âœ…âœ… [å†…ç›˜] å‘Šè­¦å·²å‘é€: {symbol} | æ¶¨å¹…+{price_change:.2f}% äº¤æ˜“é‡${volume:,.0f}")
                # æ›´æ–°æ•°æ®åº“è®°å½•ï¼šæ ‡è®°ä¸ºå·²å‘é€å‘Šè­¦
                self._update_alert_status(tx_hash, target_token, alert_sent=True, alert_blocked_reason=None)
            else:
                # âŒ æ’­æŠ¥å¤±è´¥ â†’ åˆ é™¤å†·å´æœŸï¼ˆè§£é”ï¼Œå…è®¸ä¸‹æ¬¡é‡è¯•ï¼‰
                await self.remove_alert_cooldown(target_token)
                logger.warning(f"âš ï¸  [å†…ç›˜] æ’­æŠ¥å¤±è´¥ï¼Œå·²è§£é”å†·å´æœŸ: {target_token[:10]}...")
            
            # è®°å½•åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨ç°æœ‰recorderï¼‰
            if hasattr(self, 'alert_recorder') and self.alert_recorder:
                try:
                    await self.alert_recorder.write_bsc_alert(
                        token=target_token,
                        symbol=symbol,
                        tx_hash=tx_hash,
                        pool_type=pool_type,
                        price_change=price_change,
                        volume=volume,
                        market_cap=market_cap,
                        amount=usd_value,
                        alert_reason=", ".join(alert_reasons),
                        notify_error=None if send_success else "Telegramå‘é€å¤±è´¥"
                    )
                except Exception as e:
                    logger.debug(f"è®°å½•å‘Šè­¦åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            
        except Exception as e:
            logger.error(f"âŒ å‘é€å†…ç›˜å‘Šè­¦å¤±è´¥: {e}")
    
    
    def health_check_loop(self):
        """å¥åº·æ£€æŸ¥å¾ªç¯ï¼ˆæ¯åˆ†é’Ÿè¾“å‡ºä¸€æ¬¡çŠ¶æ€ï¼‰"""
        while not self.should_stop:
            try:
                time.sleep(60)  # æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡
                
                if self.should_stop:
                    break
                
                now = time.time()
                idle_seconds = int(now - self.last_message_time)
                
                # å»é‡ç¼“å­˜å®šæœŸæ¸…ç†ï¼ˆè¶…è¿‡ 80% å®¹é‡æ—¶æ¸…ç†æœ€è€çš„ 20%ï¼‰
                seen_txs_size = len(self.seen_txs)
                if seen_txs_size > self.max_seen_txs * 0.8:
                    cleanup_count = int(self.max_seen_txs * 0.2)
                    for _ in range(cleanup_count):
                        if self.seen_txs:
                            self.seen_txs.popitem(last=False)  # å¼¹å‡ºæœ€è€çš„
                    logger.info(f"ğŸ§¹ å»é‡ç¼“å­˜æ¸…ç†: ç§»é™¤ {cleanup_count} æ¡æ—§è®°å½• ({seen_txs_size} â†’ {len(self.seen_txs)})")
                
                # è®¡ç®—è¿è¡Œæ—¶é•¿
                running_seconds = int(time.time() - self.start_time)
                running_hours = running_seconds // 3600
                running_minutes = (running_seconds % 3600) // 60
                running_secs = running_seconds % 60
                uptime_str = f"{running_hours}æ—¶{running_minutes}åˆ†{running_secs}ç§’" if running_hours > 0 else f"{running_minutes}åˆ†{running_secs}ç§’"
                
                logger.info("=" * 80)
                logger.info("ğŸ’“ WebSocket å¥åº·æ£€æŸ¥")
                logger.info(f"   çŠ¶æ€: {'ğŸŸ¢ è¿è¡Œä¸­' if self.ws and not self.should_stop else 'ğŸ”´ å·²åœæ­¢'}")
                logger.info(f"   è¿è¡Œæ—¶é•¿: {uptime_str}")
                logger.info(f"   é‡è¿æ¬¡æ•°: {self.reconnect_count}")
                logger.info(f"   å›è¡¥æ¬¡æ•°: {self.backfill_count} (å†·å´æœŸ: {self.backfill_cooldown}s)")
                logger.info(f"   æ¶ˆæ¯æ€»æ•°: {self.message_count}")
                logger.info(f"   å»é‡ç¼“å­˜: {len(self.seen_txs)} / {self.max_seen_txs} ({len(self.seen_txs) / self.max_seen_txs * 100:.1f}%)")
                
                # å›æ‰§ç¼“å­˜è¯¦ç»†ç»Ÿè®¡
                total_cache_requests = self.receipt_cache_hits + self.receipt_cache_misses
                hit_rate = (self.receipt_cache_hits / total_cache_requests * 100) if total_cache_requests > 0 else 0
                avg_wait_time = (self.receipt_cache_wait_time_total / self.receipt_cache_concurrent_waits) if self.receipt_cache_concurrent_waits > 0 else 0
                
                logger.info(f"   å›æ‰§ç¼“å­˜: {len(self.receipt_cache)} æ¡")
                logger.info(f"      â”œâ”€ å‘½ä¸­: {self.receipt_cache_hits} æ¬¡ ({hit_rate:.1f}% å‘½ä¸­ç‡)")
                logger.info(f"      â”œâ”€ æœªå‘½ä¸­: {self.receipt_cache_misses} æ¬¡")
                logger.info(f"      â”œâ”€ å¹¶å‘ç­‰å¾…: {self.receipt_cache_concurrent_waits} æ¬¡ï¼ˆèŠ‚çœRPCï¼‰")
                
                # ç­‰å¾…è€—æ—¶ç»Ÿè®¡
                if self.receipt_cache_concurrent_waits > 0:
                    logger.info(f"      â”‚  â”œâ”€ å¹³å‡è€—æ—¶: {avg_wait_time:.2f}s/æ¬¡")
                    logger.info(f"      â”‚  â”œâ”€ ç´¯è®¡è€—æ—¶: {self.receipt_cache_wait_time_total:.1f}s")
                    if self.receipt_cache_wait_timeouts > 0:
                        timeout_rate = (self.receipt_cache_wait_timeouts / self.receipt_cache_concurrent_waits * 100)
                        logger.info(f"      â”‚  â””â”€ âš ï¸ è¶…æ—¶: {self.receipt_cache_wait_timeouts} æ¬¡ ({timeout_rate:.1f}%)")
                    else:
                        logger.info(f"      â”‚  â””â”€ âœ… æ— è¶…æ—¶")
                
                logger.info(f"      â””â”€ å¤±è´¥ç¼“å­˜å‘½ä¸­: {self.receipt_cache_failed_hits} æ¬¡ï¼ˆé¿å…é‡è¯•ï¼‰")
                
                logger.info(f"   eth_callç¼“å­˜: {len(self.eth_call_cache)} æ¡ (å‘½ä¸­ {self.eth_call_cache_hits} æ¬¡, èŠ‚çœRPC)")
                logger.info(f"   éfourmemeç¼“å­˜: {self.cache_hit_count} æ¬¡ï¼ˆèŠ‚çœAPIè°ƒç”¨ï¼‰")
                logger.info(f"   fourmemeç¼“å­˜: {self.fourmeme_cache_hit_count} æ¬¡ï¼ˆèŠ‚çœAPIè°ƒç”¨ï¼‰")
                
                # RPCé™æµç»Ÿè®¡
                if self.rate_limit_429_count > 0:
                    logger.info(f"   ğŸš« RPCé™æµç»Ÿè®¡:")
                    logger.info(f"      â”œâ”€ ç´¯è®¡429æ¬¡æ•°: {self.rate_limit_429_count}")
                    logger.info(f"      â””â”€ å½“å‰è¿ç»­429: {self.rate_limit_consecutive_429}")
                else:
                    logger.info(f"   âœ… RPCé™æµ: æ— é™æµï¼ˆç´¯è®¡0æ¬¡ï¼‰")
                
                # ç¬¬ä¸€å±‚/ç¬¬äºŒå±‚ç»Ÿè®¡
                total_first_layer = self.first_layer_pass_internal + self.first_layer_pass_external
                total_second_check = self.second_layer_check_internal + self.second_layer_check_external
                total_second_pass = self.second_layer_pass_internal + self.second_layer_pass_external
                
                logger.info(f"   ç¬¬ä¸€å±‚è¿‡æ»¤: é€šè¿‡ {total_first_layer} ä¸ª")
                if total_first_layer > 0:
                    internal_pct = (self.first_layer_pass_internal / total_first_layer * 100)
                    external_pct = (self.first_layer_pass_external / total_first_layer * 100)
                    logger.info(f"      â”œâ”€ ğŸ”´ å†…ç›˜: {self.first_layer_pass_internal} ({internal_pct:.1f}%)")
                    logger.info(f"      â””â”€ ğŸŸ¢ å¤–ç›˜: {self.first_layer_pass_external} ({external_pct:.1f}%)")
                
                logger.info(f"   ç¬¬äºŒå±‚æ£€æŸ¥: {total_second_check} ä¸ª")
                if total_second_check > 0:
                    internal_check_pct = (self.second_layer_check_internal / total_second_check * 100) if total_second_check > 0 else 0
                    external_check_pct = (self.second_layer_check_external / total_second_check * 100) if total_second_check > 0 else 0
                    logger.info(f"      â”œâ”€ ğŸ”´ å†…ç›˜: {self.second_layer_check_internal} ({internal_check_pct:.1f}%)")
                    logger.info(f"      â””â”€ ğŸŸ¢ å¤–ç›˜: {self.second_layer_check_external} ({external_check_pct:.1f}%)")
                    
                    pass_rate = (total_second_pass / total_second_check * 100)
                    fail_count = total_second_check - total_second_pass
                    fail_rate = 100 - pass_rate
                    logger.info(f"      â”œâ”€ âœ… é€šè¿‡: {total_second_pass} ({pass_rate:.1f}%)")
                    logger.info(f"      â”‚  â”œâ”€ ğŸ”´ å†…ç›˜: {self.second_layer_pass_internal}")
                    logger.info(f"      â”‚  â””â”€ ğŸŸ¢ å¤–ç›˜: {self.second_layer_pass_external}")
                    logger.info(f"      â””â”€ âŒ æœªé€šè¿‡: {fail_count} ({fail_rate:.1f}%)")
                
                # å‘Šè­¦å‘é€ç»Ÿè®¡
                total_alerts = self.alert_success_count + self.alert_fail_count
                logger.info(f"   å‘Šè­¦ç»Ÿè®¡:")
                logger.info(f"      â”œâ”€ âœ… å‘é€æˆåŠŸ: {self.alert_success_count}")
                logger.info(f"      â”œâ”€ âŒ å‘é€å¤±è´¥: {self.alert_fail_count}")
                logger.info(f"      â””â”€ â³ å†·å´æœŸæ‹¦æˆª: {self.alert_cooldown_blocked}")
                if total_alerts > 0:
                    total_candidates = total_alerts + self.alert_cooldown_blocked
                    success_rate = (self.alert_success_count / total_alerts * 100)
                    logger.info(f"      æ€»è®¡: {total_candidates} ä¸ªå€™é€‰ â†’ å®é™…å‘é€ {total_alerts} ä¸ª (æˆåŠŸç‡ {success_rate:.1f}%)")
                
                logger.info(f"   ä¸Šæ¬¡æ¶ˆæ¯: {idle_seconds}ç§’å‰")
                logger.info(f"   ç©ºé—²è­¦å‘Š: {'âš ï¸ è¶…è¿‡5åˆ†é’Ÿæ— æ¶ˆæ¯ï¼' if idle_seconds > 300 else 'âœ… æ­£å¸¸'}")
                logger.info("=" * 80)
                
                # æ›´æ–°ç¼“å­˜å¤§å° Metrics
                if HAS_PROMETHEUS:
                    self.metrics_cache_size.labels(cache_type='seen_txs').set(len(self.seen_txs))
                    self.metrics_cache_size.labels(cache_type='receipt').set(len(self.receipt_cache))
                    self.metrics_cache_size.labels(cache_type='eth_call').set(len(self.eth_call_cache))
                
                # å¦‚æœè¶…è¿‡10åˆ†é’Ÿæ²¡æœ‰æ¶ˆæ¯ï¼Œä¸»åŠ¨é‡è¿
                if idle_seconds > 600 and self.ws:
                    logger.warning("âš ï¸ æ£€æµ‹åˆ°10åˆ†é’Ÿæ— æ¶ˆæ¯ï¼Œä¸»åŠ¨è§¦å‘é‡è¿...")
                    try:
                        self.ws.close()
                    except:
                        pass
                    
            except Exception as e:
                logger.error(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
    
    def on_message(self, ws, message):
        """WebSocket æ¶ˆæ¯å›è°ƒ"""
        try:
            # æ›´æ–°æœ€åæ¶ˆæ¯æ—¶é—´å’Œè®¡æ•°
            self.last_message_time = time.time()
            self.message_count += 1
            
            # Prometheus: æ¶ˆæ¯è®¡æ•°ï¼ˆBSC WebSocketä½¿ç”¨Chainstackï¼Œæ— é™åˆ¶ï¼Œä¸æ¶ˆè€—ç§¯åˆ†ï¼‰
            if HAS_PROMETHEUS:
                self.metrics_messages.inc()
            
            msg = json.loads(message)
            
            # è·³è¿‡è®¢é˜…ç¡®è®¤ï¼ˆåŒ…å«idä½†ä¸åŒ…å«methodçš„æ¶ˆæ¯ï¼‰
            if "id" in msg and "method" not in msg:
                # è¿™æ˜¯è®¢é˜…ç¡®è®¤æ¶ˆæ¯ï¼Œè®°å½•subscription ID
                sub_id = msg.get("result")
                if sub_id:
                    logger.debug(f"âœ“ è®¢é˜…æˆåŠŸï¼Œsubscription ID: {sub_id}")
                return
            
            # è·å–å®æ—¶äº‹ä»¶ï¼ˆmethod=eth_subscriptionï¼‰
            if msg.get("method") != "eth_subscription":
                logger.warning(f"âš ï¸ æ”¶åˆ°æœªçŸ¥æ¶ˆæ¯ç±»å‹: {msg.get('method', 'unknown')}")
                return
            
            params = msg.get("params", {})
            result = params.get("result", {})
            
            if not isinstance(result, dict):
                return
            
            # å»é‡ï¼ˆä½¿ç”¨ tx_hash:logIndex ç»„åˆé”®ï¼Œæ”¯æŒåŒä¸€äº¤æ˜“çš„å¤šä¸ªæ—¥å¿—ï¼‰
            tx_hash = result.get("transactionHash")
            if not tx_hash:
                # transactionHash å¯èƒ½ä¸º Noneï¼ˆè®¢é˜…ç¡®è®¤ã€éƒ¨åˆ†èŠ‚ç‚¹ bugï¼‰
                return
            
            # logIndex æ˜¯åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼Œè½¬ä¸ºæ•´æ•°é¿å…æ ¼å¼å·®å¼‚ï¼ˆ0x1 vs 0x01ï¼‰
            log_index_hex = result.get("logIndex", "0x0")
            try:
                log_index = int(log_index_hex, 16) if isinstance(log_index_hex, str) else int(log_index_hex or 0)
            except (ValueError, TypeError):
                log_index = 0
            
            # ç»„åˆé”®ï¼štx_hash:logIndex
            key = f"{tx_hash}:{log_index}"
            if key in self.seen_txs:
                logger.debug(f"â­ï¸  å»é‡è·³è¿‡: {tx_hash[:10]}...#{log_index}")
                return
            
            self.seen_txs[key] = True
            logger.debug(f"âœ… å¤„ç†æ—¥å¿—: {tx_hash[:10]}...#{log_index} (ç¼“å­˜å¤§å°: {len(self.seen_txs)})")
            
            # LRUæ·˜æ±°æœ€è€çš„æ—¥å¿—ï¼ˆFIFOï¼‰
            if len(self.seen_txs) > self.max_seen_txs:
                self.seen_txs.popitem(last=False)  # å¼¹å‡ºæœ€æ—©çš„
            
            # æ›´æ–°æœ€åå¤„ç†çš„åŒºå—å·ï¼ˆç”¨äºæ–­çº¿å›è¡¥ï¼‰
            block_number = result.get("blockNumber")
            if block_number:
                try:
                    block_num = int(block_number, 16) if isinstance(block_number, str) else block_number
                    if block_num > self.last_processed_block:
                        self.last_processed_block = block_num
                except:
                    pass
            
            # åˆ¤æ–­äº‹ä»¶ç±»å‹
            topics = result.get("topics", [])
            addr = result.get("address", "").lower()
            
            # é˜²å¾¡æ€§æ£€æŸ¥ï¼štopicså¿…é¡»å­˜åœ¨ä¸”ä¸ä¸ºç©º
            if not topics or len(topics) == 0:
                return
            
            # ç»Ÿä¸€å°å†™ï¼ˆBSCèŠ‚ç‚¹è¿”å›æ˜¯0xå¤§å†™ï¼‰
            topic0 = topics[0].lower() if topics[0] else ""
            if not topic0:
                return
            
            # ========== ç›´æ¥å¤„ç†æ¨¡å¼ï¼ˆç¦ç”¨é˜Ÿåˆ—ï¼Œçº¿ç¨‹æ± ç›´æ¥å¤„ç†ï¼‰==========
            
            # 1ï¸âƒ£ Fourmeme Proxy çš„æ‰€æœ‰äº‹ä»¶ï¼ˆå†…ç›˜äº¤æ˜“ï¼‰
            if addr == self.FOURMEME_PROXY[0].lower():
                # ç›´æ¥ç”¨çº¿ç¨‹æ± å¤„ç†ï¼ˆæ— ç¼“å†²ï¼Œä½å»¶è¿Ÿï¼‰
                self.executor.submit(self._run_async_in_thread, self.handle_proxy_event, result)
                return
            
            # 2ï¸âƒ£ Swap äº‹ä»¶ï¼ˆå¤–ç›˜ï¼šPancakeSwap V2ï¼‰
            elif topic0 == self.TOPIC_V2_SWAP:
                # ç›´æ¥ç”¨çº¿ç¨‹æ± å¤„ç†ï¼ˆæ— ç¼“å†²ï¼Œä½å»¶è¿Ÿï¼‰
                self.executor.submit(self._run_async_in_thread, self.handle_swap_event, result)
                return
            
            # å…¶ä»–äº‹ä»¶ï¼šå¿½ç•¥
            else:
                return
        
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ¶ˆæ¯å‡ºé”™: {e}")
    
    def _run_async_in_thread(self, async_func, *args, **kwargs):
        """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°ï¼ˆä½¿ç”¨ asyncio.run ç®€åŒ–äº‹ä»¶å¾ªç¯ç®¡ç†ï¼‰"""
        asyncio.run(async_func(*args, **kwargs))
    
    def on_open(self, ws):
        """WebSocket è¿æ¥æˆåŠŸå›è°ƒ"""
        is_reconnect = self.reconnect_count > 0
        
        if not is_reconnect:
            logger.info("âœ… WebSocket è¿æ¥æˆåŠŸï¼")
            logger.info(f"èŠ‚ç‚¹: {self.ws_url[:50]}")
        else:
            logger.info(f"âœ… WebSocket é‡è¿æˆåŠŸï¼(ç¬¬{self.reconnect_count}æ¬¡)")
            # é‡è¿åç«‹å³å›è¡¥é—æ¼çš„äº¤æ˜“
            self.executor.submit(self._backfill_missed_logs, f"é‡è¿#{self.reconnect_count}")
        
        self.reconnect_count += 1
        
        # æ›´æ–°è¿æ¥çŠ¶æ€ Metric
        if HAS_PROMETHEUS:
            self.metrics_connections.set(1)  # 1 = å·²è¿æ¥
        
        # ========== ä¼˜åŒ–åçš„è®¢é˜…ç­–ç•¥ ==========
        
        # 1ï¸âƒ£ è®¢é˜… Fourmeme Proxy çš„æ‰€æœ‰äº‹ä»¶ï¼ˆæ•è·å†…ç›˜äº¤æ˜“ï¼‰
        # æ³¨æ„ï¼šTransferäº‹ä»¶æ˜¯Tokenåˆçº¦å‘å‡ºçš„ï¼Œä¸æ˜¯Proxyå‘å‡ºçš„
        # æ‰€ä»¥éœ€è¦è®¢é˜…Proxyçš„æ‰€æœ‰äº‹ä»¶ï¼Œç„¶ååœ¨handle_proxy_eventä¸­è¿‡æ»¤
        ws.send(json.dumps({
            "jsonrpc": "2.0",
            "id": 1,
            "method": "eth_subscribe",
            "params": ["logs", {
                "address": [self.FOURMEME_PROXY[0]]  # åªè®¢é˜…ä¸»Proxyï¼ˆTryBuyå·²åºŸå¼ƒï¼‰
                # ä¸é™åˆ¶topics - æ•è·æ‰€æœ‰äº‹ä»¶ï¼ˆTokenPurchase/TokenSaleç­‰ï¼‰
            }]
            }))
        logger.info(f"âœ“ è®¢é˜… Fourmeme Proxy æ‰€æœ‰äº‹ä»¶ï¼ˆå†…ç›˜ï¼‰")
        # 2ï¸âƒ£ è®¢é˜… PancakeSwap V2 Swap äº‹ä»¶ï¼ˆå¤–ç›˜äº¤æ˜“ï¼‰
        ws.send(json.dumps({
            "jsonrpc": "2.0",
            "id": 2,
            "method": "eth_subscribe",
            "params": ["logs", {"topics": [self.TOPIC_V2_SWAP]}]
        }))
        logger.info(f"âœ“ è®¢é˜… PancakeV2 Swap äº‹ä»¶ï¼ˆå¤–ç›˜ï¼‰")
        
        logger.info("âœ… è®¢é˜…å®Œæˆ")
        logger.info(f"   å†…ç›˜: Proxyæ‰€æœ‰äº‹ä»¶ (TokenPurchase/Saleç­‰) â†’ {self.FOURMEME_PROXY[0][:10]}...")
        logger.info(f"   å¤–ç›˜: å…¨é“¾Swapäº‹ä»¶ â†’ PancakeSwap V2")
        logger.info(f"ğŸ“± Telegram é¢‘é“: {self.bsc_channel_id}")
        logger.info(f"â³ ç­‰å¾…é“¾ä¸Šäº¤æ˜“...")
    
    def on_error(self, ws, error):
        """WebSocket é”™è¯¯å›è°ƒ"""
        logger.error(f"âŒ WebSocket é”™è¯¯: {error}")
        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    def on_close(self, ws, close_status_code, close_msg):
        """WebSocket å…³é—­å›è°ƒ"""
        # æ›´æ–°è¿æ¥çŠ¶æ€ Metric
        if HAS_PROMETHEUS:
            self.metrics_connections.set(0)  # 0 = å·²æ–­å¼€
        
        if self.should_stop:
            logger.info(f"âœ… WebSocket è¿æ¥å·²å…³é—­")
        else:
            logger.warning(f"âš ï¸  WebSocket è¿æ¥æ–­å¼€: {close_status_code} - {close_msg}")
            logger.info("ğŸ”„ å°†åœ¨5ç§’åè‡ªåŠ¨é‡è¿...")
    
    def _backfill_missed_logs(self, reason="é‡è¿"):
        """
        æ–­çº¿å›è¡¥ï¼šä½¿ç”¨eth_getLogså›è¡¥é—æ¼çš„äº¤æ˜“ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        
        ä¼˜åŒ–ï¼š
        - 60ç§’å†·å´æœŸï¼Œé˜²æ­¢é¢‘ç¹è§¦å‘
        - ç¦»çº¿æ—¶é—´é˜ˆå€¼ï¼ˆ>30ç§’æ‰å›è¡¥ï¼‰
        - ç¼©å°åŒºå—è·¨åº¦ï¼ˆ200å—ï¼‰
        - è®°å½•è§¦å‘åŸå› å’Œç»Ÿè®¡
        """
        try:
            now = time.time()
            
            # 1. å†·å´æœŸæ£€æŸ¥ï¼ˆ60ç§’å†…ä¸é‡å¤å›è¡¥ï¼‰
            if now - self.last_backfill_time < self.backfill_cooldown:
                elapsed = int(now - self.last_backfill_time)
                logger.info(f"â­ï¸  å›è¡¥å†·å´ä¸­ ({elapsed}s/{self.backfill_cooldown}s)ï¼Œè·³è¿‡æœ¬æ¬¡å›è¡¥ï¼ˆåŸå› ï¼š{reason}ï¼‰")
                return
            
            # è®°å½•å›è¡¥æ—¶é—´å’ŒåŸå› 
            self.last_backfill_time = now
            self.reconnect_time = now
            
            # 2. è·å–å½“å‰åŒºå—
            latest_block_hex = self.rpc_call("eth_blockNumber", [])
            if not latest_block_hex:
                logger.warning("âŒ è·å–æœ€æ–°åŒºå—å¤±è´¥ï¼Œè·³è¿‡å›è¡¥")
                return
            
            latest_block = int(latest_block_hex, 16)
            
            # 3. è®¡ç®—å›è¡¥åŒºå—èŒƒå›´
            if self.last_processed_block == 0:
                # é¦–æ¬¡è¿æ¥ï¼Œåªå›è¡¥æœ€è¿‘50ä¸ªåŒºå—ï¼ˆçº¦15ç§’ï¼‰
                from_block = max(latest_block - 50, 0)
                offline_seconds = "é¦–æ¬¡è¿æ¥"
            else:
                # è®¡ç®—ç¦»çº¿æ—¶é—´ï¼ˆæŒ‰3ç§’/å—ä¼°ç®—ï¼‰
                missed_blocks = latest_block - self.last_processed_block
                offline_seconds = missed_blocks * 3  # BSC çº¦3ç§’/å—
                
                # ç¦»çº¿æ—¶é—´é˜ˆå€¼ï¼šåªåœ¨ç¦»çº¿ > 30ç§’ æ‰å›è¡¥
                if offline_seconds < 30:
                    logger.info(f"â­ï¸  ç¦»çº¿æ—¶é—´è¿‡çŸ­ ({offline_seconds:.0f}s < 30s)ï¼Œè·³è¿‡å›è¡¥ï¼ˆåŸå› ï¼š{reason}ï¼‰")
                    self.last_processed_block = latest_block
                    return
                
                # é™åˆ¶å›è¡¥åŒºå—è·¨åº¦ï¼ˆæœ€å¤š200å—ï¼Œçº¦10åˆ†é’Ÿï¼‰
                max_backfill_blocks = 200
                from_block = max(self.last_processed_block, latest_block - max_backfill_blocks)
            
            block_span = latest_block - from_block
            self.backfill_count += 1
            
            logger.info(f"ğŸ”„ [å›è¡¥ #{self.backfill_count}] å¼€å§‹: #{from_block} â†’ #{latest_block} ({block_span}å—, ç¦»çº¿â‰ˆ{offline_seconds}s, åŸå› :{reason})")
            
            # 4. åˆ†æ‰¹æŸ¥è¯¢ï¼ˆç¼©å°batchï¼Œé™ä½å•æ¬¡è¯·æ±‚å‹åŠ›ï¼‰
            batch_size = 200  # ä»1000æ”¹ä¸º200
            total_logs = 0
            
            for start in range(from_block, latest_block + 1, batch_size):
                end = min(start + batch_size - 1, latest_block)
                
                # æŸ¥è¯¢Proxyç›¸å…³çš„æ—¥å¿—
                logs = self.rpc_call("eth_getLogs", [{
                    "fromBlock": hex(start),
                    "toBlock": hex(end),
                    "address": self.FOURMEME_PROXY
                }])
                
                if logs and isinstance(logs, list):
                    total_logs += len(logs)
                    # å¤„ç†æ¯æ¡æ—¥å¿—
                    for log in logs:
                        try:
                            # å¼‚æ­¥å¤„ç†æ—¥å¿—ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­ï¼‰
                            self.executor.submit(self._run_async_in_thread, self._process_backfill_log, log)
                        except Exception as e:
                            logger.debug(f"å¤„ç†å›è¡¥æ—¥å¿—å¤±è´¥: {e}")
            
            logger.info(f"âœ… [å›è¡¥ #{self.backfill_count}] å®Œæˆ: å…±å¤„ç† {total_logs} æ¡æ—¥å¿—")
            self.last_processed_block = latest_block
            
        except Exception as e:
            logger.error(f"âŒ [å›è¡¥ #{self.backfill_count}] å¤±è´¥: {e}")
    
    async def _process_backfill_log(self, log):
        """å¤„ç†å›è¡¥çš„æ—¥å¿—"""
        try:
            # åˆ¤æ–­æ˜¯å†…ç›˜è¿˜æ˜¯å¤–ç›˜
            topics = log.get("topics", [])
            if not topics:
                return
            
            topic0 = topics[0].lower() if topics[0] else ""
            addr = log.get("address", "").lower()
            
            # å†…ç›˜äº‹ä»¶
            if topic0 in self.FOURMEME_CUSTOM_EVENTS or addr in self.FOURMEME_PROXY:
                await self.handle_proxy_event(log)
        except Exception as e:
            logger.debug(f"å¤„ç†å›è¡¥æ—¥å¿—å¼‚å¸¸: {e}")
    
    def signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼ˆCtrl+Cï¼‰"""
        logger.info("\nâš ï¸  æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
        self.should_stop = True
        
        # é€€å‡ºå‰ä¿å­˜ä¸€æ¬¡æŒ‡æ ‡åˆ°Redis
        if HAS_PROMETHEUS and self.redis_client:
            try:
                self._save_all_metrics_to_redis()
                logger.info("ğŸ’¾ é€€å‡ºå‰ä¿å­˜PrometheusæŒ‡æ ‡å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ é€€å‡ºå‰ä¿å­˜æŒ‡æ ‡å¤±è´¥: {e}")
        
        if self.ws:
            self.ws.close()
        
        # å…³é—­ HTTP Session
        if hasattr(self, 'session'):
            try:
                self.session.close()
                logger.info("âœ… HTTP Session å·²å…³é—­")
            except Exception as e:
                logger.debug(f"å…³é—­ Session å¼‚å¸¸: {e}")
        
        self.executor.shutdown(wait=False)
        

        os._exit(0)
    
    async def _periodic_save_metrics(self):
        """åå°ä»»åŠ¡ï¼šæ¯5åˆ†é’Ÿä¿å­˜ä¸€æ¬¡æŒ‡æ ‡åˆ°Redis"""
        while not self.should_stop:
            try:
                await asyncio.sleep(300)  # 5åˆ†é’Ÿ
                if not self.should_stop:
                    await asyncio.to_thread(self._save_all_metrics_to_redis)
                    logger.info("ğŸ’¾ å®šæœŸä¿å­˜PrometheusæŒ‡æ ‡åˆ°Redis")
            except Exception as e:
                logger.error(f"âŒ å®šæœŸä¿å­˜æŒ‡æ ‡å¤±è´¥: {e}")
    
    async def start(self):
        """å¯åŠ¨ç›‘æ§"""
        # åŠ è½½é…ç½®
        await self.load_config_from_redis()

        # æ³¨å†Œä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
        # å¯åŠ¨å®šæœŸä¿å­˜æŒ‡æ ‡ä»»åŠ¡
        if HAS_PROMETHEUS and self.redis_client:
            asyncio.create_task(self._periodic_save_metrics())
            logger.info("âœ… å¯åŠ¨PrometheusæŒ‡æ ‡å®šæœŸä¿å­˜ä»»åŠ¡ï¼ˆæ¯5åˆ†é’Ÿï¼‰")
        
        # åˆ›å»º WebSocketï¼ˆæ·»åŠ  ping/pong å¿ƒè·³ä¿æ´»ï¼‰
        websocket.enableTrace(False)
        
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œ WebSocketï¼ˆæ·»åŠ å¿ƒè·³å’Œè‡ªåŠ¨é‡è¿ï¼‰
        def run_ws_with_retry():
            """å¸¦é‡è¿æœºåˆ¶çš„ WebSocket è¿è¡Œå¾ªç¯"""
            retry_count = 0
            while not self.should_stop:
                try:
                    logger.info(f"ğŸ”Œ WebSocket è¿æ¥å°è¯•... (ç¬¬{retry_count + 1}æ¬¡)")
                    
                    # æ¯æ¬¡é‡è¿éƒ½åˆ›å»ºæ–°çš„ WebSocket å¯¹è±¡
                    self.ws = websocket.WebSocketApp(
                        self.ws_url,
                        on_message=self.on_message,
                        on_open=self.on_open,
                        on_error=self.on_error,
                        on_close=self.on_close
                    )
                    
                    # OPTIMIZED: å‡å°‘å¿ƒè·³é—´éš”ï¼Œæé«˜WSç¨³å®šæ€§ï¼ˆNodeRealå»¶è¿Ÿé«˜ï¼‰
                    self.ws.run_forever(
                        ping_interval=10,    # æ¯10ç§’å‘é€pingï¼ˆé™ä½é‡è¿é£é™©ï¼‰
                        ping_timeout=5,      # pingè¶…æ—¶5ç§’ï¼ˆå¿«é€Ÿæ£€æµ‹æ–­çº¿ï¼‰
                        skip_utf8_validation=True
                    )
                    
                    # å¦‚æœæ­£å¸¸é€€å‡ºï¼ˆç”¨æˆ·åœæ­¢ï¼‰ï¼Œè·³å‡ºå¾ªç¯
                    if self.should_stop:
                        break
                    
                    # å¼‚å¸¸é€€å‡ºï¼Œç­‰å¾…åé‡è¿
                    retry_count += 1
                    wait_seconds = min(5 * retry_count, 60)  # æœ€å¤šç­‰60ç§’
                    logger.warning(f"â³ WebSocket æ–­å¼€ï¼Œ{wait_seconds}ç§’åé‡è¿...")
                    time.sleep(wait_seconds)
                    
                except Exception as e:
                    logger.error(f"âŒ WebSocket è¿è¡Œå¼‚å¸¸: {e}")
                    logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                    
                    if not self.should_stop:
                        retry_count += 1
                        wait_seconds = min(5 * retry_count, 60)
                        logger.warning(f"â³ {wait_seconds}ç§’åé‡è¯•...")
                        time.sleep(wait_seconds)

        ws_thread = threading.Thread(target=run_ws_with_retry, daemon=True)
        ws_thread.start()
        
        # å¯åŠ¨å¥åº·æ£€æŸ¥çº¿ç¨‹
        health_thread = threading.Thread(target=self.health_check_loop, daemon=True)
        health_thread.start()
        logger.info("ğŸ’“ å¥åº·æ£€æŸ¥å·²å¯åŠ¨ï¼ˆæ¯60ç§’ä¸€æ¬¡ï¼‰")
        
        # ä¿æŒä¸»çº¿ç¨‹è¿è¡Œ
        try:
            while not self.should_stop:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            logger.info("âš ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            logger.info("ğŸ›‘ æ­£åœ¨å…³é—­ç›‘æ§...")
            self.should_stop = True
            
            # å…³é—­WebSocket
            if self.ws:
                try:
                    self.ws.close()
                    logger.info("âœ… WebSocket å·²å…³é—­")
                except Exception as e:
                    logger.debug(f"å…³é—­ WebSocket å¼‚å¸¸: {e}")
            
            # å…³é—­ HTTP Session
            if hasattr(self, 'session'):
                try:
                    self.session.close()
                    logger.info("âœ… HTTP Session å·²å…³é—­")
                except Exception as e:
                    logger.debug(f"å…³é—­ Session å¼‚å¸¸: {e}")
            
            # å…³é—­çº¿ç¨‹æ± ï¼ˆç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæœ€å¤š30ç§’ï¼‰
            if hasattr(self, 'executor'):
                logger.info("ğŸ›‘ ç­‰å¾…çº¿ç¨‹æ± ä»»åŠ¡å®Œæˆï¼ˆæœ€å¤š30ç§’ï¼‰...")
                self.executor.shutdown(wait=True)
                logger.info("âœ… çº¿ç¨‹æ± å·²å…³é—­")
            
            logger.info("âœ… ç›‘æ§å·²å®Œå…¨å…³é—­")

