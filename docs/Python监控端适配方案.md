# Pythonç›‘æ§ç«¯é€‚é…V2æ–¹æ¡ˆ

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.1  
> **åˆ›å»ºæ—¥æœŸ**: 2025-11-10  
> **æœ€åæ›´æ–°**: 2025-11-13  
> **ç›®æ ‡**: è®©Pythonç›‘æ§ç«¯é€‚é…æ–°çš„monitor_*_v2è¡¨ç»“æ„
> **æœ€æ–°æ›´æ–°**: ä¿®æ­£ä»»åŠ¡-é…ç½®å…³ç³»ï¼ˆM:N â†’ 1:Nï¼‰

---

## ğŸ“‹ ç›®å½•

1. [æ ¸å¿ƒå˜åŒ–](#æ ¸å¿ƒå˜åŒ–)
2. [æ•°æ®åº“è¿æ¥](#æ•°æ®åº“è¿æ¥)
3. [åŠ è½½ä»»åŠ¡å’Œé…ç½®](#åŠ è½½ä»»åŠ¡å’Œé…ç½®)
4. [æ‰¹æ¬¡åˆ†é…ç®—æ³•](#æ‰¹æ¬¡åˆ†é…ç®—æ³•)
5. [é…ç½®å˜æ›´æ„ŸçŸ¥](#é…ç½®å˜æ›´æ„ŸçŸ¥)
6. [å¿ƒè·³ä¸ŠæŠ¥æœºåˆ¶](#å¿ƒè·³ä¸ŠæŠ¥æœºåˆ¶)
7. [å®Œæ•´ä»£ç ç¤ºä¾‹](#å®Œæ•´ä»£ç ç¤ºä¾‹)

---

## ğŸ”„ æ ¸å¿ƒå˜åŒ–

### æ—§ç³»ç»Ÿ vs æ–°ç³»ç»Ÿ

| ç»´åº¦ | æ—§ç³»ç»Ÿ | æ–°ç³»ç»Ÿ V2 |
|------|--------|-----------|
| **é…ç½®è¡¨** | `quick_monitor_template` | `monitor_config_v2` |
| **ä»»åŠ¡è¡¨** | æ— ç‹¬ç«‹ä»»åŠ¡è¡¨ | `monitor_task_v2` |
| **ç›®æ ‡è¡¨** | `sol_ws_batch_pool`ï¼ˆæ··åˆï¼‰ | `monitor_task_target_v2` |
| **æ‰¹æ¬¡è¡¨** | `sol_ws_batch_pool`ï¼ˆæ··åˆï¼‰ | `monitor_batch_v2` + `monitor_batch_item_v2` |
| **å‘Šè­¦è¡¨** | åˆ†æ•£å¤šå¤„ | `monitor_alert_log_v2` |
| **å…³è”å…³ç³»** | 1:Nï¼ˆé…ç½®â†’Tokenï¼‰ | ~~M:Nï¼ˆé…ç½®â†”ä»»åŠ¡ï¼‰~~ 1:Nï¼ˆé…ç½®â†’ä»»åŠ¡ï¼‰ + 1:Nï¼ˆä»»åŠ¡â†’ç›®æ ‡ï¼‰ â­ |

### å…³é”®æ¦‚å¿µå˜åŒ–

```
æ—§ç³»ç»Ÿï¼šé…ç½® â†’ Tokenåˆ—è¡¨ï¼ˆbatch_idåˆ†ç»„ï¼‰

æ–°ç³»ç»Ÿï¼šé…ç½® â†’ ä»»åŠ¡ â†’ ç›®æ ‡åˆ—è¡¨ â†’ æ‰¹æ¬¡åˆ†é…
         (1:N)  (1:1)  (1:N)
```

### â­ é‡è¦è¯´æ˜ï¼šä»»åŠ¡-é…ç½®å…³ç³»

**æ¶æ„è®¾è®¡**ï¼š
- âœ… ä¸€ä¸ªä»»åŠ¡åªèƒ½ç»‘å®š**ä¸€ä¸ªé…ç½®**ï¼ˆ1:1å…³ç³»ï¼‰
- âœ… ä¸€ä¸ªé…ç½®å¯ä»¥è¢«**å¤šä¸ªä»»åŠ¡**ä½¿ç”¨ï¼ˆ1:Nå…³ç³»ï¼‰
- âœ… å•ä¸ªé…ç½®è¶³å¤Ÿä¸€ä¸ªä»»åŠ¡ä½¿ç”¨ï¼ˆå¯åŒ…å«ä»·æ ¼+æŒä»“+æˆäº¤é‡ç­‰å¤šä¸ªäº‹ä»¶è§„åˆ™ï¼‰

**ä»£ç å®ç°**ï¼š
- Pythonä»£ç ä¸­ä»ä½¿ç”¨ `configs` æ•°ç»„ï¼Œä½†**å®é™…åªæœ‰1ä¸ªå…ƒç´ **
- è¿™æ ·è®¾è®¡æ˜¯ä¸ºäº†ä»£ç å…¼å®¹æ€§å’Œæ‰©å±•æ€§ï¼ˆæœªæ¥å¦‚æœéœ€è¦æ”¯æŒå¤šé…ç½®ï¼Œæ”¹åŠ¨æœ€å°ï¼‰
- å®é™…ä½¿ç”¨æ—¶ï¼š`config = task['configs'][0]`

---

## ğŸ”Œ æ•°æ®åº“è¿æ¥

### 1. é…ç½®æ–‡ä»¶ï¼ˆconfig.pyï¼‰

```python
# config.py
import os
from dotenv import load_dotenv

load_dotenv()

DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 3306)),
    'user': os.getenv('DB_USER', 'root'),
    'password': os.getenv('DB_PASSWORD'),
    'database': os.getenv('DB_NAME', 'kakarot_web3'),
    'charset': 'utf8mb4'
}

REDIS_CONFIG = {
    'host': os.getenv('REDIS_HOST', 'localhost'),
    'port': int(os.getenv('REDIS_PORT', 6379)),
    'db': int(os.getenv('REDIS_DB', 0)),
    'password': os.getenv('REDIS_PASSWORD'),
    'decode_responses': True
}

# ç›‘æ§é…ç½®
HEARTBEAT_INTERVAL = 30  # å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰
CONFIG_POLL_INTERVAL = 5  # é…ç½®è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
BATCH_SIZE = 99  # æ‰¹æ¬¡å¤§å°
```

---

## ğŸ“Š åŠ è½½ä»»åŠ¡å’Œé…ç½®

### 2. æ•°æ®åŠ è½½å™¨ï¼ˆdata_loader.pyï¼‰

```python
# data_loader.py
import pymysql
from typing import List, Dict
import json

class MonitorDataLoader:
    """ä»V2è¡¨ç»“æ„åŠ è½½ä»»åŠ¡å’Œé…ç½®"""
    
    def __init__(self, db_config: dict):
        self.db_config = db_config
    
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        return pymysql.connect(**self.db_config)
    
    def load_active_tasks(self) -> List[Dict]:
        """
        åŠ è½½æ‰€æœ‰æ´»è·ƒä»»åŠ¡ï¼ˆstatus=1ï¼‰
        
        è¿”å›æ ¼å¼ï¼š
        [
            {
                'task_id': 1,
                'task_name': 'SOLæ™ºèƒ½ç›‘æ§',
                'task_type': 'smart',
                'chain_type': 'sol',
                'configs': [é…ç½®åˆ—è¡¨],
                'targets': [ç›®æ ‡åˆ—è¡¨]  # ä»…smart/batchæœ‰
            }
        ]
        """
        conn = self.get_connection()
        cursor = conn.cursor(pymysql.cursors.DictCursor)
        
        try:
            # æŸ¥è¯¢æ´»è·ƒä»»åŠ¡
            cursor.execute("""
                SELECT 
                    id as task_id,
                    task_name,
                    task_type,
                    chain_type,
                    status,
                    create_time,
                    update_time
                FROM monitor_task_v2
                WHERE status = 1
                  AND del_flag = 0
                ORDER BY id
            """)
            
            tasks = cursor.fetchall()
            
            # ä¸ºæ¯ä¸ªä»»åŠ¡åŠ è½½å…³è”çš„é…ç½®å’Œç›®æ ‡
            for task in tasks:
                task['configs'] = self._load_task_configs(cursor, task['task_id'])
                
                # åªæœ‰smart/batchç±»å‹ä»»åŠ¡æ‰æœ‰ç›®æ ‡
                if task['task_type'] in ['smart', 'batch']:
                    task['targets'] = self._load_task_targets(cursor, task['task_id'])
                else:
                    task['targets'] = []
            
            return tasks
            
        finally:
            cursor.close()
            conn.close()
    
    def _load_task_configs(self, cursor, task_id: int) -> List[Dict]:
        """åŠ è½½ä»»åŠ¡å…³è”çš„é…ç½®"""
        cursor.execute("""
            SELECT 
                c.id as config_id,
                c.config_name,
                c.config_category,
                c.chain_type,
                c.source,
                c.market_type,
                c.min_transaction_usd,
                c.cumulative_min_amount_usd,
                c.time_interval,
                c.top_holders_threshold,
                c.events_config,
                c.trigger_logic,
                c.notify_methods,
                c.version
            FROM monitor_config_v2 c
            INNER JOIN monitor_task_config_v2 tc ON c.id = tc.config_id
            WHERE tc.task_id = %s
              AND c.status = 1
              AND c.del_flag = 0
            ORDER BY tc.config_order
        """, (task_id,))
        
        configs = cursor.fetchall()
        
        # è§£æ JSON å­—æ®µ
        for config in configs:
            if config['events_config']:
                try:
                    config['events_config'] = json.loads(config['events_config'])
                except:
                    config['events_config'] = {}
        
        return configs
    
    def _load_task_targets(self, cursor, task_id: int) -> List[Dict]:
        """åŠ è½½ä»»åŠ¡çš„ç›‘æ§ç›®æ ‡"""
        cursor.execute("""
            SELECT 
                id as target_id,
                target_type,
                target_value as ca,
                token_name,
                token_symbol,
                market_cap,
                pair_address,
                source,
                batch_id,
                batch_order,
                priority,
                status
            FROM monitor_task_target_v2
            WHERE task_id = %s
              AND status = 1
            ORDER BY batch_id, batch_order
        """, (task_id,))
        
        return cursor.fetchall()
    
    def load_task_by_id(self, task_id: int) -> Dict:
        """åŠ è½½å•ä¸ªä»»åŠ¡"""
        conn = self.get_connection()
        cursor = conn.cursor(pymysql.cursors.DictCursor)
        
        try:
            cursor.execute("""
                SELECT 
                    id as task_id,
                    task_name,
                    task_type,
                    chain_type,
                    status
                FROM monitor_task_v2
                WHERE id = %s
            """, (task_id,))
            
            task = cursor.fetchone()
            if not task:
                return None
            
            task['configs'] = self._load_task_configs(cursor, task_id)
            
            if task['task_type'] in ['smart', 'batch']:
                task['targets'] = self._load_task_targets(cursor, task_id)
            else:
                task['targets'] = []
            
            return task
            
        finally:
            cursor.close()
            conn.close()
```

---

## ğŸ”¢ æ‰¹æ¬¡åˆ†é…ç®—æ³•

### 3. æ‰¹æ¬¡åˆ†é…å™¨ï¼ˆbatch_allocator.pyï¼‰

```python
# batch_allocator.py
import hashlib
import pymysql
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)

class BatchAllocator:
    """ä¸€è‡´æ€§å“ˆå¸Œæ‰¹æ¬¡åˆ†é…å™¨"""
    
    BATCH_SIZE = 99
    HASH_SALT = "kakarot_v2_2025"  # ç›å€¼ç‰ˆæœ¬
    
    def __init__(self, db_config: dict):
        self.db_config = db_config
    
    def get_connection(self):
        return pymysql.connect(**self.db_config)
    
    def allocate_batches(self, task_id: int):
        """
        ä¸ºä»»åŠ¡çš„æ‰€æœ‰ç›®æ ‡åˆ†é…æ‰¹æ¬¡
        
        æ­¥éª¤ï¼š
        1. è¯»å–æ‰€æœ‰æ´»è·ƒç›®æ ‡
        2. ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œæ’åº
        3. æŒ‰BATCH_SIZEåˆ†ç»„ï¼ˆæ¯æ‰¹â‰¤99ä¸ªï¼‰
        4. æ›´æ–°ç›®æ ‡çš„batch_idå’Œbatch_order
        5. åŒæ­¥æ‰¹æ¬¡å¤´è¡¨
        """
        conn = self.get_connection()
        cursor = conn.cursor(pymysql.cursors.DictCursor)
        
        try:
            # 1. è¯»å–æ´»è·ƒç›®æ ‡
            cursor.execute("""
                SELECT id, target_value, batch_id
                FROM monitor_task_target_v2
                WHERE task_id = %s AND status = 1
                ORDER BY id
            """, (task_id,))
            
            targets = cursor.fetchall()
            
            if not targets:
                logger.info(f"ä»»åŠ¡ {task_id} æ— ç›®æ ‡ï¼Œè·³è¿‡æ‰¹æ¬¡åˆ†é…")
                return
            
            # 2. ä¸€è‡´æ€§å“ˆå¸Œæ’åº
            targets_sorted = sorted(
                targets, 
                key=lambda x: self._hash_target(task_id, x['target_value'])
            )
            
            # 3. åˆ†é…æ‰¹æ¬¡å·
            total_batches = (len(targets_sorted) + self.BATCH_SIZE - 1) // self.BATCH_SIZE
            
            updates = []
            for idx, target in enumerate(targets_sorted):
                new_batch_no = (idx // self.BATCH_SIZE) + 1
                new_batch_order = idx % self.BATCH_SIZE
                
                # åªæ›´æ–°å˜åŒ–çš„ç›®æ ‡ï¼ˆå‡å°‘æ•°æ®åº“å†™å…¥ï¼‰
                if target.get('batch_id') != new_batch_no:
                    updates.append((new_batch_no, new_batch_order, target['id']))
            
            # 4. æ‰¹é‡æ›´æ–°
            if updates:
                cursor.executemany("""
                    UPDATE monitor_task_target_v2
                    SET batch_id = %s, batch_order = %s, update_time = NOW()
                    WHERE id = %s
                """, updates)
                
                logger.info(f"ä»»åŠ¡ {task_id}: {len(targets_sorted)} ä¸ªç›®æ ‡, "
                          f"{total_batches} ä¸ªæ‰¹æ¬¡, å˜æ›´ {len(updates)} é¡¹")
            
            # 5. åŒæ­¥æ‰¹æ¬¡å¤´è¡¨
            self._sync_batch_headers(cursor, task_id, total_batches)
            
            conn.commit()
            
        except Exception as e:
            conn.rollback()
            logger.error(f"æ‰¹æ¬¡åˆ†é…å¤±è´¥: {e}")
            raise
        finally:
            cursor.close()
            conn.close()
    
    def _hash_target(self, task_id: int, target_value: str) -> int:
        """è®¡ç®—ç›®æ ‡çš„å“ˆå¸Œå€¼ï¼ˆä¸€è‡´æ€§å“ˆå¸Œï¼‰"""
        hash_input = f"{task_id}:{target_value}:{self.HASH_SALT}"
        hash_hex = hashlib.md5(hash_input.encode()).hexdigest()
        return int(hash_hex[:8], 16)  # å–å‰8ä½åå…­è¿›åˆ¶
    
    def _sync_batch_headers(self, cursor, task_id: int, expected_batches: int):
        """åŒæ­¥æ‰¹æ¬¡å¤´è¡¨"""
        for batch_no in range(1, expected_batches + 1):
            # è®¡ç®—æ‰¹æ¬¡é¡¹æ•°
            cursor.execute("""
                SELECT COUNT(*) as item_count
                FROM monitor_task_target_v2
                WHERE task_id = %s AND batch_id = %s AND status = 1
            """, (task_id, batch_no))
            
            result = cursor.fetchone()
            item_count = result['item_count'] if result else 0
            
            # æ’å…¥æˆ–æ›´æ–°æ‰¹æ¬¡å¤´
            cursor.execute("""
                INSERT INTO monitor_batch_v2 
                    (task_id, batch_no, item_count, status, create_time, update_time)
                VALUES (%s, %s, %s, 'pending', NOW(), NOW())
                ON DUPLICATE KEY UPDATE
                    item_count = VALUES(item_count),
                    update_time = NOW()
            """, (task_id, batch_no, item_count))
```

---

## ğŸ”” é…ç½®å˜æ›´æ„ŸçŸ¥

### 4. é…ç½®ç›‘å¬å™¨ï¼ˆconfig_watcher.pyï¼‰

```python
# config_watcher.py
import redis
import threading
import time
import logging
from datetime import datetime
from typing import Callable

logger = logging.getLogger(__name__)

class ConfigWatcher:
    """é…ç½®å˜æ›´ç›‘å¬å™¨ï¼ˆRedis Pub/Sub + è½®è¯¢å…œåº•ï¼‰"""
    
    def __init__(self, redis_config: dict, db_config: dict):
        self.redis_client = redis.Redis(**redis_config)
        self.db_config = db_config
        self.config_cache = {}  # {config_id: {'version': 1, 'last_reload': datetime}}
        self.last_poll_time = datetime.now()
        self.callbacks = []  # é…ç½®å˜æ›´å›è°ƒå‡½æ•°
        self.running = False
    
    def register_callback(self, callback: Callable[[int, int], None]):
        """
        æ³¨å†Œé…ç½®å˜æ›´å›è°ƒå‡½æ•°
        
        Args:
            callback: å›è°ƒå‡½æ•°ï¼Œç­¾åä¸º callback(config_id, version)
        """
        self.callbacks.append(callback)
    
    def start(self):
        """å¯åŠ¨é…ç½®ç›‘å¬"""
        self.running = True
        
        # å¯åŠ¨Redisè®¢é˜…çº¿ç¨‹
        threading.Thread(target=self._subscribe_redis, daemon=True).start()
        
        # å¯åŠ¨è½®è¯¢å…œåº•çº¿ç¨‹
        threading.Thread(target=self._poll_changes, daemon=True).start()
        
        logger.info("é…ç½®ç›‘å¬å™¨å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢é…ç½®ç›‘å¬"""
        self.running = False
        logger.info("é…ç½®ç›‘å¬å™¨å·²åœæ­¢")
    
    def _subscribe_redis(self):
        """Redis Pub/Subè®¢é˜…ï¼ˆå®æ—¶ï¼‰"""
        try:
            pubsub = self.redis_client.pubsub()
            pubsub.subscribe('monitor:config:changed')
            
            logger.info("Redisè®¢é˜…å·²å¯åŠ¨: monitor:config:changed")
            
            for message in pubsub.listen():
                if not self.running:
                    break
                
                if message['type'] == 'message':
                    try:
                        import json
                        event = json.loads(message['data'])
                        config_id = event.get('configId')
                        version = event.get('version')
                        
                        if config_id:
                            self._reload_config(config_id, version)
                    except Exception as e:
                        logger.error(f"å¤„ç†Redisæ¶ˆæ¯å¤±è´¥: {e}")
        
        except Exception as e:
            logger.error(f"Redisè®¢é˜…å¤±è´¥: {e}")
    
    def _poll_changes(self):
        """è½®è¯¢å¢é‡ï¼ˆ5ç§’é—´éš”ï¼Œå…œåº•ï¼‰"""
        import pymysql
        
        while self.running:
            try:
                time.sleep(5)
                
                conn = pymysql.connect(**self.db_config)
                cursor = conn.cursor(pymysql.cursors.DictCursor)
                
                # æŸ¥è¯¢æœ€è¿‘æ›´æ–°çš„é…ç½®
                cursor.execute("""
                    SELECT id, version, update_time
                    FROM monitor_config_v2
                    WHERE update_time > %s
                      AND status = 1
                    ORDER BY update_time DESC
                """, (self.last_poll_time,))
                
                changed_configs = cursor.fetchall()
                
                for config in changed_configs:
                    config_id = config['id']
                    version = config['version']
                    
                    # æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦æ›´æ–°
                    cached_version = self.config_cache.get(config_id, {}).get('version', 0)
                    if version > cached_version:
                        self._reload_config(config_id, version)
                
                self.last_poll_time = datetime.now()
                
                cursor.close()
                conn.close()
                
            except Exception as e:
                logger.error(f"è½®è¯¢é…ç½®å¤±è´¥: {e}")
    
    def _reload_config(self, config_id: int, version: int):
        """
        é‡è½½é…ç½®ï¼ˆ2ç§’å»æŠ–ï¼Œå¹‚ç­‰ï¼‰
        
        Args:
            config_id: é…ç½®ID
            version: é…ç½®ç‰ˆæœ¬
        """
        # 2ç§’å»æŠ–ï¼šé¿å…çŸ­æ—¶é—´å†…é‡å¤é‡è½½
        last_reload = self.config_cache.get(config_id, {}).get('last_reload')
        if last_reload:
            delta = (datetime.now() - last_reload).total_seconds()
            if delta < 2:
                logger.debug(f"é…ç½® {config_id} è·³è¿‡é‡è½½ï¼ˆå»æŠ–ï¼‰")
                return
        
        # æ£€æŸ¥ç‰ˆæœ¬
        cached_version = self.config_cache.get(config_id, {}).get('version', 0)
        if version <= cached_version:
            logger.debug(f"é…ç½® {config_id} ç‰ˆæœ¬æœªå˜åŒ–ï¼Œè·³è¿‡")
            return
        
        # æ›´æ–°ç¼“å­˜
        self.config_cache[config_id] = {
            'version': version,
            'last_reload': datetime.now()
        }
        
        logger.info(f"âœ… é…ç½®å·²é‡è½½: configId={config_id}, version={version}")
        
        # è°ƒç”¨å›è°ƒå‡½æ•°
        for callback in self.callbacks:
            try:
                callback(config_id, version)
            except Exception as e:
                logger.error(f"é…ç½®å˜æ›´å›è°ƒå¤±è´¥: {e}")
```

---

## ğŸ’“ å¿ƒè·³ä¸ŠæŠ¥æœºåˆ¶

### 5. å¿ƒè·³ä¸ŠæŠ¥å™¨ï¼ˆheartbeat_reporter.pyï¼‰

```python
# heartbeat_reporter.py
import pymysql
import threading
import time
import os
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class HeartbeatReporter:
    """æ‰¹æ¬¡å¿ƒè·³ä¸ŠæŠ¥å™¨"""
    
    def __init__(self, db_config: dict, interval: int = 30):
        self.db_config = db_config
        self.interval = interval
        self.running = False
        self.worker_id = f"{os.getpid()}@{os.uname().nodename}"  # è¿›ç¨‹ID@ä¸»æœºå
        self.batch_map = {}  # {batch_id: {'task_id': x, 'batch_no': y}}
    
    def register_batch(self, batch_id: int, task_id: int, batch_no: int):
        """æ³¨å†Œéœ€è¦ä¸ŠæŠ¥å¿ƒè·³çš„æ‰¹æ¬¡"""
        self.batch_map[batch_id] = {
            'task_id': task_id,
            'batch_no': batch_no
        }
        logger.info(f"æ³¨å†Œæ‰¹æ¬¡å¿ƒè·³: batch_id={batch_id}, task={task_id}, no={batch_no}")
    
    def unregister_batch(self, batch_id: int):
        """å–æ¶ˆæ³¨å†Œæ‰¹æ¬¡"""
        if batch_id in self.batch_map:
            del self.batch_map[batch_id]
            logger.info(f"å–æ¶ˆæ‰¹æ¬¡å¿ƒè·³: batch_id={batch_id}")
    
    def start(self):
        """å¯åŠ¨å¿ƒè·³ä¸ŠæŠ¥çº¿ç¨‹"""
        self.running = True
        threading.Thread(target=self._heartbeat_loop, daemon=True).start()
        logger.info(f"å¿ƒè·³ä¸ŠæŠ¥å™¨å·²å¯åŠ¨: worker_id={self.worker_id}, interval={self.interval}s")
    
    def stop(self):
        """åœæ­¢å¿ƒè·³ä¸ŠæŠ¥"""
        self.running = False
        logger.info("å¿ƒè·³ä¸ŠæŠ¥å™¨å·²åœæ­¢")
    
    def _heartbeat_loop(self):
        """å¿ƒè·³å¾ªç¯"""
        while self.running:
            try:
                self._report_heartbeat()
                time.sleep(self.interval)
            except Exception as e:
                logger.error(f"å¿ƒè·³ä¸ŠæŠ¥å¤±è´¥: {e}")
    
    def _report_heartbeat(self):
        """ä¸ŠæŠ¥å¿ƒè·³"""
        if not self.batch_map:
            return
        
        conn = pymysql.connect(**self.db_config)
        cursor = conn.cursor()
        
        try:
            for batch_id, info in self.batch_map.items():
                task_id = info['task_id']
                batch_no = info['batch_no']
                
                # æ›´æ–°æ‰¹æ¬¡å¿ƒè·³
                cursor.execute("""
                    UPDATE monitor_batch_v2
                    SET last_heartbeat = NOW(),
                        worker_id = %s,
                        worker_pid = %s,
                        status = 'running',
                        update_time = NOW()
                    WHERE task_id = %s AND batch_no = %s
                """, (self.worker_id, os.getpid(), task_id, batch_no))
            
            conn.commit()
            logger.debug(f"å¿ƒè·³å·²ä¸ŠæŠ¥: {len(self.batch_map)} ä¸ªæ‰¹æ¬¡")
            
        except Exception as e:
            conn.rollback()
            logger.error(f"å¿ƒè·³ä¸ŠæŠ¥æ•°æ®åº“é”™è¯¯: {e}")
        finally:
            cursor.close()
            conn.close()
    
    def report_alert(self, batch_id: int, task_id: int, batch_no: int):
        """ä¸ŠæŠ¥å‘Šè­¦æ•°ï¼ˆå¢é‡ï¼‰"""
        conn = pymysql.connect(**self.db_config)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                UPDATE monitor_batch_v2
                SET total_alerts = total_alerts + 1,
                    last_alert_time = NOW(),
                    update_time = NOW()
                WHERE task_id = %s AND batch_no = %s
            """, (task_id, batch_no))
            
            conn.commit()
            
        except Exception as e:
            conn.rollback()
            logger.error(f"ä¸ŠæŠ¥å‘Šè­¦æ•°å¤±è´¥: {e}")
        finally:
            cursor.close()
            conn.close()
    
    def report_error(self, batch_id: int, task_id: int, batch_no: int, error_msg: str):
        """ä¸ŠæŠ¥é”™è¯¯"""
        conn = pymysql.connect(**self.db_config)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                UPDATE monitor_batch_v2
                SET error_count = error_count + 1,
                    last_error = %s,
                    update_time = NOW()
                WHERE task_id = %s AND batch_no = %s
            """, (error_msg[:500], task_id, batch_no))  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
            
            conn.commit()
            
        except Exception as e:
            conn.rollback()
            logger.error(f"ä¸ŠæŠ¥é”™è¯¯å¤±è´¥: {e}")
        finally:
            cursor.close()
            conn.close()
```

---

## ğŸ“¦ å®Œæ•´ä»£ç ç¤ºä¾‹

### 6. ç›‘æ§ä¸»ç¨‹åºï¼ˆmonitor_main.pyï¼‰

```python
# monitor_main.py
import logging
import signal
import sys
from config import DB_CONFIG, REDIS_CONFIG, HEARTBEAT_INTERVAL
from data_loader import MonitorDataLoader
from batch_allocator import BatchAllocator
from config_watcher import ConfigWatcher
from heartbeat_reporter import HeartbeatReporter

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MonitorService:
    """ç›‘æ§æœåŠ¡ä¸»ç±»"""
    
    def __init__(self):
        self.loader = MonitorDataLoader(DB_CONFIG)
        self.allocator = BatchAllocator(DB_CONFIG)
        self.watcher = ConfigWatcher(REDIS_CONFIG, DB_CONFIG)
        self.heartbeat = HeartbeatReporter(DB_CONFIG, HEARTBEAT_INTERVAL)
        
        self.tasks = []  # å½“å‰åŠ è½½çš„ä»»åŠ¡åˆ—è¡¨
        self.running = False
    
    def start(self):
        """å¯åŠ¨ç›‘æ§æœåŠ¡"""
        logger.info("=" * 60)
        logger.info("ç›‘æ§ç³»ç»Ÿ V2.0 å¯åŠ¨ä¸­...")
        logger.info("=" * 60)
        
        # 1. åŠ è½½æ‰€æœ‰ä»»åŠ¡
        self._load_all_tasks()
        
        # 2. å¯åŠ¨é…ç½®ç›‘å¬
        self.watcher.register_callback(self._on_config_changed)
        self.watcher.start()
        
        # 3. å¯åŠ¨å¿ƒè·³ä¸ŠæŠ¥
        self.heartbeat.start()
        
        # 4. æ³¨å†Œä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        self.running = True
        logger.info("âœ… ç›‘æ§ç³»ç»Ÿ V2.0 å·²å¯åŠ¨ï¼")
        
        # 5. å¼€å§‹ç›‘æ§å¾ªç¯
        self._monitor_loop()
    
    def _load_all_tasks(self):
        """åŠ è½½æ‰€æœ‰æ´»è·ƒä»»åŠ¡"""
        logger.info("æ­£åœ¨åŠ è½½ä»»åŠ¡...")
        
        self.tasks = self.loader.load_active_tasks()
        
        logger.info(f"âœ… å·²åŠ è½½ {len(self.tasks)} ä¸ªä»»åŠ¡")
        
        for task in self.tasks:
            logger.info(f"  - ä»»åŠ¡ {task['task_id']}: {task['task_name']} "
                       f"({task['task_type']}, {task['chain_type']}) "
                       f"é…ç½®Ã—{len(task['configs'])} ç›®æ ‡Ã—{len(task['targets'])}")
            
            # æ³¨å†Œæ‰¹æ¬¡å¿ƒè·³
            if task['targets']:
                batch_ids = set(t['batch_id'] for t in task['targets'] if t.get('batch_id'))
                for batch_id in batch_ids:
                    self.heartbeat.register_batch(
                        batch_id, 
                        task['task_id'], 
                        batch_id
                    )
    
    def _on_config_changed(self, config_id: int, version: int):
        """é…ç½®å˜æ›´å›è°ƒ"""
        logger.info(f"ğŸ”„ é…ç½®å˜æ›´: config_id={config_id}, version={version}")
        
        # æ‰¾åˆ°ä½¿ç”¨è¯¥é…ç½®çš„ä»»åŠ¡
        affected_tasks = []
        for task in self.tasks:
            for config in task['configs']:
                if config['config_id'] == config_id:
                    affected_tasks.append(task['task_id'])
                    break
        
        if affected_tasks:
            logger.info(f"  å½±å“ä»»åŠ¡: {affected_tasks}")
            # é‡æ–°åŠ è½½è¿™äº›ä»»åŠ¡
            for task_id in affected_tasks:
                self._reload_task(task_id)
    
    def _reload_task(self, task_id: int):
        """é‡æ–°åŠ è½½ä»»åŠ¡"""
        logger.info(f"é‡æ–°åŠ è½½ä»»åŠ¡ {task_id}...")
        
        new_task = self.loader.load_task_by_id(task_id)
        if not new_task:
            logger.warning(f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨æˆ–å·²åœç”¨")
            return
        
        # æ›´æ–°ä»»åŠ¡åˆ—è¡¨
        for i, task in enumerate(self.tasks):
            if task['task_id'] == task_id:
                self.tasks[i] = new_task
                logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²é‡è½½")
                break
    
    def _monitor_loop(self):
        """ç›‘æ§ä¸»å¾ªç¯"""
        import time
        
        while self.running:
            try:
                # è¿™é‡Œå®ç°ä½ çš„ç›‘æ§é€»è¾‘
                # ä¾‹å¦‚ï¼šå¤„ç†WebSocketæ•°æ®ã€æ£€æŸ¥å‘Šè­¦è§„åˆ™ç­‰
                
                for task in self.tasks:
                    # æ ¹æ®ä»»åŠ¡ç±»å‹æ‰§è¡Œä¸åŒçš„ç›‘æ§é€»è¾‘
                    if task['task_type'] == 'smart':
                        self._monitor_smart_task(task)
                    elif task['task_type'] == 'batch':
                        self._monitor_batch_task(task)
                    elif task['task_type'] == 'block':
                        self._monitor_block_task(task)
                
                time.sleep(1)  # é¿å…CPUå ç”¨è¿‡é«˜
                
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}", exc_info=True)
    
    def _monitor_smart_task(self, task: dict):
        """ç›‘æ§æ™ºèƒ½ä»»åŠ¡"""
        # å®ç°ä½ çš„æ™ºèƒ½ç›‘æ§é€»è¾‘
        pass
    
    def _monitor_batch_task(self, task: dict):
        """ç›‘æ§æ‰¹é‡ä»»åŠ¡"""
        # å®ç°ä½ çš„æ‰¹é‡ç›‘æ§é€»è¾‘
        pass
    
    def _monitor_block_task(self, task: dict):
        """ç›‘æ§åŒºå—ä»»åŠ¡"""
        # å®ç°ä½ çš„åŒºå—ç›‘æ§é€»è¾‘
        pass
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†ï¼ˆä¼˜é›…é€€å‡ºï¼‰"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
        self.stop()
    
    def stop(self):
        """åœæ­¢ç›‘æ§æœåŠ¡"""
        self.running = False
        self.watcher.stop()
        self.heartbeat.stop()
        logger.info("âœ… ç›‘æ§ç³»ç»Ÿå·²åœæ­¢")
        sys.exit(0)


if __name__ == '__main__':
    service = MonitorService()
    service.start()
```

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 7. å¯åŠ¨ç›‘æ§æœåŠ¡

```bash
# 1. å®‰è£…ä¾èµ–
pip install pymysql redis python-dotenv

# 2. é…ç½®ç¯å¢ƒå˜é‡ï¼ˆ.envï¼‰
cat > .env << EOF
DB_HOST=localhost
DB_PORT=3306
DB_USER=root
DB_PASSWORD=your_password
DB_NAME=kakarot_web3

REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
EOF

# 3. è¿è¡Œæ‰¹æ¬¡åˆ†é…ï¼ˆé¦–æ¬¡è¿è¡Œæˆ–ç›®æ ‡å˜æ›´åï¼‰
python batch_allocator_cli.py --task-id 1

# 4. å¯åŠ¨ç›‘æ§æœåŠ¡
python monitor_main.py
```

### 8. æ‰¹æ¬¡åˆ†é…CLIå·¥å…·ï¼ˆbatch_allocator_cli.pyï¼‰

```python
# batch_allocator_cli.py
import argparse
import logging
from config import DB_CONFIG
from batch_allocator import BatchAllocator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def main():
    parser = argparse.ArgumentParser(description='æ‰¹æ¬¡åˆ†é…å·¥å…·')
    parser.add_argument('--task-id', type=int, required=True, help='ä»»åŠ¡ID')
    args = parser.parse_args()
    
    allocator = BatchAllocator(DB_CONFIG)
    
    logger.info(f"å¼€å§‹ä¸ºä»»åŠ¡ {args.task_id} åˆ†é…æ‰¹æ¬¡...")
    allocator.allocate_batches(args.task_id)
    logger.info("âœ… æ‰¹æ¬¡åˆ†é…å®Œæˆ")

if __name__ == '__main__':
    main()
```

---

## ğŸ“Š æ•°æ®æµå¯¹æ¯”

### æ—§ç³»ç»Ÿ

```
Pythonå¯åŠ¨
  â†’ æŸ¥è¯¢ sol_ws_batch_pool (WHERE is_active=1)
  â†’ æŒ‰ batch_id åˆ†ç»„
  â†’ è®¢é˜… WebSocket
  â†’ æ£€æµ‹äº‹ä»¶ â†’ å‘é€å‘Šè­¦
```

### æ–°ç³»ç»ŸV2

```
Pythonå¯åŠ¨
  â†’ æŸ¥è¯¢ monitor_task_v2 (WHERE status=1)
  â†’ JOIN monitor_task_config_v2 åŠ è½½é…ç½®
  â†’ JOIN monitor_config_v2 åŠ è½½è§„åˆ™
  â†’ JOIN monitor_task_target_v2 åŠ è½½ç›®æ ‡
  â†’ æŒ‰ batch_id åˆ†ç»„
  â†’ è®¢é˜… WebSocket
  â†’ æ£€æµ‹äº‹ä»¶ â†’ å†™å…¥ monitor_alert_log_v2
  â†’ å‘é€å‘Šè­¦ + ä¸ŠæŠ¥å¿ƒè·³
```

---

## âœ… å…³é”®æ£€æŸ¥æ¸…å•

- [ ] ç¡®è®¤æ–°è¡¨ `monitor_*_v2` å·²åˆ›å»º
- [ ] é…ç½®æ•°æ®åº“è¿æ¥ï¼ˆDB_CONFIGï¼‰
- [ ] é…ç½®Redisè¿æ¥ï¼ˆREDIS_CONFIGï¼‰
- [ ] å®ç° `_monitor_smart_task` ç›‘æ§é€»è¾‘
- [ ] å®ç° `_monitor_batch_task` ç›‘æ§é€»è¾‘
- [ ] å®ç° `_monitor_block_task` ç›‘æ§é€»è¾‘
- [ ] å®ç°å‘Šè­¦å†™å…¥ `monitor_alert_log_v2`
- [ ] æµ‹è¯•é…ç½®å˜æ›´æ„ŸçŸ¥ï¼ˆRedis Pub/Subï¼‰
- [ ] æµ‹è¯•å¿ƒè·³ä¸ŠæŠ¥æœºåˆ¶
- [ ] æµ‹è¯•æ‰¹æ¬¡åˆ†é…ç®—æ³•

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: æ—§ç³»ç»Ÿçš„ç›‘æ§é€»è¾‘å¦‚ä½•è¿ç§»ï¼Ÿ

**A**: æ ¸å¿ƒç›‘æ§é€»è¾‘ä¸å˜ï¼Œåªæ˜¯æ•°æ®æºä»æ—§è¡¨æ”¹ä¸ºæ–°è¡¨ï¼š

```python
# æ—§ä»£ç 
tokens = db.query("SELECT * FROM sol_ws_batch_pool WHERE is_active=1")

# æ–°ä»£ç 
tasks = loader.load_active_tasks()
for task in tasks:
    for target in task['targets']:
        # target['ca'] å°±æ˜¯è¦ç›‘æ§çš„Tokenåœ°å€
```

### Q2: å¦‚ä½•å¤„ç†é…ç½®å˜æ›´ï¼Ÿ

**A**: ä½¿ç”¨ `ConfigWatcher` ç›‘å¬é…ç½®å˜æ›´ï¼Œè‡ªåŠ¨é‡è½½ï¼š

```python
watcher.register_callback(lambda config_id, version: 
    print(f"é…ç½®{config_id}å·²æ›´æ–°åˆ°v{version}")
)
watcher.start()
```

### Q3: æ‰¹æ¬¡åˆ†é…ä½•æ—¶è§¦å‘ï¼Ÿ

**A**: åœ¨ä»¥ä¸‹æƒ…å†µè§¦å‘ï¼š

1. ä»»åŠ¡é¦–æ¬¡åˆ›å»ºæ—¶
2. æ–°å¢/åˆ é™¤ç›®æ ‡æ—¶
3. æ‰‹åŠ¨è°ƒç”¨ `allocate_batches(task_id)`

### Q4: å¦‚ä½•ä¿è¯å¿ƒè·³ä¸ä¸­æ–­ï¼Ÿ

**A**: `HeartbeatReporter` ä½¿ç”¨ç‹¬ç«‹çº¿ç¨‹ï¼Œ30ç§’ä¸€æ¬¡ä¸ŠæŠ¥ï¼Œå³ä½¿ä¸»ç¨‹åºé˜»å¡ä¹Ÿä¸å½±å“ã€‚

---

## ğŸ”Œ WebSocketæ¨é€é›†æˆ

### 9. WebSocketæ¨é€å™¨ï¼ˆwebsocket_pusher.pyï¼‰

Pythonç›‘æ§ç«¯å¯ä»¥é€šè¿‡WebSocketä¸»åŠ¨æ¨é€çŠ¶æ€æ›´æ–°åˆ°å‰ç«¯ã€‚

```python
# websocket_pusher.py
import websocket
import json
import threading
import time
import logging
from typing import Dict, Any

logger = logging.getLogger(__name__)

class WebSocketPusher:
    """WebSocketæ¨é€å™¨ï¼ˆè¿æ¥åˆ°åç«¯WebSocketæœåŠ¡ï¼‰"""
    
    def __init__(self, ws_url: str):
        """
        åˆå§‹åŒ–WebSocketæ¨é€å™¨
        
        Args:
            ws_url: WebSocketæœåŠ¡å™¨åœ°å€ï¼Œä¾‹å¦‚ï¼šws://localhost:8080/websocket/monitor
        """
        self.ws_url = ws_url
        self.ws = None
        self.connected = False
        self.running = False
        self.reconnect_interval = 5  # é‡è¿é—´éš”ï¼ˆç§’ï¼‰
    
    def connect(self):
        """è¿æ¥åˆ°WebSocketæœåŠ¡å™¨"""
        self.running = True
        threading.Thread(target=self._connect_loop, daemon=True).start()
        logger.info(f"WebSocketæ¨é€å™¨å·²å¯åŠ¨: {self.ws_url}")
    
    def _connect_loop(self):
        """è¿æ¥å¾ªç¯ï¼ˆæ”¯æŒè‡ªåŠ¨é‡è¿ï¼‰"""
        while self.running:
            try:
                logger.info(f"æ­£åœ¨è¿æ¥WebSocketæœåŠ¡å™¨: {self.ws_url}")
                
                self.ws = websocket.WebSocketApp(
                    self.ws_url,
                    on_open=self._on_open,
                    on_message=self._on_message,
                    on_error=self._on_error,
                    on_close=self._on_close
                )
                
                # é˜»å¡è¿è¡Œï¼ˆç›´åˆ°è¿æ¥å…³é—­ï¼‰
                self.ws.run_forever()
                
            except Exception as e:
                logger.error(f"WebSocketè¿æ¥å¤±è´¥: {e}")
            
            # å¦‚æœè¿˜åœ¨è¿è¡ŒçŠ¶æ€ï¼Œç­‰å¾…åé‡è¿
            if self.running:
                logger.info(f"{self.reconnect_interval}ç§’åå°è¯•é‡è¿...")
                time.sleep(self.reconnect_interval)
    
    def _on_open(self, ws):
        """è¿æ¥æˆåŠŸå›è°ƒ"""
        self.connected = True
        logger.info("âœ… WebSocketè¿æ¥æˆåŠŸ")
        
        # å¯åŠ¨å¿ƒè·³çº¿ç¨‹
        threading.Thread(target=self._heartbeat_loop, daemon=True).start()
    
    def _on_message(self, ws, message):
        """æ¥æ”¶æ¶ˆæ¯å›è°ƒ"""
        try:
            data = json.loads(message)
            msg_type = data.get('type')
            
            if msg_type == 'pong':
                logger.debug("æ”¶åˆ°å¿ƒè·³å“åº”")
            elif msg_type == 'connected':
                logger.info(f"æœåŠ¡å™¨ç¡®è®¤è¿æ¥: {data.get('message')}")
            else:
                logger.info(f"æ”¶åˆ°æ¶ˆæ¯: {msg_type}")
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
    
    def _on_error(self, ws, error):
        """é”™è¯¯å›è°ƒ"""
        logger.error(f"WebSocketé”™è¯¯: {error}")
    
    def _on_close(self, ws, close_status_code, close_msg):
        """è¿æ¥å…³é—­å›è°ƒ"""
        self.connected = False
        logger.info(f"WebSocketè¿æ¥å…³é—­: {close_status_code} - {close_msg}")
    
    def _heartbeat_loop(self):
        """å¿ƒè·³å¾ªç¯"""
        while self.running and self.connected:
            try:
                self.send_message({'type': 'ping'})
                time.sleep(30)  # æ¯30ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
            except Exception as e:
                logger.error(f"å‘é€å¿ƒè·³å¤±è´¥: {e}")
                break
    
    def send_message(self, message: Dict[str, Any]):
        """å‘é€æ¶ˆæ¯"""
        if self.ws and self.connected:
            try:
                self.ws.send(json.dumps(message))
            except Exception as e:
                logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
        else:
            logger.warning("WebSocketæœªè¿æ¥ï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
    
    def push_batch_status(self, batch_id: int, status: str, details: Dict[str, Any] = None):
        """
        æ¨é€æ‰¹æ¬¡çŠ¶æ€æ›´æ–°
        
        Args:
            batch_id: æ‰¹æ¬¡ID
            status: çŠ¶æ€ (pending/running/paused/stopped/completed/error)
            details: è¯¦ç»†ä¿¡æ¯
        """
        message = {
            'type': 'batch_status',
            'data': {
                'batchId': batch_id,
                'status': status,
                'details': details or {},
                'timestamp': int(time.time() * 1000)
            }
        }
        self.send_message(message)
        logger.info(f"æ¨é€æ‰¹æ¬¡çŠ¶æ€: batchId={batch_id}, status={status}")
    
    def push_task_status(self, task_id: int, status: int, message: str = ''):
        """
        æ¨é€ä»»åŠ¡çŠ¶æ€æ›´æ–°
        
        Args:
            task_id: ä»»åŠ¡ID
            status: çŠ¶æ€ (0=åœæ­¢, 1=è¿è¡Œ)
            message: çŠ¶æ€æ¶ˆæ¯
        """
        msg = {
            'type': 'task_status',
            'data': {
                'taskId': task_id,
                'status': status,
                'message': message,
                'timestamp': int(time.time() * 1000)
            }
        }
        self.send_message(msg)
        logger.info(f"æ¨é€ä»»åŠ¡çŠ¶æ€: taskId={task_id}, status={status}")
    
    def push_alert(self, alert_id: int, alert_type: str, alert_data: Dict[str, Any]):
        """
        æ¨é€å‘Šè­¦é€šçŸ¥
        
        Args:
            alert_id: å‘Šè­¦ID
            alert_type: å‘Šè­¦ç±»å‹ (price_change/holder_change/volume_change/block_event)
            alert_data: å‘Šè­¦æ•°æ®
        """
        message = {
            'type': 'alert',
            'data': {
                'alertId': alert_id,
                'alertType': alert_type,
                'alertData': alert_data,
                'timestamp': int(time.time() * 1000)
            }
        }
        self.send_message(message)
        logger.info(f"æ¨é€å‘Šè­¦: alertId={alert_id}, type={alert_type}")
    
    def close(self):
        """å…³é—­è¿æ¥"""
        self.running = False
        self.connected = False
        if self.ws:
            self.ws.close()
        logger.info("WebSocketæ¨é€å™¨å·²å…³é—­")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºWebSocketæ¨é€å™¨
    pusher = WebSocketPusher('ws://localhost:8080/websocket/monitor')
    pusher.connect()
    
    # ç­‰å¾…è¿æ¥å»ºç«‹
    time.sleep(2)
    
    # æ¨é€æµ‹è¯•æ¶ˆæ¯
    pusher.push_batch_status(1, 'running', {'itemCount': 50, 'progress': 30})
    pusher.push_task_status(1, 1, 'ä»»åŠ¡å·²å¯åŠ¨')
    pusher.push_alert(1, 'price_change', {
        'tokenName': 'TestToken',
        'tokenSymbol': 'TEST',
        'ca': '0x1234567890',
        'priceChange': 25.5,
        'volume': 100000
    })
    
    # ä¿æŒè¿è¡Œ
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        pusher.close()
```

### é›†æˆåˆ°ç›‘æ§ä¸»ç¨‹åº

```python
# monitor_main.py (æ›´æ–°ç‰ˆ)
from websocket_pusher import WebSocketPusher

class MonitorService:
    def __init__(self):
        # ... å…¶ä»–åˆå§‹åŒ– ...
        
        # åˆå§‹åŒ–WebSocketæ¨é€å™¨
        ws_url = os.getenv('WS_URL', 'ws://localhost:8080/websocket/monitor')
        self.ws_pusher = WebSocketPusher(ws_url)
    
    def start(self):
        # ... å…¶ä»–å¯åŠ¨ä»£ç  ...
        
        # å¯åŠ¨WebSocketæ¨é€
        self.ws_pusher.connect()
    
    def _on_batch_status_changed(self, batch_id, status):
        """æ‰¹æ¬¡çŠ¶æ€å˜æ›´æ—¶æ¨é€"""
        self.ws_pusher.push_batch_status(batch_id, status, {
            'itemCount': 50,
            'progress': 75
        })
    
    def _on_alert_triggered(self, alert_id, alert_type, alert_data):
        """è§¦å‘å‘Šè­¦æ—¶æ¨é€"""
        self.ws_pusher.push_alert(alert_id, alert_type, alert_data)
    
    def stop(self):
        # ... å…¶ä»–åœæ­¢ä»£ç  ...
        
        # å…³é—­WebSocket
        self.ws_pusher.close()
```

---

## ğŸ“¡ WebSocketæ¶ˆæ¯æ ¼å¼

### å‰ç«¯ â†’ åç«¯ï¼ˆPythonï¼‰

**1. å¿ƒè·³**
```json
{
  "type": "ping"
}
```

**2. è®¢é˜…ä¸»é¢˜**
```json
{
  "type": "subscribe",
  "topic": "batch_status"
}
```

### åç«¯ï¼ˆPythonï¼‰â†’ å‰ç«¯

**1. è¿æ¥æˆåŠŸ**
```json
{
  "type": "connected",
  "sessionId": "abc123",
  "message": "WebSocketè¿æ¥æˆåŠŸ",
  "timestamp": 1699999999999
}
```

**2. å¿ƒè·³å“åº”**
```json
{
  "type": "pong",
  "timestamp": 1699999999999
}
```

**3. æ‰¹æ¬¡çŠ¶æ€æ›´æ–°**
```json
{
  "type": "batch_status",
  "data": {
    "batchId": 1,
    "status": "running",
    "details": {
      "itemCount": 50,
      "progress": 30,
      "errorCount": 0
    }
  },
  "timestamp": 1699999999999
}
```

**4. ä»»åŠ¡çŠ¶æ€æ›´æ–°**
```json
{
  "type": "task_status",
  "data": {
    "taskId": 1,
    "status": 1,
    "message": "ä»»åŠ¡å·²å¯åŠ¨"
  },
  "timestamp": 1699999999999
}
```

**5. å‘Šè­¦é€šçŸ¥**
```json
{
  "type": "alert",
  "data": {
    "alertId": 123,
    "alertType": "price_change",
    "alertData": {
      "tokenName": "Solana",
      "tokenSymbol": "SOL",
      "ca": "So11111111111111111111111111111111111111112",
      "priceChange": 25.5,
      "volume": 1000000,
      "marketCap": 50000000
    }
  },
  "timestamp": 1699999999999
}
```

---

## ğŸ“ ç‰ˆæœ¬æ›´æ–°è®°å½•

### v1.1 (2025-11-13) - æ¶æ„å…³ç³»ä¿®æ­£

**ä¿®æ­£å†…å®¹**ï¼š
- âœ… ä¿®æ­£ä»»åŠ¡-é…ç½®å…³ç³»ï¼š~~M:Nï¼ˆå¤šå¯¹å¤šï¼‰~~ â†’ **1:Nï¼ˆä¸€å¯¹å¤šï¼‰**
- âœ… æ˜ç¡®è¯´æ˜ï¼šä¸€ä¸ªä»»åŠ¡åªèƒ½ç»‘å®šä¸€ä¸ªé…ç½®
- âœ… è¡¥å……ï¼šPythonä»£ç ä¸­ `configs` æ•°ç»„å®é™…åªæœ‰1ä¸ªå…ƒç´ 
- âœ… æ›´æ–°ï¼šå…³ç³»å›¾å’Œè¯´æ˜æ–‡å­—

**ä¿®æ”¹åŸå› **ï¼š
- å•ä¸ªé…ç½®è¶³å¤Ÿä¸€ä¸ªä»»åŠ¡ä½¿ç”¨ï¼ˆå¯åŒ…å«å¤šä¸ªäº‹ä»¶è§„åˆ™ï¼‰
- å‰ç«¯å®ç°é‡‡ç”¨å•é€‰ï¼ˆconfigIdï¼‰ï¼Œè€Œéå¤šé€‰ï¼ˆconfigIdsï¼‰
- ç®€åŒ–ä¸šåŠ¡é€»è¾‘ï¼Œé™ä½å¤æ‚åº¦

**ä»£ç å½±å“**ï¼š
- âš ï¸ Pythonä»£ç ä¸­ä¿æŒ `configs` æ•°ç»„ç»“æ„ï¼ˆå…¼å®¹æ€§ï¼‰
- âš ï¸ å®é™…ä½¿ç”¨æ—¶å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼š`config = task['configs'][0]`
- âš ï¸ SQLæŸ¥è¯¢ä¼šåªè¿”å›1æ¡é…ç½®è®°å½•

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒå˜æ›´ç‚¹

1. âœ… **æ•°æ®åŠ è½½**ï¼šä» `sol_ws_batch_pool` â†’ `monitor_task_v2` + `monitor_task_target_v2`
2. âœ… **é…ç½®ç®¡ç†**ï¼šä»å•è¡¨ â†’ ~~å¤šå¯¹å¤šå…³è”~~ ä¸€å¯¹å¤šå…³è”ï¼ˆé…ç½®å¯å¤ç”¨ï¼‰â­
3. âœ… **æ‰¹æ¬¡åˆ†é…**ï¼šæ–°å¢ä¸€è‡´æ€§å“ˆå¸Œç®—æ³•
4. âœ… **é…ç½®æ„ŸçŸ¥**ï¼šRedis Pub/Sub + è½®è¯¢å…œåº•
5. âœ… **å¿ƒè·³ä¸ŠæŠ¥**ï¼šç‹¬ç«‹çº¿ç¨‹ï¼Œå®šæ—¶ä¸ŠæŠ¥çŠ¶æ€
6. âœ… **WebSocketæ¨é€**ï¼šå®æ—¶çŠ¶æ€æ›´æ–°åˆ°å‰ç«¯

### ä¼˜åŠ¿

- ğŸ“Š **æ•°æ®ç»“æ„æ¸…æ™°**ï¼šèŒè´£åˆ†ç¦»ï¼Œä¾¿äºç»´æŠ¤
- ğŸš€ **æ€§èƒ½ä¼˜åŒ–**ï¼šé…ç½®å¤ç”¨ï¼Œå‡å°‘å†—ä½™
- ğŸ”” **å®æ—¶æ„ŸçŸ¥**ï¼šé…ç½®å˜æ›´<2ç§’ç”Ÿæ•ˆ
- ğŸ’“ **å¥åº·ç›‘æ§**ï¼šå¿ƒè·³æœºåˆ¶ï¼Œæ•…éšœå¯è§
- ğŸ”Œ **å®æ—¶æ¨é€**ï¼šWebSocketåŒå‘é€šä¿¡ï¼Œå‰ç«¯å®æ—¶æ›´æ–°

---

## é™„å½•Cï¼šå…³é”®å®ç°ç»†èŠ‚ï¼ˆFAQï¼‰

### Q1: Consumer ID åº”è¯¥å¦‚ä½•ç”Ÿæˆï¼Ÿ

**æ¨èï¼šåŠ¨æ€ç”Ÿæˆï¼ˆhostname + pidï¼‰** âœ…

```python
import socket
import os

# å¯åŠ¨æ—¶ç”Ÿæˆå”¯ä¸€çš„ consumer_id
CONSUMER_ID = f"{socket.gethostname()}-{os.getpid()}"
# ä¾‹å¦‚: "server-01-12345"
```

**é…ç½®ç¤ºä¾‹**ï¼š

```python
# config.py
CONSUMER_ID_PREFIX = os.getenv("CONSUMER_ID_PREFIX", socket.gethostname())
CONSUMER_ID = f"{CONSUMER_ID_PREFIX}-{os.getpid()}"
```

**ä¼˜åŠ¿**ï¼š
- âœ… å¤šå®ä¾‹éƒ¨ç½²æ—¶è‡ªåŠ¨å”¯ä¸€
- âœ… é‡å¯åè‡ªåŠ¨ç”Ÿæˆæ–°IDï¼ˆé¿å…åƒµå°¸æ‰¹æ¬¡ï¼‰
- âœ… ä¾¿äºè¿ç»´æ’æŸ¥ï¼ˆhostname + pidï¼‰

---

### Q2: æ‰¹æ¬¡IDåº”è¯¥ä½¿ç”¨å“ªä¸ªå­—æ®µï¼Ÿ

**å…³é”®å˜æ›´**ï¼šä½¿ç”¨ `monitor_batch_v2.id` è€Œä¸æ˜¯ `batch_no` â­

| å­—æ®µ | ç±»å‹ | å”¯ä¸€æ€§ | ç”¨é€” |
|------|------|--------|------|
| `id` | BIGINT | å…¨å±€å”¯ä¸€ â­ | Pythonç«¯ä½¿ç”¨ï¼ˆå¿ƒè·³/çŠ¶æ€ä¸ŠæŠ¥ï¼‰ |
| `batch_no` | INT | ä»»åŠ¡å†…å”¯ä¸€ | æ˜¾ç¤ºç”¨ï¼ˆå¦‚"ç¬¬3æ‰¹"ï¼‰ |

**Pythonç«¯ä¿®æ”¹**ï¼š

```python
# âŒ é”™è¯¯ï¼ˆbatch_noåªåœ¨ä»»åŠ¡å†…å”¯ä¸€ï¼Œè·¨ä»»åŠ¡ä¼šå†²çªï¼‰
batch_id = batch['batch_no']

# âœ… æ­£ç¡®ï¼ˆidæ˜¯å…¨å±€å”¯ä¸€çš„ä¸»é”®ï¼‰
batch_id = batch['id']
```

**SQLæŸ¥è¯¢ä¿®æ”¹**ï¼š

```sql
SELECT 
    b.id AS batch_id,          -- å…¨å±€å”¯ä¸€IDï¼ŒPythonç«¯ä½¿ç”¨ â­
    b.task_id,
    b.batch_no,                -- ä»»åŠ¡å†…æ‰¹æ¬¡å·ï¼Œæ˜¾ç¤ºç”¨ï¼ˆ"ç¬¬3æ‰¹"ï¼‰
    b.epoch,
    b.consumer_id,
    b.status
FROM monitor_batch_v2 b
INNER JOIN monitor_task_v2 t ON b.task_id = t.id
WHERE b.task_id = ? 
  AND b.epoch = t.current_epoch
ORDER BY b.batch_no;
```

---

### Q3: Pythonç«¯éœ€è¦ç›´æ¥æ›´æ–°æ•°æ®åº“å¿ƒè·³å—ï¼Ÿ

**ç­”æ¡ˆï¼šä¸éœ€è¦ï¼** âŒ

**æ­£ç¡®çš„å¿ƒè·³æµç¨‹**ï¼š

```
Pythonç«¯                Javaç«¯                 æ•°æ®åº“
  |                      |                      |
  | 1. æ‰§è¡Œæ‰¹æ¬¡          |                      |
  |                      |                      |
  | 2. WebSocketå¿ƒè·³ --->| 3. æ¥æ”¶å¿ƒè·³          |
  |    (æ¯30ç§’)          |                      |
  |                      | 4. æ›´æ–°æ•°æ®åº“ -----> | 5. æŒä¹…åŒ–
  |                      |                      |
  |                      | 6. å¹¿æ’­ç»™å‰ç«¯ -----> | (WebSocketæ¨é€)
  |                      |    (å®æ—¶å±•ç¤º)        |
```

**Pythonç«¯å®ç°**ï¼ˆåªæ¨é€ï¼Œä¸å†™åº“ï¼‰ï¼š

```python
class MonitorTaskRunner:
    def run_batch(self, batch):
        batch_id = batch['id']  # å…¨å±€å”¯ä¸€ID
        
        # âœ… åªé€šè¿‡WebSocketä¸ŠæŠ¥
        self.ws_client.update_batch_status(
            batch_id=batch_id,
            status="running",
            progress=50
        )
        
        # âŒ ä¸ç›´æ¥æ›´æ–°æ•°æ®åº“
        # self.db.update_batch_heartbeat(batch_id)  # åˆ é™¤è¿™è¡Œï¼
```

**WebSocketæ¶ˆæ¯æ ¼å¼**ï¼š

```json
{
  "type": "batch_heartbeat",
  "data": {
    "batchId": 12345,          // å…¨å±€å”¯ä¸€IDï¼ˆmonitor_batch_v2.idï¼‰â­
    "taskId": 4,               // ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œç”¨äºéªŒè¯ï¼‰
    "consumerId": "server-01-12345",
    "progress": 50,
    "timestamp": 1731484800
  }
}
```

**ä¼˜åŠ¿**ï¼š
- âœ… **å•ä¸€å†™å…¥ç‚¹**ï¼šåªæœ‰Javaæ›´æ–°æ•°æ®åº“ï¼Œé¿å…å†²çª
- âœ… **å®æ—¶æ€§**ï¼šWebSocketæ¨é€ï¼Œå‰ç«¯ç«‹å³å¯è§
- âœ… **è§£è€¦**ï¼šPythonæ— éœ€å…³å¿ƒæ•°æ®åº“schemaå˜æ›´
- âœ… **å®‰å…¨æ€§**ï¼šPythonæ— éœ€æ•°æ®åº“å†™æƒé™

---

### Q4: æ˜¯å¦éœ€è¦å®ç°æ‰¹æ¬¡ä¼˜å…ˆçº§ï¼Ÿ

**å½“å‰ç‰ˆæœ¬ï¼šä¸å®ç°** â­

**ç†ç”±**ï¼š
1. âœ… æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹è¿è¡Œï¼Œä¸å­˜åœ¨è·¨ä»»åŠ¡ç«äº‰
2. âœ… Pythonç«¯æŒ‰é¡ºåºæ¶ˆè´¹æ‰¹æ¬¡ï¼Œå…¨é‡å¤„ç†
3. âœ… å¢åŠ ä¼˜å…ˆçº§ä¼šå¢åŠ å¤æ‚åº¦ï¼Œæ”¶ç›Šä¸å¤§

**å¦‚æœæœªæ¥éœ€è¦æ”¯æŒ**ï¼š

```sql
-- æ·»åŠ ä¼˜å…ˆçº§å­—æ®µ
ALTER TABLE monitor_batch_v2 
ADD COLUMN priority INT DEFAULT 0 COMMENT 'æ‰¹æ¬¡ä¼˜å…ˆçº§ï¼ˆè¶Šå¤§è¶Šä¼˜å…ˆï¼‰';

-- Pythonç«¯æŒ‰ä¼˜å…ˆçº§æ’åº
SELECT ... 
FROM monitor_batch_v2 
ORDER BY priority DESC, batch_no ASC;
```

**é€‚ç”¨åœºæ™¯**ï¼š
- ğŸ¯ VIPä»»åŠ¡ä¼˜å…ˆå¤„ç†
- ğŸ¯ é«˜ä»·å€¼ç›®æ ‡ä¼˜å…ˆç›‘æ§
- ğŸ¯ ç´§æ€¥ä»»åŠ¡æ’é˜Ÿ

---

### Q5: è‡ªåŠ¨æ›´æ–°åï¼Œæ‰¹æ¬¡ä¼šç«‹å³åˆ‡æ¢å—ï¼Ÿ

**ç­”æ¡ˆï¼šä¸ä¼šç«‹å³åˆ‡æ¢ï¼Œé‡‡ç”¨é›¶åœæœºç­–ç•¥** âœ…

**æµç¨‹**ï¼š

```
1. Javaç«¯æ£€æµ‹åˆ°é…ç½®/ç­›é€‰æ¡ä»¶å˜æ›´
   â†“
2. æ™ºèƒ½åŒæ­¥ï¼šç”Ÿæˆæ–°çš„ç›®æ ‡åˆ—è¡¨
   â†“
3. åˆ†é…æ–°æ‰¹æ¬¡ï¼ˆepoch+1ï¼‰
   â†“
4. æ›´æ–° monitor_task_v2.current_epoch = epoch+1
   â†“
5. Pythonç«¯ä¸‹æ¬¡æŸ¥è¯¢æ—¶è‡ªåŠ¨è·å–æ–°æ‰¹æ¬¡
   â†“
6. æ—§æ‰¹æ¬¡ç»§ç»­è¿è¡Œï¼Œç›´åˆ°å®Œæˆ
   â†“
7. 10åˆ†é’ŸåJavaç«¯æ¸…ç†æ—§æ‰¹æ¬¡æ•°æ®
```

**å…³é”®ç‚¹**ï¼š
- âœ… Pythonç«¯å§‹ç»ˆæŸ¥è¯¢ `epoch = current_epoch` çš„æ‰¹æ¬¡
- âœ… æ—§æ‰¹æ¬¡ä¸ä¼šç«‹å³ä¸­æ–­ï¼Œå®Œæˆå½“å‰è½®æ¬¡å³å¯
- âœ… æ–°æ‰¹æ¬¡å’Œæ—§æ‰¹æ¬¡å¯çŸ­æš‚å¹¶å­˜ï¼ˆgrace periodï¼‰
- âœ… 10åˆ†é’Ÿçª—å£æœŸï¼Œç¡®ä¿æ—§æ‰¹æ¬¡å¹³æ»‘é€€å‡º

**Pythonç«¯ä»£ç **ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰ï¼š

```python
# æ¯æ¬¡æŸ¥è¯¢éƒ½ä¼šè‡ªåŠ¨è·å–æœ€æ–°epochçš„æ‰¹æ¬¡
batches = self.get_batches_for_task(task_id)
# æŸ¥è¯¢æ¡ä»¶ï¼šWHERE epoch = (SELECT current_epoch FROM monitor_task_v2 WHERE id = ?)
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.1  
**æœ€åæ›´æ–°**: 2025-11-13  
**ä½œè€…**: Kakarot Team

